0
00:00:00,000 --> 00:00:00,910
https://youtu.be/IcFuUrvPd_M

1
00:00:00,910 --> 00:00:04,660
MATT MCGARRITY: We're almost done with the material for the week, and in this

2
00:00:04,660 --> 00:00:08,520
lecture, I think we're getting down to some of the finest grained analysis of

3
00:00:08,520 --> 00:00:12,800
what good informative speakers are doing, and that is clarity through

4
00:00:12,800 --> 00:00:14,120
elaboration.

5
00:00:14,120 --> 00:00:19,610
Being able to really discuss their details with reference to the larger

6
00:00:19,610 --> 00:00:24,510
point in a way that's just elegant and sublime.

7
00:00:24,510 --> 00:00:29,410
And so we've been working this week on moving from idea to the outline, and

8
00:00:29,410 --> 00:00:32,259
we're almost at the end of this very basic process.

9
00:00:32,259 --> 00:00:36,210
So once again, we've gone through coming up with main ideas, breaking it

10
00:00:36,210 --> 00:00:40,010
down into smaller ideas, identifying the details that are going to help you

11
00:00:40,010 --> 00:00:44,610
discuss that content, and now, we're getting to how are you discussing

12
00:00:44,610 --> 00:00:49,500
those details in a way that just crystallize that information?

13
00:00:49,500 --> 00:00:52,870
Now, we were doing some of this, by the way, back in the impromptu when we

14
00:00:52,870 --> 00:00:55,930
were doing state it, explain it, prove it, and conclude it, right?

15
00:00:55,930 --> 00:00:58,860
I mean, we're talking about here's what the key idea is.

16
00:00:58,860 --> 00:00:59,880
Let me walk you into it.

17
00:00:59,880 --> 00:01:02,290
Here's the detail, now let me walk you out.

18
00:01:02,290 --> 00:01:07,260
And the informative speech, we're just saying it's not quite as mechanistic.

19
00:01:07,260 --> 00:01:10,740
So we need another tool, or another way of understanding, or different

20
00:01:10,740 --> 00:01:14,330
models for getting at the relationship between big ideas

21
00:01:14,330 --> 00:01:16,060
and supporting detail.

22
00:01:16,060 --> 00:01:19,230
And so that's what I want to talk about in this lecture.

23
00:01:19,230 --> 00:01:22,300
What's going on with elaboration?

24
00:01:22,300 --> 00:01:27,720
And by that, I mean, that term I'm using simply to say you're taking your

25
00:01:27,720 --> 00:01:30,110
idea and your expanding it.

26
00:01:30,110 --> 00:01:33,990
You're not just talking about it, but you're elaborating on it.

27
00:01:33,990 --> 00:01:36,300
You're expanding our understanding of it.

28
00:01:36,300 --> 00:01:40,270
So what's happening in elaboration, and then we're going to analyze a few

29
00:01:40,270 --> 00:01:43,650
clips to see this in action.

30
00:01:43,650 --> 00:01:47,390
And in terms of very specifically, how certain sentences are performing

31
00:01:47,390 --> 00:01:49,480
certain functions.

32
00:01:49,480 --> 00:01:54,000
So first off, what's going on with this process of elaboration.

33
00:01:54,000 --> 00:01:57,410
Once again, it's similar in some way to what you were

34
00:01:57,410 --> 00:01:59,050
doing in your impromptu.

35
00:01:59,050 --> 00:02:03,600
Basically, you're walking us into and out of the details.

36
00:02:03,600 --> 00:02:06,570
You're providing us shells of context.

37
00:02:06,570 --> 00:02:11,240
You're saying here's the idea, let me get more specific, more specific.

38
00:02:11,240 --> 00:02:15,050
Oh, I've got the smallest bit of detail, and now I'm bringing it back

39
00:02:15,050 --> 00:02:17,380
out again, so you remember what I'm talking about.

40
00:02:17,380 --> 00:02:20,960
So I see this as this hour glass function.

41
00:02:20,960 --> 00:02:26,450
Now, performing this hour glass of moving from broad to narrow back out

42
00:02:26,450 --> 00:02:28,330
again, it could be a main point.

43
00:02:28,330 --> 00:02:29,970
It could be a sub point.

44
00:02:29,970 --> 00:02:33,370
I just want to say that whenever you need to move from sort of a higher

45
00:02:33,370 --> 00:02:38,210
order level of complexity into the details, that you don't just jump

46
00:02:38,210 --> 00:02:42,270
straight to the details, and you don't simply sit in the details at the

47
00:02:42,270 --> 00:02:45,450
exclusion of the larger point, but that you're finding a way to walk us

48
00:02:45,450 --> 00:02:49,780
into and out of the complexities of this information.

49
00:02:49,780 --> 00:02:52,950
So in terms of that rubric, this is really what I mean by balancing

50
00:02:52,950 --> 00:02:56,510
breadth and depth, context and content.

51
00:02:56,510 --> 00:03:00,570
I've got my larger idea and as a novice with your information, you're

52
00:03:00,570 --> 00:03:04,800
helping me figure out where the details sit in relation to that, and

53
00:03:04,800 --> 00:03:07,430
how these ideas relate to one another.

54
00:03:07,430 --> 00:03:09,850
So it's not just that you're talking to me.

55
00:03:09,850 --> 00:03:15,230
You're providing me with a map through the information, how the components

56
00:03:15,230 --> 00:03:16,880
relate to one another.

57
00:03:16,880 --> 00:03:20,450
And I would say in terms of elaboration, excellent speakers make

58
00:03:20,450 --> 00:03:23,110
this sound effortless.

59
00:03:23,110 --> 00:03:26,140
But there's something going on there.

60
00:03:26,140 --> 00:03:30,360
And at some level, this is not too dissimilar to how writing instruction,

61
00:03:30,360 --> 00:03:33,380
at least in the US, talks about paragraphs.

62
00:03:33,380 --> 00:03:35,160
You've got a topic sentence.

63
00:03:35,160 --> 00:03:38,670
You've got supporting sentences, and then you've got a concluding line.

64
00:03:38,670 --> 00:03:42,080
The only thing we're doing is saying that those supporting sentences are

65
00:03:42,080 --> 00:03:46,470
getting more and more narrow and more and more detailed, and then going back

66
00:03:46,470 --> 00:03:48,380
out to that concluding line.

67
00:03:48,380 --> 00:03:52,240
And the reason I like thinking about it in this way is because it places

68
00:03:52,240 --> 00:03:57,070
most of the emphasis on the idea, and makes sure that that detail maintains

69
00:03:57,070 --> 00:03:58,700
a supporting role.

70
00:03:58,700 --> 00:04:01,080
So what I'd like to do now is take a look at this

71
00:04:01,080 --> 00:04:02,580
through a couple of examples.

72
00:04:02,580 --> 00:04:06,140
Now, we're going to look at it in terms of the text, the transcript of

73
00:04:06,140 --> 00:04:07,140
what is said.

74
00:04:07,140 --> 00:04:10,460
But just like last time, at the end of this video, if you're

75
00:04:10,460 --> 00:04:11,950
watching this on--

76
00:04:11,950 --> 00:04:13,890
I've got the scrolling bars here.

77
00:04:13,890 --> 00:04:17,820
If you're watching this on the lesson page for the week, so lesson five,

78
00:04:17,820 --> 00:04:21,890
week five, they'll be an embedded clip of these two speakers.

79
00:04:21,890 --> 00:04:24,830
One of which we've already seen before.

80
00:04:24,830 --> 00:04:27,050
She was one of the people that we looked at in week

81
00:04:27,050 --> 00:04:29,100
one, Elizabeth Warren.

82
00:04:29,100 --> 00:04:32,070
And then we're also going to be looking at Paul Krugman, and I use

83
00:04:32,070 --> 00:04:33,040
both of these.

84
00:04:33,040 --> 00:04:35,710
They're both Americans, but I like looking at them both because they're

85
00:04:35,710 --> 00:04:39,820
both economists, at least they're talking about economic issues, and so

86
00:04:39,820 --> 00:04:43,280
they sort of serve as an interesting counter balance to one another.

87
00:04:43,280 --> 00:04:45,830
But let's go ahead and take a look at Elizabeth Warren.

88
00:04:45,830 --> 00:04:51,420
So she's now a Massachusetts senator, but before that she was a professor of

89
00:04:51,420 --> 00:04:54,980
law and gave a number of talks about the banking industry

90
00:04:54,980 --> 00:04:56,520
and financial issues.

91
00:04:56,520 --> 00:04:59,630
Again, I'm using this as an example of a speaker.

92
00:04:59,630 --> 00:05:04,450
Certainly, those of you in the US, I don't care one way or the other

93
00:05:04,450 --> 00:05:06,790
whether or not you agree with her politically or not.

94
00:05:06,790 --> 00:05:10,430
That's not the function of this course and nor do I want it to be.

95
00:05:10,430 --> 00:05:14,030
But I do think there's something to be learned in terms of how she's walking

96
00:05:14,030 --> 00:05:16,810
into and out of complex detail.

97
00:05:16,810 --> 00:05:20,340
So let's go ahead and take a look at what you'll listen to at the end of

98
00:05:20,340 --> 00:05:21,270
this video.

99
00:05:21,270 --> 00:05:23,710
So let's go ahead and take a look at this text

100
00:05:23,710 --> 00:05:27,120
So you see on here, I've got distinguishing--

101
00:05:27,120 --> 00:05:33,970
what I would call the key idea and then the actual details, and then the

102
00:05:33,970 --> 00:05:36,810
black text would just be sort of filler lines.

103
00:05:36,810 --> 00:05:38,780
OK so we've got a couple of filler lines.

104
00:05:38,780 --> 00:05:40,080
My prediction should still hold.

105
00:05:40,080 --> 00:05:42,470
After all, families are getting richer, in the sense of

106
00:05:42,470 --> 00:05:44,140
more income over time.

107
00:05:44,140 --> 00:05:45,450
What happened?

108
00:05:45,450 --> 00:05:46,270
Pause.

109
00:05:46,270 --> 00:05:49,110
Savings went down in the same time period.

110
00:05:49,110 --> 00:05:50,240
That's a point.

111
00:05:50,240 --> 00:05:50,950
That's her claim.

112
00:05:50,950 --> 00:05:53,040
That's her subpoint.

113
00:05:53,040 --> 00:05:55,770
Then we jump straight to some detail, her evidence.

114
00:05:55,770 --> 00:05:59,820
So the one income family in 1970 was putting away about 11% of

115
00:05:59,820 --> 00:06:01,430
their take home pay.

116
00:06:01,430 --> 00:06:05,890
Then notice here, she doesn't jump right to the next piece of evidence.

117
00:06:05,890 --> 00:06:07,150
She's got a buffer sentence.

118
00:06:07,150 --> 00:06:08,310
She's giving us time.

119
00:06:08,310 --> 00:06:11,640
And I don't even know she knows that she's doing this, but she's giving us

120
00:06:11,640 --> 00:06:13,410
time to process that.

121
00:06:13,410 --> 00:06:17,220
She's elaborating on that evidence.

122
00:06:17,220 --> 00:06:18,450
So she says, think about that.

123
00:06:18,450 --> 00:06:22,500
Week after week, month after month, they're putting away about 11%.

124
00:06:22,500 --> 00:06:30,670
Those one, two, three, four sentences don't add much new content to what was

125
00:06:30,670 --> 00:06:33,760
in green there, 1970, putting away around 11%.

126
00:06:33,760 --> 00:06:37,380
They don't add new content, but I would say they are desperately

127
00:06:37,380 --> 00:06:41,730
important when it comes to listening to that speech.

128
00:06:41,730 --> 00:06:43,160
Because they elaborate.

129
00:06:43,160 --> 00:06:43,910
They repeat.

130
00:06:43,910 --> 00:06:44,680
They reiterate.

131
00:06:44,680 --> 00:06:46,920
They open up that piece of data.

132
00:06:46,920 --> 00:06:48,860
But then, we're ready for the next one.

133
00:06:48,860 --> 00:06:54,720
By the year 2006, you notice that line goes below zero, another buffer line.

134
00:06:54,720 --> 00:06:58,430
This is a concept only Alan Greenspan would love, back to the details,

135
00:06:58,430 --> 00:06:59,410
negative savings.

136
00:06:59,410 --> 00:07:03,640
The American family today puts away nothing, buffer, and quite frankly,

137
00:07:03,640 --> 00:07:06,300
has been putting away nothing for the last five or six years.

138
00:07:06,300 --> 00:07:07,505
There's nothing there.

139
00:07:07,505 --> 00:07:10,220
There is no savings.

140
00:07:10,220 --> 00:07:13,210
Look at the end of that paragraph and the beginning of that paragraph.

141
00:07:13,210 --> 00:07:14,580
That's a subpoint.

142
00:07:14,580 --> 00:07:18,090
That right there is a subpoint with detail, and that, I think, is how you

143
00:07:18,090 --> 00:07:19,320
do it well.

144
00:07:19,320 --> 00:07:24,540
It is weaving together these various levels of meaning, but weaving them

145
00:07:24,540 --> 00:07:31,090
together in a way that there's not a hard shift between claim and support.

146
00:07:31,090 --> 00:07:34,230
And I won't read you the next one, but you could certainly take a look at it.

147
00:07:34,230 --> 00:07:41,260
But you got the same thing going on, a claim, or an idea, a key point, some

148
00:07:41,260 --> 00:07:46,110
buffer, explanation, getting into the nitty gritty of the evidence of the

149
00:07:46,110 --> 00:07:50,570
details for that point, and then buffer sentencing us out and ending

150
00:07:50,570 --> 00:07:52,490
again with a capper.

151
00:07:52,490 --> 00:07:57,500
So I think that is a good example of how this would work.

152
00:07:57,500 --> 00:08:00,860
Now, let's take a look at somebody else, Paul Krugman.

153
00:08:00,860 --> 00:08:02,330
He's no slouch, right?

154
00:08:02,330 --> 00:08:03,560
The dude's got a Nobel Prize.

155
00:08:03,560 --> 00:08:05,480
I don't think they just hand those out.

156
00:08:05,480 --> 00:08:11,510
So he knows what he's talking about, but in this clip, and it's a clip

157
00:08:11,510 --> 00:08:15,900
chosen for this very reason, so I'm not saying he never does this.

158
00:08:15,900 --> 00:08:19,580
But it serves as a good counter statement to what we just saw.

159
00:08:19,580 --> 00:08:23,630
So let's go ahead and take a look at textually what's going on when he's

160
00:08:23,630 --> 00:08:27,850
talking through some financial evidence.

161
00:08:27,850 --> 00:08:31,290
All right, so here, you've got the evidence.

162
00:08:31,290 --> 00:08:36,380
So he's got, just getting back to normal levels of state and local--

163
00:08:36,380 --> 00:08:39,630
of state and local employment relative to population, you can

164
00:08:39,630 --> 00:08:41,330
get 1.3 million workers.

165
00:08:41,330 --> 00:08:44,360
You can add 1.3 million people to employment right away.

166
00:08:44,360 --> 00:08:45,420
So that's a buffer sentence.

167
00:08:45,420 --> 00:08:49,920
So we've got our piece of data, but we don't have a driving subpoint.

168
00:08:49,920 --> 00:08:54,390
We don't have a key idea to attach that evidence to.

169
00:08:54,390 --> 00:09:00,480
Now, it kind of makes its own point but we haven't shelled that detail.

170
00:09:00,480 --> 00:09:02,540
It sort of floats out there.

171
00:09:02,540 --> 00:09:06,070
He's got some buffer, but he's not dialing back out to the

172
00:09:06,070 --> 00:09:07,380
level of key idea.

173
00:09:07,380 --> 00:09:10,310
Then we jump again into another piece of hard evidence.

174
00:09:10,310 --> 00:09:12,850
You can get $3 billion a year in aid to the economy.

175
00:09:12,850 --> 00:09:16,890
That's enough almost certainly to give us below 7% on unemployment.

176
00:09:16,890 --> 00:09:19,530
To get us into a much, much better economic frame.

177
00:09:19,530 --> 00:09:20,940
It's not technically hard.

178
00:09:20,940 --> 00:09:21,580
Politically hard.

179
00:09:21,580 --> 00:09:22,830
No question about it.

180
00:09:22,830 --> 00:09:28,080
So I don't really see a whole bunch in that small segment on the

181
00:09:28,080 --> 00:09:30,090
larger claim there.

182
00:09:30,090 --> 00:09:32,420
Now, it's not terrible.

183
00:09:32,420 --> 00:09:37,760
It's not bad, but I think there's a real difference between how one

184
00:09:37,760 --> 00:09:43,670
interacts with that Krugman clip as opposed to that Warren clip.

185
00:09:43,670 --> 00:09:49,090
And what I think is happening is, in that Krugman clip, it's too truncated.

186
00:09:49,090 --> 00:09:51,600
If there's just not enough time--

187
00:09:51,600 --> 00:09:56,480
there's not enough elaboration on that evidence.

188
00:09:56,480 --> 00:09:59,350
It's just here's a data point, here's a data point.

189
00:09:59,350 --> 00:10:04,580
And when I work with a lot of people in business and science and in most

190
00:10:04,580 --> 00:10:07,670
fields, they tend to be more on that end.

191
00:10:07,670 --> 00:10:13,590
They talk almost exclusively about the details without giving us elaboration,

192
00:10:13,590 --> 00:10:17,350
without giving us the sense for what that subpoint is or what

193
00:10:17,350 --> 00:10:19,320
the larger idea is.

194
00:10:19,320 --> 00:10:22,470
They've got here a general theme, and then I'm going to just jump and talk

195
00:10:22,470 --> 00:10:23,570
to the details.

196
00:10:23,570 --> 00:10:27,240
So I like moving through these two clips, putting them in conversation

197
00:10:27,240 --> 00:10:32,240
with each other, because I think it highlights how you can provide

198
00:10:32,240 --> 00:10:35,650
context, meaning, through elaboration.

199
00:10:35,650 --> 00:10:37,870
It's not just about that evidence.

200
00:10:37,870 --> 00:10:43,130
It's about walking us into and out of that evidence so we've got some type

201
00:10:43,130 --> 00:10:45,510
of meaning attached to it.

202
00:10:45,510 --> 00:10:53,240
And so this matters, because, in essence, if it's just the raw data,

203
00:10:53,240 --> 00:10:57,240
your audience can get that raw data anywhere.

204
00:10:57,240 --> 00:10:58,970
They can go look it up on Wikipedia.

205
00:10:58,970 --> 00:11:01,070
We live in an information society.

206
00:11:01,070 --> 00:11:05,010
Almost anything that you're going to speak on, they can probably go find

207
00:11:05,010 --> 00:11:10,150
out that same information or get, at least, your details somewhere else.

208
00:11:10,150 --> 00:11:15,950
But what you provide as a speaker is meaning to the information, an

209
00:11:15,950 --> 00:11:18,580
interpretation of the information, a read on that

210
00:11:18,580 --> 00:11:21,560
information, a sense of context.

211
00:11:21,560 --> 00:11:24,430
That's what you're doing as an informative speaker.

212
00:11:24,430 --> 00:11:26,340
You're not just providing raw information.

213
00:11:26,340 --> 00:11:27,900
You're the filter.

214
00:11:27,900 --> 00:11:32,200
I'll often come back to this when I say in persuasive speaking and

215
00:11:32,200 --> 00:11:35,030
informative speaking, you're the argument.

216
00:11:35,030 --> 00:11:37,640
It's not you're the performer and your argument is on the page.

217
00:11:37,640 --> 00:11:39,900
When you stand up to speak, the audience doesn't see

218
00:11:39,900 --> 00:11:41,380
that thing, that page.

219
00:11:41,380 --> 00:11:43,110
They see you.

220
00:11:43,110 --> 00:11:44,470
So you're the argument.

221
00:11:44,470 --> 00:11:45,670
You're the presenter.

222
00:11:45,670 --> 00:11:48,440
You're the thing that people are interacting with.

223
00:11:48,440 --> 00:11:52,480
So your job is to help us, as an audience, understand what that

224
00:11:52,480 --> 00:11:54,040
information means.

225
00:11:54,040 --> 00:11:59,710
You're informing us what the details are and what those details mean for us

226
00:11:59,710 --> 00:12:01,360
for the topic.

227
00:12:01,360 --> 00:12:03,070
And that's a big thing.

228
00:12:03,070 --> 00:12:07,080
So we've got one more lecture left, and we'll take a look at examining an

229
00:12:07,080 --> 00:12:10,250
informative speech and getting some feedback form exposure.

230
00:12:10,250 --> 00:12:13,590
But at this point, in terms of what I've been asking you to do this week,

231
00:12:13,590 --> 00:12:15,630
you should have a pretty solid outline.

232
00:12:15,630 --> 00:12:18,520
We've got main points, subpoints, and details.

233
00:12:18,520 --> 00:12:20,400
It's probably gone through a couple of revisions and a

234
00:12:20,400 --> 00:12:21,800
couple of run throughs.

235
00:12:21,800 --> 00:12:25,240
I certainly asked you to work on it a couple of times, and you're probably

236
00:12:25,240 --> 00:12:29,000
locking down the key content and your refining.

237
00:12:29,000 --> 00:12:33,570
And so this week has been about moving from the idea, the informative idea,

238
00:12:33,570 --> 00:12:37,120
coming out of the last week from our goals for the informative speech.

239
00:12:37,120 --> 00:12:41,110
It's been moving from idea to this developed outline, and that's a lot of

240
00:12:41,110 --> 00:12:46,470
terrain to cover in the span of a week and it reflects a lot of

241
00:12:46,470 --> 00:12:49,110
decisions on your part.

242
00:12:49,110 --> 00:12:50,250
And that's good.

243
00:12:50,250 --> 00:12:53,860
That's what you should be doing as a speaker, rendering judgments.

244
00:12:53,860 --> 00:12:59,010
Remember that William Keith and Christian Lumber line, clarity is the

245
00:12:59,010 --> 00:13:01,000
result of choices.

246
00:13:01,000 --> 00:13:04,380
Every time you're making a change, you're rendering a judgment, you're

247
00:13:04,380 --> 00:13:05,780
making a decision.

248
00:13:05,780 --> 00:13:09,810
The key thing is that you're driving those decisions towards the goal of

249
00:13:09,810 --> 00:13:11,810
clarity for that audience.

250
00:13:11,810 --> 00:13:17,910
So work on your speeches, continue to refine this, continue to develop it.

251
00:13:17,910 --> 00:13:20,230
Really start doing some run throughs.

252
00:13:20,230 --> 00:13:22,460
Hopefully, you're working this up for a speech that you're going to be

253
00:13:22,460 --> 00:13:26,550
giving tomorrow, or even if you're thinking about doing it for this

254
00:13:26,550 --> 00:13:28,540
class, you should be practicing it.

255
00:13:28,540 --> 00:13:31,890
Next week, we're going to get in to style and delivery.

256
00:13:31,890 --> 00:13:34,730
But at this point, you should have something that you should be working

257
00:13:34,730 --> 00:13:37,210
with and running and starting to feel good about.

258
00:13:37,210 --> 00:13:38,460

