0
00:00:00,000 --> 00:00:00,870
https://youtu.be/cRCKAV132N4

1
00:00:00,870 --> 00:00:03,060
MATT MCGARRITY: In the last lecture, we talked a little bit about whether

2
00:00:03,060 --> 00:00:06,200
or not you wanted to include counter arguments in your speech.

3
00:00:06,200 --> 00:00:08,029
So let's say that yes, you do.

4
00:00:08,029 --> 00:00:10,290
You want to include counter arguments in your speech.

5
00:00:10,290 --> 00:00:14,010
So now what I want to spend our time talking about is, what

6
00:00:14,010 --> 00:00:15,690
do you respond to?

7
00:00:15,690 --> 00:00:17,960
You don't necessarily have to respond to everything.

8
00:00:17,960 --> 00:00:19,870
You want to sort of pick and choose your battles.

9
00:00:19,870 --> 00:00:23,450
What do you need to respond to in order to achieve your goals?

10
00:00:23,450 --> 00:00:26,340
So in order to do this, we have to figure out where you and

11
00:00:26,340 --> 00:00:27,800
your audience disagree.

12
00:00:27,800 --> 00:00:30,650
And in argumentation we call these clash points, where you and your

13
00:00:30,650 --> 00:00:31,670
audience disagree.

14
00:00:31,670 --> 00:00:34,160
Everything in argumentation is so violent.

15
00:00:34,160 --> 00:00:36,490
But we're talking about clash points.

16
00:00:36,490 --> 00:00:39,890
And this is akin to the classical notion of stasis theory, sort of

17
00:00:39,890 --> 00:00:43,990
seeing the stances in a debate, stasis as stances, positions.

18
00:00:43,990 --> 00:00:48,080
And the classical rhetorician Deborah Hawhee has pointed out how in

19
00:00:48,080 --> 00:00:52,930
rhetoric, understanding stases was also very similar to how sort of young

20
00:00:52,930 --> 00:00:55,030
wrestlers would learn how to wrestle.

21
00:00:55,030 --> 00:00:59,400
So if you can look at your opponent and see what stance that they've

22
00:00:59,400 --> 00:01:03,370
taken, well, you're going to design your attack or your response

23
00:01:03,370 --> 00:01:04,080
accordingly.

24
00:01:04,080 --> 00:01:07,310
You're not going to try to sweep the leg if they don't have any

25
00:01:07,310 --> 00:01:08,006
weight on their leg.

26
00:01:08,006 --> 00:01:11,480
So you want to see what their position is so that you can strategize an

27
00:01:11,480 --> 00:01:12,370
appropriate position.

28
00:01:12,370 --> 00:01:16,140
That's what's stasis theory allows you to do is identify these clash points

29
00:01:16,140 --> 00:01:19,030
and figure out which one of these clash points you really need to

30
00:01:19,030 --> 00:01:21,680
respond to if you're going to be persuasive.

31
00:01:21,680 --> 00:01:25,830
So in doing this in this lecture here, we're going to talk about

32
00:01:25,830 --> 00:01:29,860
distinguishing between matters of fact, policy, and value to help us

33
00:01:29,860 --> 00:01:31,680
identify these clash points.

34
00:01:31,680 --> 00:01:33,510
So to begin with, fact.

35
00:01:33,510 --> 00:01:38,540
Debates over fact, assertions of fact are really issues of what is or what

36
00:01:38,540 --> 00:01:41,130
isn't, what happened or what didn't.

37
00:01:41,130 --> 00:01:42,950
These can be noncontroversial.

38
00:01:42,950 --> 00:01:45,450
So today is Thursday.

39
00:01:45,450 --> 00:01:47,890
That's not a particularly controversial claim.

40
00:01:47,890 --> 00:01:50,150
It's something I would like you to take as valid.

41
00:01:50,150 --> 00:01:52,320
But we can adjudicate this easily.

42
00:01:52,320 --> 00:01:57,090
I can have multiple people come in and say, yes, it is indeed Thursday.

43
00:01:57,090 --> 00:02:00,650
So you're not watching-- who knows if you're watching it on a Thursday?

44
00:02:00,650 --> 00:02:03,420
Nevertheless, that's a pretty low threshold claim.

45
00:02:03,420 --> 00:02:06,130
But other claims of fact can be far more complicated.

46
00:02:06,130 --> 00:02:10,690
So certainly in criminal cases many times they're trying to decide on

47
00:02:10,690 --> 00:02:12,030
matters of fact.

48
00:02:12,030 --> 00:02:16,170
Did Person X steal this car or not steal this car?

49
00:02:16,170 --> 00:02:18,560
It either happened or it didn't happen.

50
00:02:18,560 --> 00:02:19,860
You do this at work, right?

51
00:02:19,860 --> 00:02:22,125
How many people will use our new service?

52
00:02:22,125 --> 00:02:23,090
Well, we don't know.

53
00:02:23,090 --> 00:02:24,250
But we can make estimates.

54
00:02:24,250 --> 00:02:26,190
How many people used the old service?

55
00:02:26,190 --> 00:02:29,610
What were the customer service ratings on the old service?

56
00:02:29,610 --> 00:02:31,990
These are all things that can probably be sorted out.

57
00:02:31,990 --> 00:02:34,660
You can go look up that information.

58
00:02:34,660 --> 00:02:38,040
Scientists all the time argue over issues of fact.

59
00:02:38,040 --> 00:02:43,780
So was there such a thing that we called for a while the brontosaurus?

60
00:02:43,780 --> 00:02:46,650
So they thought so for a long time, that there was this thing called the

61
00:02:46,650 --> 00:02:47,210
brontosaurus.

62
00:02:47,210 --> 00:02:51,320
But prevailing interpretation of fact now is that, no, it was an apatosaurus

63
00:02:51,320 --> 00:02:53,930
with a couple of other fossils mixed in.

64
00:02:53,930 --> 00:02:58,445
So these are matters of fact, where what is or what isn't.

65
00:02:58,445 --> 00:03:00,920
Then we can shift to matters of policy.

66
00:03:00,920 --> 00:03:04,930
And in discussions of policy, we're trying to adjudicate questions about

67
00:03:04,930 --> 00:03:07,940
what we as a collective should do.

68
00:03:07,940 --> 00:03:11,540
In many cases, these are harder to decide, or at least different to

69
00:03:11,540 --> 00:03:15,810
decide, because we're dealing with the contingencies of the future.

70
00:03:15,810 --> 00:03:19,720
So here in the US, one of the debates about policy that we've had for a long

71
00:03:19,720 --> 00:03:24,200
time, hugely controversial, is what should the US do about health care,

72
00:03:24,200 --> 00:03:26,930
about health care costs, about health care coverage?

73
00:03:26,930 --> 00:03:29,510
This is a question about what should our policy be?

74
00:03:29,510 --> 00:03:33,420
What should the laws be that bind us as a collective, as

75
00:03:33,420 --> 00:03:35,420
US citizens, together?

76
00:03:35,420 --> 00:03:38,990
Here in the State of Washington, we had a policy debate around, what

77
00:03:38,990 --> 00:03:41,730
should we do about same-sex marriage?

78
00:03:41,730 --> 00:03:45,140
So these are policies that affect us in the State of Washington.

79
00:03:45,140 --> 00:03:48,270
But you have these outside of the sort of large issues.

80
00:03:48,270 --> 00:03:51,555
If your company is thinking about opening a new branch office, well,

81
00:03:51,555 --> 00:03:53,460
where should we put that branch office?

82
00:03:53,460 --> 00:03:57,560
Well, that's a serious consideration because it's a significant allocation

83
00:03:57,560 --> 00:03:58,640
of resources.

84
00:03:58,640 --> 00:04:01,490
But you're trying to make decisions that will affect what

85
00:04:01,490 --> 00:04:03,270
you do in the future.

86
00:04:03,270 --> 00:04:05,210
How should your organization raise awareness?

87
00:04:05,210 --> 00:04:07,040
You have to pick among campaigns.

88
00:04:07,040 --> 00:04:10,230
You're making a decision about what's going to happen in the future.

89
00:04:10,230 --> 00:04:10,990
So we've got fact.

90
00:04:10,990 --> 00:04:11,890
We've got policy.

91
00:04:11,890 --> 00:04:13,790
And we turn finally to value.

92
00:04:13,790 --> 00:04:19,810
Debates about value, questions of value, are asking what is good or bad?

93
00:04:19,810 --> 00:04:23,770
What is appropriate or inappropriate?

94
00:04:23,770 --> 00:04:26,270
And these can be difficult to adjudicate, because often they're

95
00:04:26,270 --> 00:04:28,530
dealing with personal or collective belief.

96
00:04:28,530 --> 00:04:32,700
So one of the big ones, is abortion moral or immoral?

97
00:04:32,700 --> 00:04:33,660
That's a huge question.

98
00:04:33,660 --> 00:04:35,420
But it's a value question.

99
00:04:35,420 --> 00:04:39,830
We can shift it into an aesthetic realm.

100
00:04:39,830 --> 00:04:40,730
Yeah, an aesthetic realm.

101
00:04:40,730 --> 00:04:42,790
Is Star Trek better than Star Wars?

102
00:04:42,790 --> 00:04:44,400
Well, you can have lots of debate over that.

103
00:04:44,400 --> 00:04:46,930
But we're talking in the realm of value.

104
00:04:46,930 --> 00:04:48,170
So fact, policy, and value.

105
00:04:48,170 --> 00:04:53,550
But of course, rarely is a single topic restricted to just one of those

106
00:04:53,550 --> 00:04:54,440
categories.

107
00:04:54,440 --> 00:04:57,140
Usually it's a mixture of all three.

108
00:04:57,140 --> 00:05:02,420
So we can turn to the idea of the debate around, how old is the earth?

109
00:05:02,420 --> 00:05:05,020
Well, scientists say 4.5 billion years.

110
00:05:05,020 --> 00:05:08,050
Young Earth creationists would say something more like 6,000 years.

111
00:05:08,050 --> 00:05:12,490
This is primarily a debate over fact.

112
00:05:12,490 --> 00:05:15,230
But certainly value is coming in there.

113
00:05:15,230 --> 00:05:19,430
Young Earth creationists are not necessarily coming to that independent

114
00:05:19,430 --> 00:05:22,700
of their values or their beliefs.

115
00:05:22,700 --> 00:05:28,400
Now that same question, the combination changes if the earth's age

116
00:05:28,400 --> 00:05:31,490
comes up in a discussion of public school textbooks.

117
00:05:31,490 --> 00:05:35,617
So if the question was, should public school textbooks date the earth at 4.5

118
00:05:35,617 --> 00:05:39,730
billion years, well, that's primarily a policy question.

119
00:05:39,730 --> 00:05:44,350
But it is deeply interwoven with those fact and value issues.

120
00:05:44,350 --> 00:05:47,930
And to the degree that people would argue over it, they're coming at it

121
00:05:47,930 --> 00:05:49,200
from various angles.

122
00:05:49,200 --> 00:05:52,620
Any one question might be more policy-oriented, fact-oriented,

123
00:05:52,620 --> 00:05:53,590
value-oriented.

124
00:05:53,590 --> 00:05:58,190
But overall, that debate is covering a lot of different territories.

125
00:05:58,190 --> 00:06:00,240
So let's take a look at another example.

126
00:06:00,240 --> 00:06:03,550
So here in the US, there are debates over government fuel standards.

127
00:06:03,550 --> 00:06:04,630
Well, that's a matter of policy.

128
00:06:04,630 --> 00:06:05,730
That's a matter of law.

129
00:06:05,730 --> 00:06:09,550
But these debates are very much linked to fact debates about the role of

130
00:06:09,550 --> 00:06:11,440
emissions in global climate change.

131
00:06:11,440 --> 00:06:16,100
And certainly with evaluative frameworks over environmentalism or

132
00:06:16,100 --> 00:06:17,280
industrialism.

133
00:06:17,280 --> 00:06:22,170
So you can't really pull that debate out of all three, but rather have to

134
00:06:22,170 --> 00:06:26,260
understand how individual points are circulating among those three

135
00:06:26,260 --> 00:06:28,720
different realms.

136
00:06:28,720 --> 00:06:30,350
The same thing affects much smaller issues.

137
00:06:30,350 --> 00:06:32,730
Here in the City of Seattle, there's always a debate about whether or not

138
00:06:32,730 --> 00:06:34,120
we should build more bike lanes.

139
00:06:34,120 --> 00:06:34,410
OK.

140
00:06:34,410 --> 00:06:37,060
So that's fact, policy, and value.

141
00:06:37,060 --> 00:06:39,270
And we deal with these questions all the time.

142
00:06:39,270 --> 00:06:42,780
Where should we go out for dinner is in essence a question that can be

143
00:06:42,780 --> 00:06:44,010
adjudicated through debate.

144
00:06:44,010 --> 00:06:46,930
And of course, this one is perhaps the most intractable of all.

145
00:06:46,930 --> 00:06:48,610
But it's a question about the future.

146
00:06:48,610 --> 00:06:49,290
Where should we go?

147
00:06:49,290 --> 00:06:50,040
That's policy.

148
00:06:50,040 --> 00:06:51,310
But what are you in the mood for?

149
00:06:51,310 --> 00:06:52,310
Well, I don't know.

150
00:06:52,310 --> 00:06:53,000
Fact.

151
00:06:53,000 --> 00:06:54,880
How good is that restaurant?

152
00:06:54,880 --> 00:06:56,300
Well, I heard it was quite good.

153
00:06:56,300 --> 00:06:58,720
Well, I heard it was quite bad.

154
00:06:58,720 --> 00:07:00,820
They had a health code violation.

155
00:07:00,820 --> 00:07:01,580
Debate over fact.

156
00:07:01,580 --> 00:07:02,450
No, they didn't.

157
00:07:02,450 --> 00:07:03,860
That's ridiculous.

158
00:07:03,860 --> 00:07:07,660
So these very small questions can also be understood through the lenses of

159
00:07:07,660 --> 00:07:09,350
fact, policy, and value.

160
00:07:09,350 --> 00:07:14,130
And what thinking through a debate with these lenses gets you is it helps

161
00:07:14,130 --> 00:07:16,490
you map the debate more closely.

162
00:07:16,490 --> 00:07:21,070
It helps you figure out where you and your audience disagree.

163
00:07:21,070 --> 00:07:23,270
It helps you find these clash points.

164
00:07:23,270 --> 00:07:27,400
And finding those clash points is hugely important if you're going to

165
00:07:27,400 --> 00:07:28,760
persuade that audience.

166
00:07:28,760 --> 00:07:31,440
So you can answer questions like, what values are they using?

167
00:07:31,440 --> 00:07:33,040
Or what aren't they talking about?

168
00:07:33,040 --> 00:07:35,880
That's a great opportunity to get an easy win.

169
00:07:35,880 --> 00:07:38,470
If they're not talking about something and it's important to the debate,

170
00:07:38,470 --> 00:07:42,390
maybe you can bring it up and be persuasive by doing so.

171
00:07:42,390 --> 00:07:44,690
What audience beliefs can you leave in place?

172
00:07:44,690 --> 00:07:47,710
Because remember, you're trying to figure out how to be persuasive.

173
00:07:47,710 --> 00:07:49,370
But you don't have to argue everything.

174
00:07:49,370 --> 00:07:52,950
So how can you maybe contain your argument so it's not bigger or more

175
00:07:52,950 --> 00:07:55,150
controversial than you need?

176
00:07:55,150 --> 00:07:57,970
So what I want you to do is just think through a topic that

177
00:07:57,970 --> 00:07:58,750
you're working on.

178
00:07:58,750 --> 00:08:01,890
And again, this can be the persuasive speech that you might do for this

179
00:08:01,890 --> 00:08:05,760
class or a speech that you have to give at work or at a civic

180
00:08:05,760 --> 00:08:07,800
organization, or the next speech you have to give.

181
00:08:07,800 --> 00:08:12,230
But think through that topic in terms of fact, policy, and value.

182
00:08:12,230 --> 00:08:16,410
If you have to persuade an audience and there's disagreement, where is

183
00:08:16,410 --> 00:08:17,160
that disagreement?

184
00:08:17,160 --> 00:08:19,760
What is the nature of that disagreement?

185
00:08:19,760 --> 00:08:23,490
And in the next lecture, we'll sort through some strategies for addressing

186
00:08:23,490 --> 00:08:26,080
these clash points in a persuasive manner.

187
00:08:26,080 --> 00:08:29,730
But before we figure out how to respond to these clash points, we got

188
00:08:29,730 --> 00:08:33,030
to begin by figuring out what these clash points actually are.

189
00:08:33,030 --> 00:08:34,409
That's what this lecture was about.

190
00:08:34,409 --> 00:08:37,740
And I'd like you to do that now in something that you're working on.

191
00:08:37,740 --> 00:08:38,990


