0
00:00:00,000 --> 00:00:00,870
https://youtu.be/NVLpNfeFNWo

1
00:00:00,870 --> 00:00:04,150
MATT MCGARRITY: Having spent a lot of time getting through the argumentative

2
00:00:04,150 --> 00:00:08,280
elements for your persuasive speech, I now want to turn to analyzing

3
00:00:08,280 --> 00:00:08,930
arrangement.

4
00:00:08,930 --> 00:00:12,170
Thinking about how you're going to put the speech together in a way that

5
00:00:12,170 --> 00:00:13,240
makes sense.

6
00:00:13,240 --> 00:00:15,390
And in the next lecture, I'm going to have you double check your

7
00:00:15,390 --> 00:00:19,630
arrangement, specifically with argument congruency in mind.

8
00:00:19,630 --> 00:00:25,770
But this speech is not as formally laid out as the impromptu and the

9
00:00:25,770 --> 00:00:26,760
informative speeches.

10
00:00:26,760 --> 00:00:30,880
There, clarity of arrangement was key.

11
00:00:30,880 --> 00:00:34,230
Here, we're more concerned with effect.

12
00:00:34,230 --> 00:00:38,390
Does the arrangement advance your goals in the speech?

13
00:00:38,390 --> 00:00:42,850
And in many cases, in a stylistically rich speech, some of that arrangement

14
00:00:42,850 --> 00:00:46,000
talk falls by the wayside.

15
00:00:46,000 --> 00:00:48,490
Not as a bad thing, but as a strategic choice.

16
00:00:48,490 --> 00:00:52,480
So regardless of how your speech is arranged, for this speech, your

17
00:00:52,480 --> 00:00:55,000
audience should be able to answer these questions.

18
00:00:55,000 --> 00:00:56,960
What are the ills?

19
00:00:56,960 --> 00:00:58,660
Who or what's to blame for these ills?

20
00:00:58,660 --> 00:01:00,150
What are the cures?

21
00:01:00,150 --> 00:01:03,550
And what can we do to help implement those cures?

22
00:01:03,550 --> 00:01:06,020
So you might have other aspects in there.

23
00:01:06,020 --> 00:01:10,760
You might have consequences, but at the bare minimum, I want your audience

24
00:01:10,760 --> 00:01:12,500
to be able to answer those questions.

25
00:01:12,500 --> 00:01:16,460
Those are really key points in your persuasive case.

26
00:01:16,460 --> 00:01:20,300
So I've got a couple of recommendations, suggestions, ideas

27
00:01:20,300 --> 00:01:24,040
about how you might arrange the main points in your speech.

28
00:01:24,040 --> 00:01:26,340
Now, what I'm going to show you here just because we don't have a whole

29
00:01:26,340 --> 00:01:30,700
bunch of space on the screen to my right, is I'm just going to show you

30
00:01:30,700 --> 00:01:31,730
the main points here.

31
00:01:31,730 --> 00:01:36,640
If you go to the web page, the weekly web page, I have a document there that

32
00:01:36,640 --> 00:01:40,225
shows these arrangements patterns with the main points as well as the sub

33
00:01:40,225 --> 00:01:44,500
points, so you have a richer understanding of what the sub points

34
00:01:44,500 --> 00:01:45,570
might actually look like.

35
00:01:45,570 --> 00:01:48,760
But these are just some ideas about how you might choose to arrange that

36
00:01:48,760 --> 00:01:50,200
persuasive case.

37
00:01:50,200 --> 00:01:52,370
So we'll start with ill, blame, cure.

38
00:01:52,370 --> 00:01:55,050
It's a straight up needs case.

39
00:01:55,050 --> 00:01:57,610
When we watched and listened to-- when we listened to.

40
00:01:57,610 --> 00:02:01,270
It was an audio clip, when we listen to that Obama's speech last week, this

41
00:02:01,270 --> 00:02:07,220
was the basic structure of his speech, ill, blame, cure.

42
00:02:07,220 --> 00:02:09,660
He had consequences in there as well.

43
00:02:09,660 --> 00:02:13,130
So in this hypothetical one, so people have argued for or against the

44
00:02:13,130 --> 00:02:15,880
educational package in the US called No Child Left Behind.

45
00:02:15,880 --> 00:02:18,170
So people would be able to argue ill.

46
00:02:18,170 --> 00:02:21,160
No Child Left Behind hurts our communities, and then

47
00:02:21,160 --> 00:02:21,770
they get into it.

48
00:02:21,770 --> 00:02:22,670
Well, why is it doing that?

49
00:02:22,670 --> 00:02:25,050
Well, No Child Left Behind is vague.

50
00:02:25,050 --> 00:02:27,510
And then finally, I'd say, well, so therefore, what do we do?

51
00:02:27,510 --> 00:02:29,490
Well, we have to change No Child Left Behind.

52
00:02:29,490 --> 00:02:33,300
And here, what you can do is you can develop a specific cure, and then it's

53
00:02:33,300 --> 00:02:34,690
related call to action.

54
00:02:34,690 --> 00:02:36,690
So we need to change the legislation.

55
00:02:36,690 --> 00:02:38,050
Contact your legislator.

56
00:02:38,050 --> 00:02:42,900
We need to support local school districts, here's how you can do it.

57
00:02:42,900 --> 00:02:44,500
Whatever you choose to do there.

58
00:02:44,500 --> 00:02:46,820
I'm not making an argument for or against No Child Left Behind.

59
00:02:46,820 --> 00:02:50,950
This is merely an example of one way in which you might organize that case.

60
00:02:50,950 --> 00:02:54,180
Now, in other cases, maybe you don't need blame or maybe you want to devote

61
00:02:54,180 --> 00:02:55,970
your attention elsewhere.

62
00:02:55,970 --> 00:03:00,740
So an argument that's made often here is we must protect our Second

63
00:03:00,740 --> 00:03:02,330
Amendment right to bear arms.

64
00:03:02,330 --> 00:03:06,280
So here the blame is not really all that necessary in the development of

65
00:03:06,280 --> 00:03:07,990
this motivational speech.

66
00:03:07,990 --> 00:03:11,520
The ill is gun restrictions threaten our rights and our lives.

67
00:03:11,520 --> 00:03:14,030
So that's a presence absence case.

68
00:03:14,030 --> 00:03:18,710
So if the presence of gun restrictions is what's at threat, the absence is

69
00:03:18,710 --> 00:03:20,270
kind of what's going to make it go away.

70
00:03:20,270 --> 00:03:22,650
So here you've got a pretty straightforward ill, cure.

71
00:03:22,650 --> 00:03:26,200
So gun restrictions threaten our rights, therefore we must defend our

72
00:03:26,200 --> 00:03:29,120
right to bare arms by not having these gun restrictions, and here's what you

73
00:03:29,120 --> 00:03:33,440
can do to help make sure that we don't have these burdensome onerous gun

74
00:03:33,440 --> 00:03:35,170
restrictions.

75
00:03:35,170 --> 00:03:38,000
By the way, actually, I take this and I use this as an example because I've

76
00:03:38,000 --> 00:03:41,400
had students run this speech plenty of times, both for and against gun

77
00:03:41,400 --> 00:03:42,310
restrictions.

78
00:03:42,310 --> 00:03:44,410
And one bears repeating.

79
00:03:44,410 --> 00:03:47,930
So when I do this speech here at the University of Washington, the students

80
00:03:47,930 --> 00:03:49,670
have to deliver it outside.

81
00:03:49,670 --> 00:03:53,050
So we've got a space in the middle of campus.

82
00:03:53,050 --> 00:03:57,340
We're an urban campus, so we've got a lot of people milling around.

83
00:03:57,340 --> 00:04:00,910
It's called Red Square, not the Red Square in Moscow but different one,

84
00:04:00,910 --> 00:04:03,230
and it's a good place for doing this.

85
00:04:03,230 --> 00:04:06,920
So every couple of months, my class is out there, hundreds of people are out

86
00:04:06,920 --> 00:04:10,000
there, declaiming, not all at once, but they're doing

87
00:04:10,000 --> 00:04:11,200
their speeches outside.

88
00:04:11,200 --> 00:04:14,130
And I really like it, especially in the spring, because we get lots of

89
00:04:14,130 --> 00:04:17,970
tourist groups that come through, and it's a beautiful campus.

90
00:04:17,970 --> 00:04:22,190
Well, one time, I had somebody basically making this case about we

91
00:04:22,190 --> 00:04:25,140
should not have gun restrictions.

92
00:04:25,140 --> 00:04:29,500
And one of his calls to action, by the way, was buy a gun and join the NRA.

93
00:04:29,500 --> 00:04:30,800
So I mean, he'd developed it.

94
00:04:30,800 --> 00:04:31,240
It was fine.

95
00:04:31,240 --> 00:04:32,200
It was a good speech.

96
00:04:32,200 --> 00:04:36,250
I was out there watching it, as I often do, and there was a huge tour

97
00:04:36,250 --> 00:04:39,690
group moving through, and they didn't know what was going on.

98
00:04:39,690 --> 00:04:43,460
So they're walking by and then they stop, and he's in front of the

99
00:04:43,460 --> 00:04:46,280
library, and he's got an audience and they just start taking pictures.

100
00:04:46,280 --> 00:04:49,600
And I'm watching and the whole time I'm thinking, this tourist group is

101
00:04:49,600 --> 00:04:53,220
going to go back, and they're going to say, those Americans,

102
00:04:53,220 --> 00:04:54,970
they love two things.

103
00:04:54,970 --> 00:04:58,600
Freedom of speech, because they're just always talking, and guns.

104
00:04:58,600 --> 00:05:00,590
They're talking about guns all the time.

105
00:05:00,590 --> 00:05:05,410
So I thought that was a great speech, but I do worry it gave that particular

106
00:05:05,410 --> 00:05:10,650
group of foreign visitors a slightly skewed understanding of what happens

107
00:05:10,650 --> 00:05:13,440
in the US generally, and at the University of Washington.

108
00:05:13,440 --> 00:05:16,530
Nevertheless, it's a good model for an advocacy speech.

109
00:05:16,530 --> 00:05:19,050
It's pretty straightforward, ill and cure.

110
00:05:19,050 --> 00:05:21,510
We can also talk to a motivated sequence.

111
00:05:21,510 --> 00:05:25,080
This has been something that's been kicked around in speech and the

112
00:05:25,080 --> 00:05:26,620
teaching of speech for a while.

113
00:05:26,620 --> 00:05:29,190
So maybe you've got an introduction that

114
00:05:29,190 --> 00:05:31,590
demonstrates, that gains attention.

115
00:05:31,590 --> 00:05:34,570
Once you've got that, then you'd prove need.

116
00:05:34,570 --> 00:05:37,710
We can talk about this as ill, it's often referred to as need.

117
00:05:37,710 --> 00:05:41,680
So in this case, arguing about getting advertisers out of public school

118
00:05:41,680 --> 00:05:45,780
classrooms, the need would be, commercial education hurts students.

119
00:05:45,780 --> 00:05:47,190
And then what do we need to do?

120
00:05:47,190 --> 00:05:49,390
Well, we need to kick advertisers out of the classroom.

121
00:05:49,390 --> 00:05:50,990
So there's a one-to-one correlation there.

122
00:05:50,990 --> 00:05:52,950
They're present, they need to be absent.

123
00:05:52,950 --> 00:05:56,200
What makes the motivated sequence different is then, we can think

124
00:05:56,200 --> 00:05:57,830
through what--

125
00:05:57,830 --> 00:06:01,740
being very explicit about, what would implementation look like.

126
00:06:01,740 --> 00:06:03,980
So you've got this visualization step.

127
00:06:03,980 --> 00:06:07,250
So you say, well, here's what, if we truly kicked-- in this case, if we

128
00:06:07,250 --> 00:06:10,820
truly kicked commercialized education out of classrooms, what would those

129
00:06:10,820 --> 00:06:11,640
classrooms look like?

130
00:06:11,640 --> 00:06:13,130
How would life be better?

131
00:06:13,130 --> 00:06:16,930
So you're just sort of drawing us a mental picture of what the world looks

132
00:06:16,930 --> 00:06:19,050
like once your cure is implemented.

133
00:06:19,050 --> 00:06:22,660
You can certainly think of a fairly famous speech that has a

134
00:06:22,660 --> 00:06:24,050
visualization step.

135
00:06:24,050 --> 00:06:27,180
It's almost as if he was talking about a dream.

136
00:06:27,180 --> 00:06:30,310
But I mean as part of I Have a Dream, you've got this very elaborate working

137
00:06:30,310 --> 00:06:34,770
up of what implementation looks like, that visualization step.

138
00:06:34,770 --> 00:06:37,540
And in this model, then you end with the call to action.

139
00:06:37,540 --> 00:06:38,730
And these are variable, right?

140
00:06:38,730 --> 00:06:41,570
You could swap these pieces around.

141
00:06:41,570 --> 00:06:44,090
You could have the call to action before visualization.

142
00:06:44,090 --> 00:06:46,950
But it's just a way of highlighting how you might want to think about

143
00:06:46,950 --> 00:06:51,090
writing and performing this picture of what the world looks like after your

144
00:06:51,090 --> 00:06:53,720
cure has been implemented.

145
00:06:53,720 --> 00:06:57,430
You can also think about sort of satisfying shared values.

146
00:06:57,430 --> 00:07:03,400
So every couple of years, if there's a nominee for the US Supreme Court,

147
00:07:03,400 --> 00:07:09,780
there's a debate over rules, and how the nomination process goes through.

148
00:07:09,780 --> 00:07:14,470
And this argument that you see here, in terms of arguing for against the

149
00:07:14,470 --> 00:07:17,510
nomination process, it's argued both by Republicans and

150
00:07:17,510 --> 00:07:18,960
Democrats here in the US.

151
00:07:18,960 --> 00:07:23,100
Most recently, it was by the Democrats, right?

152
00:07:23,100 --> 00:07:26,360
So they would start off by saying, well, we believe in fair hearings.

153
00:07:26,360 --> 00:07:29,160
Their statement of the shared value.

154
00:07:29,160 --> 00:07:31,820
Currently, this process is being violated.

155
00:07:31,820 --> 00:07:33,380
So you've got the ill, right?

156
00:07:33,380 --> 00:07:35,170
This ill is at risk.

157
00:07:35,170 --> 00:07:38,760
So we need to act to preserve our shared value, the cure.

158
00:07:38,760 --> 00:07:40,360
And now, here's what you can do.

159
00:07:40,360 --> 00:07:45,140
So it's an ill cure model, but instead of just talking generally about sort

160
00:07:45,140 --> 00:07:49,320
of the tangible issues, you're setting up the evaluative criteria you're

161
00:07:49,320 --> 00:07:51,750
going to use for discussion of this policy.

162
00:07:51,750 --> 00:07:55,920
In this case, one of our shared values are fair nominations.

163
00:07:55,920 --> 00:07:59,330
Finally, one thing you might consider, if you are running counter-arguments,

164
00:07:59,330 --> 00:08:01,530
is thinking about how you're going to build that in.

165
00:08:01,530 --> 00:08:05,380
So here, you could start off by saying, in this case, we're talking

166
00:08:05,380 --> 00:08:06,460
about nuclear energy.

167
00:08:06,460 --> 00:08:08,900
Opponents of nuclear energy are worried about this.

168
00:08:08,900 --> 00:08:13,100
Then you've got your counter-argument responding to those concerns about

169
00:08:13,100 --> 00:08:14,240
nuclear energy.

170
00:08:14,240 --> 00:08:17,470
Then you've got an ill, well, right now, we're missing out on all the

171
00:08:17,470 --> 00:08:21,480
benefits of nuclear energy, and then you can build in that cure and call to

172
00:08:21,480 --> 00:08:23,740
action in one step.

173
00:08:23,740 --> 00:08:26,235
So these are just some ideas for arranging your speech in

174
00:08:26,235 --> 00:08:27,370
a persuasive way.

175
00:08:27,370 --> 00:08:31,740
And if you haven't already, go ahead and try to outline a basic argument

176
00:08:31,740 --> 00:08:32,940
for your speech.

177
00:08:32,940 --> 00:08:36,350
And this could be for this assignment or it could be another related speech,

178
00:08:36,350 --> 00:08:40,299
but regardless, your audience should be able to answer at the end of that

179
00:08:40,299 --> 00:08:42,169
speech, what are the ills?

180
00:08:42,169 --> 00:08:43,610
Who or what's to blame for these ills?

181
00:08:43,610 --> 00:08:44,470
What are the cures?

182
00:08:44,470 --> 00:08:46,770
And what can we do to help implement the cures?

183
00:08:46,770 --> 00:08:49,500
So I want you to get that in order because in the next lecture, we're

184
00:08:49,500 --> 00:08:52,700
going to be checking that outline, checking that argument, for

185
00:08:52,700 --> 00:08:53,950
congruency.

186
00:08:53,950 --> 00:08:54,367


