1
00:00:17,199 --> 00:00:22,699
https://youtu.be/8a3Pcc4ojiA
What about ignorance can you take away from
this first five week course that will help

2
00:00:22,699 --> 00:00:28,759
you in everyday life? One of the most important
and useful things is being able to recognize

3
00:00:28,759 --> 00:00:35,180
when ignorance may be good or bad for you,
or for other people, or both. I'm not claiming

4
00:00:35,180 --> 00:00:39,800
that this always will be clear, and of course
ignorance that benefits one person may harm

5
00:00:39,800 --> 00:00:45,519
another. I am saying that by now, you should
have the concepts and mental pathways to be

6
00:00:45,519 --> 00:00:51,689
able to judiciously decide when ignorance
may be beneficial, harmful, or neither. So

7
00:00:51,689 --> 00:00:57,170
I am going to review what we've covered in
this first five week course that will help

8
00:00:57,170 --> 00:01:01,180
you make this kind of decision whenever you
need to.

9
00:01:01,180 --> 00:01:07,009
By now, it should be clear that being aware
of what you don't know generally is a good

10
00:01:07,009 --> 00:01:13,350
thing. We know a lot less than we like to
think we do, and being aware of what we don't

11
00:01:13,350 --> 00:01:18,170
know puts us in a position where we can decide
whether we want to eliminate particular unknowns

12
00:01:18,170 --> 00:01:21,740
or not.
We also have seen that there are different

13
00:01:21,740 --> 00:01:28,530
kinds of ignorance, and that knowing this
can help us decide how to deal with ignorance.

14
00:01:28,530 --> 00:01:35,530
One of the most important distinctions is
between things we can know, at least in principle,

15
00:01:35,840 --> 00:01:41,670
and those we cannot know. It is futile to
try to know the unknowable. But we also saw

16
00:01:41,670 --> 00:01:46,639
in week 5 that there are situations where
it is futile to reduce ignorance even when

17
00:01:46,639 --> 00:01:51,619
it is possible to do so.
Knowing what kinds of unknowns there are in

18
00:01:51,619 --> 00:01:57,179
our environment helps us to devise effective
ways of dealing with them. This is one of

19
00:01:57,179 --> 00:02:03,119
the things that the Honey Bee and Investor
games were intended to convey. You could play

20
00:02:03,119 --> 00:02:10,000
each game better if you know something about
the kind of unknowns built into it. That goes

21
00:02:10,000 --> 00:02:15,450
for real life too. It's one thing to be making
decisions when you know all the possible outcomes

22
00:02:15,450 --> 00:02:21,810
but are merely unsure about how likely each
one is to occur, but it's quite another if

23
00:02:21,810 --> 00:02:27,879
you don't know what all the outcomes are.
In the first week, we also saw that when people

24
00:02:27,879 --> 00:02:33,010
think about ignorance, people generally
do so with negative metaphors and words that

25
00:02:33,010 --> 00:02:40,010
have negative connotations. There is widespread
blindness to the very idea that there could

26
00:02:40,400 --> 00:02:46,670
be such a thing as good ignorance. But you
now know that there is. And that opens up

27
00:02:46,670 --> 00:02:51,400
the possibility of deciding which unknowns
you'd like to have and which you'd like to

28
00:02:51,400 --> 00:02:56,269
be rid of.
To begin with, you can examine your own motives

29
00:02:56,269 --> 00:03:02,500
for knowing or not knowing, and the uses that
you have for ignorance. In the second week,

30
00:03:02,500 --> 00:03:08,110
we found that there are plenty of things we'd
rather not know temporarily, and these underpin

31
00:03:08,110 --> 00:03:14,540
a great deal of our entertainment, motivations
for learning, avenues for creativity, and

32
00:03:14,540 --> 00:03:19,930
our sense of freedom and self-determination.
We also saw that there are things we never

33
00:03:19,930 --> 00:03:24,909
want to know, in some cases because they don't
matter to us, but in other cases because they

34
00:03:24,909 --> 00:03:30,510
matter too much for us to be able to confront
them. We even encountered the idea that finding

35
00:03:30,510 --> 00:03:36,670
out more about pleasant surprises can reduce
our pleasure in them. In the third week, we

36
00:03:36,670 --> 00:03:43,159
also saw that our own cognitive biases, preferences,
and the habits that result from them bind

37
00:03:43,159 --> 00:03:49,219
us and our associates into a kind of comfortable,
shared ignorance.

38
00:03:49,219 --> 00:03:54,390
Some of these motivations and reactions to
ignorance may involve conscious choices, but

39
00:03:54,390 --> 00:04:00,280
many of them typically are defaults that most
people do not actively choose. Now that you're

40
00:04:00,280 --> 00:04:04,840
aware of them, you are in a better position
to make mindful choices about what you would

41
00:04:04,840 --> 00:04:09,590
like to know or not know.
You can also make choices about ignorance

42
00:04:09,590 --> 00:04:14,389
based on what you've learned about its roles
in society and culture, and the uses that

43
00:04:14,389 --> 00:04:19,739
you and others may have for ignorance. In
the second and third weeks, we moved into

44
00:04:19,739 --> 00:04:26,739
the social realm and found plenty of uses
for ignorance there. First and foremost are

45
00:04:26,880 --> 00:04:33,880
ignorance agreements, often in the form of
a social norm but sometimes enshrined in law.

46
00:04:33,980 --> 00:04:40,110
We saw that confidentiality, privacy, taboos,
politeness, and organised specialised knowledge

47
00:04:40,110 --> 00:04:45,540
all are based on socially mandated ignorance
arrangements. Certain kinds of relationships,

48
00:04:45,540 --> 00:04:50,970
such as those based on trust, also require
ignorance arrangements. We saw that there

49
00:04:50,970 --> 00:04:57,790
are even situations where outright lying is
mandated, such as competitive sports or war.

50
00:04:57,790 --> 00:05:04,590
There is indeed such a thing as virtuous ignorance.
Debates about whether ignorance is good or

51
00:05:04,590 --> 00:05:09,610
bad--and for whom-- turn out to be central
to some of the most important decisions of

52
00:05:09,610 --> 00:05:16,460
our time, as in whether to pursue certain
scientific and technological developments.

53
00:05:16,460 --> 00:05:22,940
In week 5 we learned a few more things about
potential benefits from ignorance. First,

54
00:05:22,940 --> 00:05:27,620
we saw examples of how more information can
actually make us worse at predicting and decision

55
00:05:27,620 --> 00:05:33,440
making. We also learned about the conditions
in which seeking greater certainty and predictive

56
00:05:33,440 --> 00:05:39,560
accuracy doesn't pay off. The key lesson there
was not to bother obtaining information that

57
00:05:39,560 --> 00:05:44,760
is irrelevant to your purposes.
Moreover, vagueness and ambiguity turn out

58
00:05:44,760 --> 00:05:50,840
to earn their keep by affording us a justifiable
"no bet" option in situations where it would

59
00:05:50,840 --> 00:05:56,970
be foolhardy to bet or decide one way or the
other. And last, but certainly not least,

60
00:05:56,970 --> 00:06:02,300
in our interviews with jazz musician John
Mackey back in week 2 and art historian Sasha

61
00:06:02,300 --> 00:06:07,710
Grishin in week 5, we got a glimpse of the
fundamental roles that unknowns play in creative

62
00:06:07,710 --> 00:06:13,400
work. So, there are situations and goals for
which some kinds of ignorance can serve us

63
00:06:13,400 --> 00:06:20,400
well, whereas premature decisiveness or insistence
on certainty may be counter-productive.

64
00:06:21,650 --> 00:06:27,410
At various points in the course, we've investigated
some of the tradeoffs that we make regarding

65
00:06:27,410 --> 00:06:33,340
ignorance. For instance, we saw that people
generally regard ignorance arising from conflicting

66
00:06:33,340 --> 00:06:40,250
information as worse than ignorance arising
from informationally equivalent ambiguous

67
00:06:40,250 --> 00:06:46,940
information. So, one kind of ignorance may
be worse than another, and it may be possible

68
00:06:46,940 --> 00:06:53,710
to trade one for the other. For instance,
in a group trying to achieve a workable consensus,

69
00:06:53,710 --> 00:06:59,540
it may be best to allow some ambiguity in
the consensus to avoid conflict.

70
00:06:59,540 --> 00:07:05,940
A related tradeoff theme that cropped up in
week 5 is the notion that one kind of mistake

71
00:07:05,940 --> 00:07:11,750
may be preferable to another kind. Let's push
this idea a bit further along, with the help

72
00:07:11,750 --> 00:07:18,750
of a 2013 opinion piece in the journal Trends
in Ecology and Evolution, written by a multidisciplinary

73
00:07:19,320 --> 00:07:24,670
set of authors. The research reviewed in this
article documents a widespread tendency for

74
00:07:24,670 --> 00:07:31,670
animals, including humans, to be prone to
one kind of error (say, a false positive)

75
00:07:32,050 --> 00:07:37,000
over its opposite counterpart (a false negative).
For instance, it may be more adaptive for

76
00:07:37,000 --> 00:07:42,220
prey to over-estimate the likelihood of a
predator attack than to under-estimate it,

77
00:07:42,220 --> 00:07:47,310
even if overestimation temporarily inhibits
the prey's foraging for food.

78
00:07:47,310 --> 00:07:51,060
We can, and do, set up this kind of bias to
our benefit even though it may be irritating

79
00:07:51,060 --> 00:07:56,360
in the short term, and you can find plenty
of examples in domains ranging from engineering

80
00:07:56,360 --> 00:08:02,750
to law to medicine. Smoke alarms, for example,
are deliberately set to frequently deliver

81
00:08:02,750 --> 00:08:09,380
a false positive, such as when you burn the
toast, but also to very reliably go off when

82
00:08:09,380 --> 00:08:14,440
there is a real fire. We don't like it when
they sound a false alarm, but we depend on

83
00:08:14,440 --> 00:08:19,610
them to save our lives if a fire starts in
the home when we and our family are asleep.

84
00:08:19,610 --> 00:08:26,180
In a 1980 interview about the prospects for
world peace, sociologist Elise Boulding was

85
00:08:26,180 --> 00:08:31,830
asked how we should think about security.
She replied, "In the broadest sense of the

86
00:08:31,830 --> 00:08:37,579
word, a certain level of insecurity is part
of the human condition. To be able to function

87
00:08:37,579 --> 00:08:43,269
and live amid uncertainty -- that's a clinical
definition of sanity." In this course, we've

88
00:08:43,269 --> 00:08:47,820
attempted to provide concepts and ways of
thinking about ignorance that enable us to

89
00:08:47,820 --> 00:08:54,820
have a sane approach to living and functioning
amid ignorance. In Ignorance 2, the next course,

90
00:08:54,900 --> 00:08:59,410
we'll investigate various methods for doing
so. Some of these methods have emerged out

91
00:08:59,410 --> 00:09:06,210
of professions such as medicine and engineering.
Others are hard-wired into our brains. Still

92
00:09:06,210 --> 00:09:12,830
others are matters of social or cultural practices
and convention. All of them revolve around

93
00:09:12,830 --> 00:09:17,610
one of the central questions of the human
condition: How can we best deal with situations

94
00:09:17,610 --> 00:09:24,080
where we must make choices but know very little?
That's the guiding topic for Ignorance 2.

