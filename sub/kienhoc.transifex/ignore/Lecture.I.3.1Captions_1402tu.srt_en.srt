1
00:00:17,850 --> 00:00:22,690
https://youtu.be/RS2KPkziRt8
This week, we're going to delve further into
the question of where our ignorance comes

2
00:00:22,690 --> 00:00:29,690
from. We'll examine how individuals, groups,
institutions, and governments strategically

3
00:00:29,920 --> 00:00:36,910
create and manipulate ignorance. There's plenty
of material there for the most avid conspiracy

4
00:00:36,910 --> 00:00:41,980
theorists among you. But we're also going
to tap into the ways in which ignorance gets

5
00:00:41,980 --> 00:00:48,980
constructed inadvertently, as we individually
and collectively go about our ordinary activities,

6
00:00:49,100 --> 00:00:55,670
exercise our preferences, and think our everyday
thoughts. You may find that accidental ignorance

7
00:00:55,670 --> 00:00:59,530
is even more intriguing than purpose-built
ignorance.

8
00:00:59,530 --> 00:01:05,089
For the first three lectures this week, starting
with this one, I'm going to present material

9
00:01:05,089 --> 00:01:11,880
on the ways in which ignorance is deliberately
created and maintained via political and social

10
00:01:11,880 --> 00:01:17,320
processes. The fourth and fifth lectures will
explore ways in which ignorance is implicitly

11
00:01:17,320 --> 00:01:24,320
or inadvertently generated or maintained via
culture, preferences, and social norms. The

12
00:01:25,270 --> 00:01:29,700
sixth, final lecture will examine the question
of whether ignorance can be thought of as

13
00:01:29,700 --> 00:01:35,859
a "public problem" and, if so, whether there
are any solutions for it.

14
00:01:35,859 --> 00:01:42,329
In addition to withholding information, proliferating
disinformation, and inhibiting curiosity,

15
00:01:42,329 --> 00:01:47,700
there's another way we can impose ignorance
on others, and that's by undoing their knowledge

16
00:01:47,700 --> 00:01:52,939
and sowing doubt. We can convince people that
what they thought they knew they don't really

17
00:01:52,939 --> 00:01:58,960
know. We can create uncertainty or doubt where
there wasn't any, or we can amplify existing

18
00:01:58,960 --> 00:02:05,369
doubts. The manufacture of doubt turns out
to be a widely practiced stratagem, especially

19
00:02:05,369 --> 00:02:10,979
in politically-charged topics.
In order for seeding doubts to have the desired

20
00:02:10,979 --> 00:02:16,510
effect, it has to be acceptable to raise them
in the first place. In some religious or political

21
00:02:16,510 --> 00:02:22,170
settings, for example, raising doubts about
fundamental beliefs or values is regarded

22
00:02:22,170 --> 00:02:28,990
as heresy and therefore impermissible. In
other settings, raising doubts is the norm.

23
00:02:28,990 --> 00:02:33,880
At first glance, social norms advocating this
may seem scarce, but it's a matter of knowing

24
00:02:33,880 --> 00:02:39,090
where to look. Criminal trials in Western
courts of law are one example. A defendant

25
00:02:39,090 --> 00:02:44,790
is to be convicted only if guilt can be demonstrated
beyond reasonable doubt, so the primary job

26
00:02:44,790 --> 00:02:51,130
of the defense is to raise doubts about the
defendant's guilt. Another example is in communities

27
00:02:51,130 --> 00:02:57,040
of scientists and scholars, where ideals of
informed skepticism and critique can dominate

28
00:02:57,040 --> 00:03:02,380
so that any offering of new knowledge must
pass trials-by-fire of intense scrutiny and

29
00:03:02,380 --> 00:03:07,390
counter-argumentation by experts before it
is published.

30
00:03:07,390 --> 00:03:12,930
These ideals and norms can, of course, be
utilized for political ends. In his 1995 book

31
00:03:12,930 --> 00:03:17,880
"Cancer Wars", Robert Proctor documented the
influences of professional, economic, and

32
00:03:17,880 --> 00:03:23,100
political interest groups on American governmental
priorities and funding of cancer research.

33
00:03:23,100 --> 00:03:28,980
One of his primary findings was that the American
government collaborated with private enterprise

34
00:03:28,980 --> 00:03:35,060
in generating doubt about the environmental
and industrial causes of cancer.

35
00:03:35,060 --> 00:03:40,570
David Michaels' 2005 article in "Scientific
American" and his 2008 book on the manufacture

36
00:03:40,570 --> 00:03:46,110
of doubt followed Proctor's lead. He identified
three primary messages orchestrated by the

37
00:03:46,110 --> 00:03:53,100
tobacco industry to challenge the scientific
consensus linking smoking with lung cancer.

38
00:03:53,100 --> 00:03:59,630
First, argue that cause-effect relationships
have not been established. Second, claim that

39
00:03:59,630 --> 00:04:06,570
statistical analyses are inconclusive. Third,
emphasize that more research is needed before

40
00:04:06,570 --> 00:04:13,000
laws or policies can be adequately justified.
This industry hired its own scientists, founded

41
00:04:13,000 --> 00:04:18,180
its own research publication ("Tobacco and
Health Research"), and carefully orchestrated

42
00:04:18,180 --> 00:04:25,180
a media campaign to spread their messages.
More recently, Naomi Oreskes and Erik Conway's

43
00:04:25,560 --> 00:04:32,560
2010 book on similar themes appeared, updated
to include accounts of how doubts were manufactured

44
00:04:33,310 --> 00:04:39,870
concerning climate change and global warming
in particular by organizations employing tactics

45
00:04:39,870 --> 00:04:46,620
inspired by the tobacco industry's example.
Frederick Seitz, a former president of the

46
00:04:46,620 --> 00:04:53,050
National Academy of Sciences, was hired by
the R. J. Reynolds Tobacco Company to direct

47
00:04:53,050 --> 00:05:00,050
their Medical Research Committee. Seitz distributed
$45 million in research grants to projects

48
00:05:01,130 --> 00:05:07,380
designed to promote tobacco and therefore
steering clear of anything that might impugn

49
00:05:07,380 --> 00:05:14,380
tobacco. In 1984 Seitz, Robert Jastrow and
William Nierenberg founded the George C. Marshall

50
00:05:14,970 --> 00:05:20,150
Institute, which then applied Tobacco Institute
tactics of doubt-mongering to the issue of

51
00:05:20,150 --> 00:05:25,910
climate change. They claimed that global warming
was caused by natural variations in solar

52
00:05:25,910 --> 00:05:32,910
flux, and that any warming caused by greenhouse
emissions is swamped by natural climate variations.

53
00:05:33,260 --> 00:05:38,630
The Marshall Institute on its Web site claims
even today that there is no certainty about

54
00:05:38,630 --> 00:05:44,370
the extent of human-caused climate change.
Oreskes and Conway documented an elaborate

55
00:05:44,370 --> 00:05:50,050
political and economic network of climate
denialist scientists, with links to well-endowed

56
00:05:50,050 --> 00:05:55,820
"think tanks" such as the Heritage Foundation,
the American Enterprise Institute and the

57
00:05:55,820 --> 00:06:02,710
Competitive Enterprise Institute, and financial
aid from trade associations such as the Electric

58
00:06:02,710 --> 00:06:08,510
Power Research Institute, the Global Climate
Coalition and the Tobacco Institute.

59
00:06:08,510 --> 00:06:14,450
I won't go into further details of doubt-inducing
tactics here; the sources I've mentioned do

60
00:06:14,450 --> 00:06:19,940
an excellent job on that topic. Instead, I
want to focus on an issue that supplements

61
00:06:19,940 --> 00:06:26,070
the material covered by those sources.
Machiavellian scheming and normative skepticism

62
00:06:26,070 --> 00:06:32,280
are not the only producers of doubt. Doubt
also can be an unintended by-product of debate

63
00:06:32,280 --> 00:06:38,180
or balanced coverage of an issue. Journalists
have been taken to task recently for giving

64
00:06:38,180 --> 00:06:43,240
equal time to global warming disbelievers,
on grounds that the scientific consensus is

65
00:06:43,240 --> 00:06:50,240
so strong that lending credibility to disbelievers
does the public a disservice. Holly Stocking

66
00:06:50,340 --> 00:06:55,930
and Lisa Holstein's 2009 paper presented a
case study of the media coverage of a controversy

67
00:06:55,930 --> 00:07:01,270
following the rapid growth of industrial hog
production in North Carolina during the 1980's

68
00:07:01,270 --> 00:07:06,919
and 1990's. Their chief interest was journalists'
responses to various attempts by the North

69
00:07:06,919 --> 00:07:13,139
Carolina Pork Council to discredit and discourage
a University of North Carolina public health

70
00:07:13,139 --> 00:07:20,139
scientist's research regarding health and
environmental problems arising from hog production.

71
00:07:20,900 --> 00:07:26,139
Stocking and Holstein related four kinds of
journalists' professional orientations to

72
00:07:26,139 --> 00:07:31,139
the ways in which they treat conflicting views
in scientific controversies.

73
00:07:31,139 --> 00:07:38,139
First, there is the journalist as disseminator,
who is interested in ascertaining facts and

74
00:07:38,449 --> 00:07:44,550
getting them to the public quickly. All viewpoints
are to be presented impartially, regardless

75
00:07:44,550 --> 00:07:49,680
of any differences in credibility or status.
It is up to the public to sift through the

76
00:07:49,680 --> 00:07:54,520
competing views and decide which are plausible
and which not.

77
00:07:54,520 --> 00:07:59,610
Second, there is the journalist whose goal
is investigating deeper interpretations behind

78
00:07:59,610 --> 00:08:05,669
the facts and providing useful context. This
stance requires that the journalist make some

79
00:08:05,669 --> 00:08:11,100
independent judgments about what is credible
or reasonable and what is not.

80
00:08:11,100 --> 00:08:18,100
Third, there is the populist mobilizer: Giving
a voice to the public and influencing political

81
00:08:18,360 --> 00:08:24,400
agendas. Again, this orientation entails some
independent judgments on the part of the journalist,

82
00:08:24,400 --> 00:08:29,060
especially concerning what the public needs
to know.

83
00:08:29,060 --> 00:08:35,440
Fourth, there is the adversarial journalist:
Maintaining vigilance and skepticism of public

84
00:08:35,440 --> 00:08:41,139
officials and special interest groups. This
role involves uncovering hidden interests

85
00:08:41,139 --> 00:08:47,440
served by public pronouncements or silences
in scientific controversies.

86
00:08:47,440 --> 00:08:51,619
The Disseminator and Adversarial roles are
the most likely to raise doubts, but they

87
00:08:51,619 --> 00:08:57,009
do so in different ways. The Disseminator's
pursuit of even-handedness can lend weight

88
00:08:57,009 --> 00:09:03,100
to views that in other forums would be completely
discredited. The Adversarial journalist, on

89
00:09:03,100 --> 00:09:09,180
the other hand, is more likely to raise moral
doubts. For example, are the experts truly

90
00:09:09,180 --> 00:09:15,449
impartial about the evidence? Do they have
vested interests of their own?

91
00:09:15,449 --> 00:09:19,800
Perhaps the most interesting finding in the
Stocking and Holstein article was that journalists

92
00:09:19,800 --> 00:09:25,410
with a high degree of scientific literacy
were less likely to follow the equal-coverage

93
00:09:25,410 --> 00:09:31,059
rule-of-thumb and more inclined to evaluate
the various claims and counter-claims, in

94
00:09:31,059 --> 00:09:37,230
most cases coming out in support of the scientists.
An implication is that the equal-coverage

95
00:09:37,230 --> 00:09:44,110
rule also may function as a let-out for journalists
who are ignorant about the science concerned.

96
00:09:44,110 --> 00:09:49,069
In their study of American media, Max and
Jules Boykoff found that more than half of

97
00:09:49,069 --> 00:09:56,059
all stories on global warming from 1988 through
2002 gave equal time to climate denialists,

98
00:09:56,059 --> 00:10:02,290
with another 35 percent giving time to them
while recognizing the consensus view. These

99
00:10:02,290 --> 00:10:09,199
journalists' uncertainties were then transmitted,
wittingly or not, to their audiences.

100
00:10:09,199 --> 00:10:13,079
This lecture has focused on the manufacture
of doubt as a way of undoing knowledge and

101
00:10:13,079 --> 00:10:17,959
thereby generating ignorance. We have seen
examples of how this may be done deliberately

102
00:10:17,959 --> 00:10:24,819
and strategically, but also how it may be
done inadvertently, even in the service of

103
00:10:24,819 --> 00:10:30,360
a laudable aim such as balanced coverage of
controversies by the news media. The next

104
00:10:30,360 --> 00:10:36,449
lecture will broaden the scope of this theme
by examining other kinds of strategic ignorance.

