1
00:00:00,000 --> 00:00:00,500
https://youtu.be/6dmbhykpH7k 

2
00:00:19,029 --> 00:00:23,539
Throughout this week we have examined how
ignorance is constructed in ways that involve

3
00:00:23,539 --> 00:00:30,050
deliberate actions, tactics, and strategies.
This is a standard version of "social construction",

4
00:00:30,050 --> 00:00:36,120
whereby various agents use their power to
create unknowns and impose them on others.

5
00:00:36,120 --> 00:00:40,940
But there's another kind of social construction
process that implicitly produces ignorance

6
00:00:40,940 --> 00:00:47,070
as a largely unintended by-product. In this
lecture, we're going to investigate the ways

7
00:00:47,070 --> 00:00:54,059
in which our own preferences and social inclinations
inadvertently combine with those of the others

8
00:00:54,059 --> 00:01:00,449
around us to generate shared, collective ignorance.
This is an important source of ignorance,

9
00:01:00,449 --> 00:01:06,490
because we're mostly blind to it (and that
goes for me too). However, we can gain some

10
00:01:06,490 --> 00:01:12,380
insights into how it happens and what can
be done about it.

11
00:01:12,380 --> 00:01:18,460
This type of implicit ignorance construction
proceeds in two steps. First, our preferences

12
00:01:18,460 --> 00:01:25,240
generate habits that constrain our experiences
and therefore the span of our knowledge. Second,

13
00:01:25,240 --> 00:01:31,030
we tend to associate with other people whose
preferences, habits, and experiences are similar

14
00:01:31,030 --> 00:01:38,030
to our own, so our friends, workmates, and
family are unlikely to fundamentally transform

15
00:01:38,380 --> 00:01:44,240
our knowledge-base. And so we, along with
our friends, workmates, and families, become

16
00:01:44,240 --> 00:01:50,130
locked into a self-reinforcing cell of shared,
collective ignorance.

17
00:01:50,130 --> 00:01:55,299
This two-step process manifests itself in
many different ways, most of which seem obvious

18
00:01:55,299 --> 00:02:00,520
when they are pointed out. However, what clearly
is not obvious to most of us is that this

19
00:02:00,520 --> 00:02:06,219
process takes place even when we don't want
it to happen, and personal freedoms of choice

20
00:02:06,219 --> 00:02:12,010
actually make it more likely to happen. Now,
this kind of collective ignorance may or may

21
00:02:12,010 --> 00:02:16,230
not be adaptive, so while we're investigating
how it happens we want to maintain an open

22
00:02:16,230 --> 00:02:23,230
mind about whether it's good or bad for us.
Let's begin with the first of the two stages,

23
00:02:23,810 --> 00:02:29,379
namely those individual heuristics and preferences
that "narrow the mind" when it comes to the

24
00:02:29,379 --> 00:02:35,269
choices we make. We prefer things, places,
activities, and people that are familiar to

25
00:02:35,269 --> 00:02:41,450
us. In other words, we develop habits. Familiarity
makes us comfortable, and this tendency is

26
00:02:41,450 --> 00:02:46,599
known as the "status quo bias". Unfamiliar
things are perceived as risky, and they require

27
00:02:46,599 --> 00:02:51,670
greater cognitive and emotional effort to
deal with. Familiarity and habits save us

28
00:02:51,670 --> 00:02:57,739
time, effort, and worry. But they also limit
our exposure to new experiences or ideas.

29
00:02:57,739 --> 00:03:01,629
If you like hip-hop music, you'll know a lot
about it and it will be an important musical

30
00:03:01,629 --> 00:03:07,260
habit, but it's unlikely that you'll try listening
to Gregorian chant, acid jazz, a symphony

31
00:03:07,260 --> 00:03:11,450
by Bruckner, a Rossini opera, or a ballad
by John Coltrane.

32
00:03:11,450 --> 00:03:17,510
Moreover, given a choice between two alternatives,
one that's familiar to us and one that's unfamiliar,

33
00:03:17,510 --> 00:03:23,200
we'll usually choose the familiar one. This
is known as the "recognition heuristic". As

34
00:03:23,200 --> 00:03:27,140
we'll see in a later lecture, this heuristic
actually can serve us well because it piggybacks

35
00:03:27,140 --> 00:03:32,439
on structures in our environment that enable
us to make relatively good choices even in

36
00:03:32,439 --> 00:03:38,230
situations where many of the alternatives
are unfamiliar to us. But for now, we're just

37
00:03:38,230 --> 00:03:43,540
focusing on the fact that the recognition
heuristic keeps us from finding out more about

38
00:03:43,540 --> 00:03:48,950
those unrecognized options, because they're
the ones we don't choose.

39
00:03:48,950 --> 00:03:54,120
We also tend to seek out, pay more attention
to, and remember more accurately information

40
00:03:54,120 --> 00:03:59,989
that confirms what we already believe. This
is known as "confirmation bias" and, like

41
00:03:59,989 --> 00:04:06,079
most biases, operates largely subconsciously.
The psychological function being satisfied

42
00:04:06,079 --> 00:04:11,219
here is the desire to be right. You can find
the most obvious examples if you recall a

43
00:04:11,219 --> 00:04:16,250
recent occasion on which someone challenged
your belief about something. Probably the

44
00:04:16,250 --> 00:04:20,870
first thing your brain did was to search your
memory for evidence and arguments to support

45
00:04:20,870 --> 00:04:26,300
your position. It is very unlikely that your
brain began searching for evidence that could

46
00:04:26,300 --> 00:04:32,060
support your challenger.
But confirmation bias also operates in subtle

47
00:04:32,060 --> 00:04:38,320
ways. Even if we're testing a hypothesis,
something we don't even believe yet but want

48
00:04:38,320 --> 00:04:45,060
to find out about, we fall prey to confirmation
bias. We use what's called a "positive test"

49
00:04:45,060 --> 00:04:50,400
strategy, which means we look for outcomes
we would expect if the hypothesis were true,

50
00:04:50,400 --> 00:04:57,259
rather than looking for outcomes that would
disconfirm the hypothesis. Peter Wason famously

51
00:04:57,259 --> 00:05:02,880
came up with a simple exercise in logic that
illustrates this tendency. Here are four cards,

52
00:05:02,880 --> 00:05:08,419
each with a letter on one side and a number
on the other side. Wason asks us the following

53
00:05:08,419 --> 00:05:13,740
question: If we want to test the hypothesis
that "if there is a vowel on one side, then

54
00:05:13,740 --> 00:05:18,970
there is an even number on the other side",
which card or cards are necessary to turn

55
00:05:18,970 --> 00:05:25,580
over to test this hypothesis? Take a moment
or two to think about your answer.

56
00:05:25,580 --> 00:05:30,139
Most of us choose the card with the vowel,
in this case the letter "A". Many of us also

57
00:05:30,139 --> 00:05:35,210
would choose the card with the even number,
"2". Few of us would choose the card with

58
00:05:35,210 --> 00:05:40,630
"7". But that's the one card that could disconfirm
the hypothesis, if it had a vowel on the other

59
00:05:40,630 --> 00:05:45,160
side. Remember, the hypothesis is that "if
there is a vowel on one side, then there is

60
00:05:45,160 --> 00:05:49,539
an even number on the other side", not "if
there is an even number on one side, there

61
00:05:49,539 --> 00:05:54,250
is a vowel on the other side." A card with
a vowel on one side and 7, or any other odd

62
00:05:54,250 --> 00:05:59,979
number, on the other side would falsify the
hypothesis, whereas a card with an even number

63
00:05:59,979 --> 00:06:05,800
on one side and a consonant on the other would
not falsify it. So we need to turn over the

64
00:06:05,800 --> 00:06:12,800
card with "A" and the card with "7".
If you're still not persuaded, try this version:

65
00:06:12,910 --> 00:06:17,690
You're a bouncer in a nightclub, and the rule
there is that if someone is consuming alcohol

66
00:06:17,690 --> 00:06:22,960
they must be over 18 years old. You see four
people: One is drinking alcohol but you don't

67
00:06:22,960 --> 00:06:28,130
know his age, another is drinking coca-cola
but you don't know his age, you can't see

68
00:06:28,130 --> 00:06:32,849
what the third person is drinking but you
know he's 16 years old, and you can't see

69
00:06:32,849 --> 00:06:36,710
what the fourth person is drinking but you
know he's 22 years old. Who do you need to

70
00:06:36,710 --> 00:06:43,349
check out? Right: It's the person drinking
alcohol and the one who's 16 years old. This

71
00:06:43,349 --> 00:06:48,729
is the same problem as the card task: The
nightclub rule is NOT that if someone is over

72
00:06:48,729 --> 00:06:54,300
18 they must consume alcohol.
Before moving on to the second phase of our

73
00:06:54,300 --> 00:06:59,229
two-part process, I'll make another claim:
Greater freedom of choice really helps us

74
00:06:59,229 --> 00:07:04,940
to be even more ensnared by our love of the
familiar, and sophisticated marketing and

75
00:07:04,940 --> 00:07:11,300
advertising are strengthening this trap. Thanks
to the net, we can find and join groups who

76
00:07:11,300 --> 00:07:17,990
share our most arcane interests. If you're
a fan of, say, 17th century Japanese literature,

77
00:07:17,990 --> 00:07:24,110
or 1950's electronic music, or intuitionist
mathematics, you can find like-minded people

78
00:07:24,110 --> 00:07:28,360
in the blogosphere or twitterverse. You're
no longer limited to friends who don't really

79
00:07:28,360 --> 00:07:35,259
know how wonderful 1950's electronic music
is; you can choose friends who do understand.

80
00:07:35,259 --> 00:07:42,259
Likewise, follow the recommendations provided
to you by Amazon, Pandora radio, eHarmony,

81
00:07:42,259 --> 00:07:49,259
and the like, and you'll find that these guides
help you become more like, well... you.

82
00:07:51,250 --> 00:07:55,860
This self-limiting choice pattern has been
occurring long before the net. We're attracted

83
00:07:55,860 --> 00:08:01,639
to people who are similar to us. A large body
of evidence about who we choose as friends,

84
00:08:01,639 --> 00:08:07,789
mates, and work colleagues supports this claim.
Margaret Heffernan, author of the book "Wilful

85
00:08:07,789 --> 00:08:14,129
Blindness", diagnosed herself with this syndrome.
She said "When I had my first opportunity,

86
00:08:14,129 --> 00:08:19,490
as a producer at the BBC, to choose my own
team, I hoped to hire people who would challenge

87
00:08:19,490 --> 00:08:26,370
me... I selected liberal-arts graduates who
were all female, spoke several languages...

88
00:08:26,370 --> 00:08:32,919
they were all like me." Mobility and increased
freedom of choice actually enhance this trend

89
00:08:32,919 --> 00:08:38,229
towards the homogenization of our in-groups:
American and UK data show an increase in the

90
00:08:38,229 --> 00:08:42,780
formation of like-minded communities over
the past two decades.

91
00:08:42,780 --> 00:08:48,230
Moreover, it isn't even actual similarity
of others that attracts us. It's perceived

92
00:08:48,230 --> 00:08:54,089
similarity. One of my students, Carol Baker,
and I asked long-term romantic couples to

93
00:08:54,089 --> 00:09:00,709
complete questionnaires measuring their risk
attitudes in areas such as finance and health.

94
00:09:00,709 --> 00:09:06,010
They filled each of them in twice: Once for
themselves and once as they believed their

95
00:09:06,010 --> 00:09:10,449
partner would fill them in. The similarity
between their own risk attitudes and their

96
00:09:10,449 --> 00:09:15,579
beliefs about their partner's risk attitudes
much more strongly predicted how positively

97
00:09:15,579 --> 00:09:19,890
they regarded their partners than the actual
similarity between their own and their partner's

98
00:09:19,890 --> 00:09:26,890
risk attitudes. Love may or may not be blind,
but it can insulate us in a double layer of

99
00:09:28,900 --> 00:09:34,630
ignorance: A very thick layer against intimacy
with dissimilar others, but also perhaps a

100
00:09:34,630 --> 00:09:38,260
thin layer concealing a few truths about our
best-loved.

101
00:09:38,260 --> 00:09:45,170
Now that we've seen how our preferences homogenize
our social networks, let's examine how that

102
00:09:45,170 --> 00:09:52,170
can combine with other factors to induce pathological
collective ignorance. In the early 1970's,

103
00:09:52,420 --> 00:09:57,280
social psychologist Irving Janis made the
provocative claim that group homogenization,

104
00:09:57,280 --> 00:10:03,000
combined with a few other conditions, could
lead to what he called "groupthink": Where

105
00:10:03,000 --> 00:10:08,709
everyone's individual viewpoints become replaced
by identical beliefs that persist in the face

106
00:10:08,709 --> 00:10:15,709
of mounting counter-evidence. Janis' preconditions
for groupthink are threefold. First, group

107
00:10:16,420 --> 00:10:22,850
cohesiveness becomes more important than individual
freedom or rights. Second, there are the group

108
00:10:22,850 --> 00:10:29,850
structural conditions: Group isolation and
group homogeneity. Third, the context: Threats,

109
00:10:31,429 --> 00:10:36,280
difficult decisions or dilemmas. Examples
of governmental and corporate catastrophes

110
00:10:36,280 --> 00:10:40,589
attributed to groupthink include the blindness
of American naval commanders to the prospect

111
00:10:40,589 --> 00:10:47,449
of a Japanese attack on Pearl Harbour in 1941,
the collapse of the airline Swissair, and

112
00:10:47,449 --> 00:10:52,380
the Space Shuttle Challenger disaster.
The main point here, however, is not that

113
00:10:52,380 --> 00:10:57,809
conditions for groupthink always result in
bad decisions, but simply that they contribute

114
00:10:57,809 --> 00:11:03,920
to a restricted and homogeneous knowledge-base
and therefore shared collective ignorance.

115
00:11:03,920 --> 00:11:09,709
Whether that ignorance is dysfunctional or
adaptive is open to question. After all, any

116
00:11:09,709 --> 00:11:14,329
specialized knowledge-base and the resulting
community of experts has an element of groupthink

117
00:11:14,329 --> 00:11:21,329
about it, but specialization is essential
for acquiring deep expertise in any field.

118
00:11:23,540 --> 00:11:29,540
This lecture has examined sources of ignorance
that are pervasive but unintended and largely

119
00:11:29,540 --> 00:11:36,270
unconscious. We've seen how our preferences
constrain the span of our knowledge and experience,

120
00:11:36,270 --> 00:11:40,360
and also limit our associations to people
whose knowledge and ignorance are similar

121
00:11:40,360 --> 00:11:47,360
to our own. Two of the key preferences behind
this are for the status quo and for information

122
00:11:48,350 --> 00:11:53,559
that confirms what we already believe. We've
also seen that when we are free to exercise

123
00:11:53,559 --> 00:12:00,079
our preferences, the result can be even greater
insularity from alternative viewpoints and

124
00:12:00,079 --> 00:12:05,709
experiences. The danger is that societies
can become fragmented into specialized enclaves

125
00:12:05,709 --> 00:12:12,709
that misunderstand one another and regard
one another as problematically ignorant. In

126
00:12:13,709 --> 00:12:17,740
the next lecture, we'll take a look at ignorance
when it is framed as a "public problem".

