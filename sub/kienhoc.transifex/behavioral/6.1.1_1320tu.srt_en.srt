1
00:00:07,279 --> 00:00:09,870
https://youtu.be/kYPNrhyGAj4
Last week, we talked about a process by which
we could

2
00:00:09,870 --> 00:00:14,349
start designing nudges to change behaviors
in specific domains.

3
00:00:14,349 --> 00:00:17,780
What I'd like to do now is to give you three
examples of recent papers that

4
00:00:17,780 --> 00:00:22,009
have been published that follow the process
in coming up with three

5
00:00:22,009 --> 00:00:24,320
interesting matching ideas.

6
00:00:24,320 --> 00:00:27,399
In particular, the three nudges we're going
to talk about are enhanced

7
00:00:27,399 --> 00:00:32,809
active choice, reminders, and finally, reform
designs to get people to be

8
00:00:32,809 --> 00:00:34,100
more honest.

9
00:00:34,100 --> 00:00:36,079
Let me start with the first one.

10
00:00:36,079 --> 00:00:39,920
It's October in Canada and it's flu season,
and in fact, it is flu season

11
00:00:39,920 --> 00:00:43,489
in many parts of the northern hemisphere at
this point in time.

12
00:00:43,489 --> 00:00:47,170
And every time the flu season comes around,
you often see messages like

13
00:00:47,170 --> 00:00:51,819
this asking you to go to your nearest clinic
and get a flu shot or an

14
00:00:51,819 --> 00:00:55,250
injection to prevent yourself from getting
the flu.

15
00:00:55,250 --> 00:00:59,359
Most of us don't get a flu shot, and the question
is, how can we design an

16
00:00:59,359 --> 00:01:02,620
intervention to get more people to protect
themselves from

17
00:01:02,620 --> 00:01:04,379
the seasonal flu?

18
00:01:04,379 --> 00:01:08,560
This was worked on by Anand-Keller and her
colleagues at Dartmouth, and what

19
00:01:08,560 --> 00:01:11,799
they were doing is they worked with the company
that had an annual flu

20
00:01:11,799 --> 00:01:15,689
program, where if you did indeed take a flu
shot, you not only got

21
00:01:15,689 --> 00:01:20,350
protection from the flu, but the company gave
you an incentive of $50.

22
00:01:20,350 --> 00:01:23,670
Under that circumstance, even then there were
a large number of people

23
00:01:23,670 --> 00:01:26,310
that did not get the flu shot.

24
00:01:26,310 --> 00:01:30,000
What Puman and her colleagues did was they
experimented with three different

25
00:01:30,000 --> 00:01:35,049
ways of asking people whether in fact they
wanted to get a flu shot.

26
00:01:35,049 --> 00:01:38,170
What are the bottlenecks in the decision to
get a flu shot?

27
00:01:38,170 --> 00:01:40,900
Bottleneck number one, it's not an active
decision.

28
00:01:40,900 --> 00:01:42,640
You see the information.

29
00:01:42,640 --> 00:01:46,060
That's not the place where you get to make
a decision, and then life gets in

30
00:01:46,060 --> 00:01:48,840
the way and you forget about the choice.

31
00:01:48,840 --> 00:01:52,539
Bottleneck number two, when most people think
about the decision to get

32
00:01:52,539 --> 00:01:56,840
a flu shot, the benefits of not getting a
flu shot are salient.

33
00:01:56,840 --> 00:02:00,990
But the benefits of getting a flu shot seem
to recede in the background.

34
00:02:00,990 --> 00:02:06,079
Punam and her colleagues tried to correct
for these deficiencies.

35
00:02:06,079 --> 00:02:09,870
Every time participants in that particular
organization got a message

36
00:02:09,870 --> 00:02:14,070
about a flu shot, they were then presented
with a card or a

37
00:02:14,070 --> 00:02:18,250
questionnaire that asked them for their intention
to get the flu shot in

38
00:02:18,250 --> 00:02:20,659
a standard opt-in condition.

39
00:02:20,659 --> 00:02:23,280
They saw the message that the checker box
that said, yes, I want to get a

40
00:02:23,280 --> 00:02:25,620
flu shot this fall.

41
00:02:25,620 --> 00:02:28,670
In a choice condition, they were given two
options.

42
00:02:28,670 --> 00:02:33,170
They could check either, yes, I do, or no,
I don't.

43
00:02:33,170 --> 00:02:36,230
But here's the most interesting version of
the questionnaire.

44
00:02:36,230 --> 00:02:40,180
This is what is called an enhanced active
choice and it said, check one

45
00:02:40,180 --> 00:02:44,980
of the following; yes, I will get the flu
shot to reduce my risk of getting

46
00:02:44,980 --> 00:02:49,080
the flu and because I like the $50 incentive.

47
00:02:49,080 --> 00:02:53,500
Or no, I won't get a flu shot this fall because
I don't care about my

48
00:02:53,500 --> 00:02:56,830
risk of getting the flu, and I don't care
for $50.

49
00:02:56,830 --> 00:03:00,900
So what's happened here is the way in which
you frame the question makes the

50
00:03:00,900 --> 00:03:04,190
cost of not getting a flu shot, say it.

51
00:03:04,190 --> 00:03:07,970
Now, if you actually see this question frame,
you would have to convince

52
00:03:07,970 --> 00:03:11,739
yourself that you're completely irrational
not to get the flu shot.

53
00:03:11,739 --> 00:03:12,739
What did they find?

54
00:03:12,739 --> 00:03:14,040
Here's what they found.

55
00:03:14,040 --> 00:03:19,209
Is people that saw the standard opt-in condition,
42% of those folks did

56
00:03:19,209 --> 00:03:21,140
express a desire to get a flu shot.

57
00:03:21,140 --> 00:03:25,340
When, in fact, it was converted into a yes/no
active choice, that

58
00:03:25,340 --> 00:03:26,890
number went up to 62%.

59
00:03:26,890 --> 00:03:31,910
But the kicker is when, in fact, they had
an enhanced active choice, when

60
00:03:31,910 --> 00:03:35,209
the number went up to 75%.

61
00:03:35,209 --> 00:03:40,739
So the idea in this paper is simple, is making
the choice salient, making

62
00:03:40,739 --> 00:03:46,409
it active, and highlighting the cost of the
bad choice changes the outcome.

63
00:03:46,409 --> 00:03:50,390
Here's a second example, reminders.

64
00:03:50,390 --> 00:03:54,690
We've talked about the fact that all of us
have good intentions, but we

65
00:03:54,690 --> 00:03:58,840
forget to do simple things like take our medications
or pay our bills on

66
00:03:58,840 --> 00:04:02,970
time or make contributions to our retirement
accounts or renew our

67
00:04:02,970 --> 00:04:04,590
driver's licenses.

68
00:04:04,590 --> 00:04:08,709
An experiment that was done by Dean Karlan
and his colleagues in three

69
00:04:08,709 --> 00:04:14,461
different countries, they looked at the Philippines,
Peru, and Bolivia, it

70
00:04:14,461 --> 00:04:18,560
reminded people from time to time using interventions
as simple as text

71
00:04:18,560 --> 00:04:24,180
messages or simple letters in the mail to
remind them to make contributions

72
00:04:24,180 --> 00:04:26,680
to their retirement plans.

73
00:04:26,680 --> 00:04:30,870
What these researchers found using a randomized
control approach in these

74
00:04:30,870 --> 00:04:35,910
three different experiments was that simply
sending reminders increased

75
00:04:35,910 --> 00:04:38,620
savings by about 6%.

76
00:04:38,620 --> 00:04:42,310
These researchers also tried other things
through the reminders.

77
00:04:42,310 --> 00:04:45,710
They tried making the reminders specific and
concrete, reminding

78
00:04:45,710 --> 00:04:50,270
people what their goal was, framing the messages
a gain versus a loss.

79
00:04:50,270 --> 00:04:54,270
And what they found was that to the extent
that the reminders are specific

80
00:04:54,270 --> 00:04:59,060
and remind people of a very concrete goal,
in fact, that savings goes up by

81
00:04:59,060 --> 00:05:01,400
16% and not just 6%.

82
00:05:01,400 --> 00:05:05,180
So simple reminder served as a nudge.

83
00:05:05,180 --> 00:05:09,560
The bottleneck here was the fact that the
decision was passive, the reminder

84
00:05:09,560 --> 00:05:11,860
made it active.

85
00:05:11,860 --> 00:05:15,080
Here's a third example, and this is work done
by my colleague Nina Mazar

86
00:05:15,080 --> 00:05:19,240
and some of her collaborators, and what they
were studying was the idea

87
00:05:19,240 --> 00:05:23,370
that most of us are a little bit dishonest.

88
00:05:23,370 --> 00:05:27,130
We're not outright liars, we don't want to
cheat, but we fudge numbers

89
00:05:27,130 --> 00:05:28,130
once in a while.

90
00:05:28,130 --> 00:05:31,090
So for example, when you write your tax returns,
we tend

91
00:05:31,090 --> 00:05:33,319
to over write expenses.

92
00:05:33,319 --> 00:05:36,990
What they did was they had participants come
into a lab to do an

93
00:05:36,990 --> 00:05:42,620
experiment, and at the end of it, participants
had to actually report

94
00:05:42,620 --> 00:05:46,570
how much they think they have earned in that
experiment using a

95
00:05:46,570 --> 00:05:48,479
form like this one.

96
00:05:48,479 --> 00:05:51,020
It looks pretty much like a standard tax form.

97
00:05:51,020 --> 00:05:53,840
Participants wrote their name on the top,
they wrote down a bunch of

98
00:05:53,840 --> 00:05:57,990
questions which asked them about how much
they had worked and the effort

99
00:05:57,990 --> 00:06:02,550
that put in and therefore, to price the contribution
that they had made to

100
00:06:02,550 --> 00:06:03,550
the experiment.

101
00:06:03,550 --> 00:06:05,860
And then they signed at the bottom saying
that everything they had

102
00:06:05,860 --> 00:06:09,150
written up here was true and honest.

103
00:06:09,150 --> 00:06:12,669
So you notice that the signature happens at
the end.

104
00:06:12,669 --> 00:06:17,160
What Nina and her colleagues thought was when
in fact, people respond to

105
00:06:17,160 --> 00:06:21,259
this questionnaire, the perception of themselves
as an honest person, as a

106
00:06:21,259 --> 00:06:23,710
good person, is in the background.

107
00:06:23,710 --> 00:06:25,630
Could we somehow bring it to the foreground?

108
00:06:25,630 --> 00:06:27,310
Could we make it more salient?

109
00:06:27,310 --> 00:06:32,699
And they did exactly that by using this version
of the form.

110
00:06:32,699 --> 00:06:36,740
Looks pretty much the same, except that now
you see the signature panel

111
00:06:36,740 --> 00:06:37,770
is at the top.

112
00:06:37,770 --> 00:06:39,280
So people write their name.

113
00:06:39,280 --> 00:06:42,340
The first thing they do is sign and say that
everything I'm going to say

114
00:06:42,340 --> 00:06:46,950
from here on is honest, is true, and then
they go on to report all of the

115
00:06:46,950 --> 00:06:50,340
numbers pretty much like they did in the first
version.

116
00:06:50,340 --> 00:06:51,340
What did they find?

117
00:06:51,340 --> 00:06:56,259
They essentially found that the rate of cheating
declined dramatically, and

118
00:06:56,259 --> 00:07:02,349
in fact, the data shows that 39% of people
cheated when in fact, they

119
00:07:02,349 --> 00:07:03,349
signed at the top.

120
00:07:03,349 --> 00:07:07,300
Whereas, as many as 79% cheated when in fact,
the

121
00:07:07,300 --> 00:07:08,419
signature was at the bottom.

122
00:07:08,419 --> 00:07:10,640
So here we have three examples.

123
00:07:10,640 --> 00:07:14,010
Three examples of simple nudges, and what
is common to all three is the

124
00:07:14,010 --> 00:07:18,169
idea that the nudges were simple to execute,
they were relatively

125
00:07:18,169 --> 00:07:22,610
inexpensive, but most importantly, they were
scalable.

126
00:07:22,610 --> 00:07:27,000
It was fairly easy to test something in the
context of a small experiment,

127
00:07:27,000 --> 00:07:31,680
but you could easily change forms or easily
send text reminders or easily

128
00:07:31,680 --> 00:07:36,150
change the way the questions were asked to
change behaviors at a fairly

129
00:07:36,150 --> 00:07:36,650
large scale.

