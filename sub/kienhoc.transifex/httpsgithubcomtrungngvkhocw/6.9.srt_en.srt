0
00:00:04,069 --> 00:00:10,199
https://youtu.be/9sgQMHtLPNU
Early in the episode and earlier in the course, we&#39;ve seen that people are a little bit too

1
00:00:10,199 --> 00:00:16,820
overeager when it comes to seeing patterns and noise. As Tom Gilovich said in the interview,

2
00:00:16,820 --> 00:00:22,010
if you take a bag of M&amp;Ms and pour it on the table, it doesn&#39;t look random. You see pockets

3
00:00:22,010 --> 00:00:28,550
of color here and there. You see faces in the things and so on. This happens all of

4
00:00:28,550 --> 00:00:35,239
the time. We see patterns among seemingly random events. Yes, this is true, and it&#39;s

5
00:00:35,239 --> 00:00:38,579
very common. It&#39;s been studied for ages.

6
00:00:38,579 --> 00:00:43,969
Something else that happens, which is quite interesting, is detecting relationships that

7
00:00:43,969 --> 00:00:50,190
don&#39;t exist as well. What do we mean by that? There&#39;s a really good one by Danny Kahneman

8
00:00:50,190 --> 00:00:57,190
and Amos Tversky—surprise, surprise. They tested the claim that or they looked into

9
00:00:57,719 --> 00:01:04,719
the claim that people report arthritis pain when there&#39;s a storm approaching. It turns

10
00:01:05,209 --> 00:01:10,630
out there&#39;s nothing, no evidence for that whatsoever. Another one is emergency room

11
00:01:10,630 --> 00:01:17,630
nurses claim that there&#39;s a lot more activity when there&#39;s a full moon during regular days

12
00:01:18,360 --> 00:01:25,360
of the month. Sportspeople, athletes, routinely engaged in all sorts of superstitious types

13
00:01:25,720 --> 00:01:30,840
of beliefs. They tie their shoes in a particular way. They bounce the ball exactly five times.

14
00:01:30,840 --> 00:01:37,159
They wear their pair of lucky socks or a pair of lucky shorts before a game or a competition.

15
00:01:37,159 --> 00:01:43,759
This happens all the time. These are superstitious beliefs as a result of seeing that two things

16
00:01:43,759 --> 00:01:50,310
tend to be linked: a pair of lucky socks and how they perform, or the full moon and the

17
00:01:50,310 --> 00:01:55,759
activity in that evening, but there is no link. There can&#39;t be any link between them,

18
00:01:55,759 --> 00:01:58,189
but people see certainly that there is a link.

19
00:01:58,189 --> 00:02:02,479
Yes. These superstitions, I think, is related to something called the conformation bias

20
00:02:02,479 --> 00:02:07,259
that we briefly touched on in episode three when we talked about the interview illusion.

21
00:02:07,259 --> 00:02:13,400
Now simply, that is we tend to notice things that confirm our beliefs, and we don&#39;t notice

22
00:02:13,400 --> 00:02:19,800
the things that contradict our beliefs. I chatted to Tom Gilovich about this, and here&#39;s what he had to say.

23
00:02:19,829 --> 00:02:25,340
So, formally, one of the other kinds of cognitive mechanisms that are operating when we have

24
00:02:25,340 --> 00:02:26,639
these beliefs or opinions?

25
00:02:26,639 --> 00:02:32,810
Yes. I think one of the most powerful and most interesting ones is something that a

26
00:02:32,810 --> 00:02:37,180
colleague, a former student here at Cornell, Scott Lilienfeld, calls the mother of all

27
00:02:37,180 --> 00:02:44,180
biases known as the confirmation bias. That&#39;s a term that most people are familiar with.

28
00:02:44,680 --> 00:02:50,500
They&#39;re familiar with the idea that if we want to believe something, we&#39;ll go and seek

29
00:02:50,500 --> 00:02:55,919
out evidence for it and we won&#39;t seek out evidence against it. That is really true.

30
00:02:55,919 --> 00:03:02,590
It&#39;s a very pronounced tendency to treat information that&#39;s consistent with what we want to believe

31
00:03:02,590 --> 00:03:08,000
in a pretty friendly way and be really hostile to information that&#39;s consistent with something

32
00:03:08,000 --> 00:03:12,310
we don&#39;t want to believe. It&#39;s almost as if we ask ourselves of something that we want

33
00:03:12,310 --> 00:03:17,780
to believe: can I believe this, or is there evidence for this? There&#39;s evidence for almost

34
00:03:17,780 --> 00:03:20,959
anything. Even the most outlandish things, there is some evidence for it. The question

35
00:03:20,959 --> 00:03:26,199
is: is there enough evidence? Is there sufficient evidence? We don&#39;t tend to ask ourselves:

36
00:03:26,199 --> 00:03:28,910
must I believe this? Is there enough evidence here?

37
00:03:28,910 --> 00:03:34,720
So all of that&#39;s true. All of people can relate to that, but it&#39;s even more pronounced than

38
00:03:34,720 --> 00:03:39,410
that—that is, even if you don&#39;t care about a particular belief, you have no vested interest

39
00:03:39,410 --> 00:03:45,049
in it, you tend to look for evidence consistent with the idea rather than information that&#39;s

40
00:03:45,049 --> 00:03:48,639
inconsistent with it, which, of course, if we want to have a balanced picture, we&#39;ve

41
00:03:48,639 --> 00:03:55,549
got to look at both. If I asked you—I gave you some plants, a bunch of hostas, and say,

42
00:03:55,549 --> 00:04:01,400
&quot;You&#39;re a nice guy. Here are some extra hostas from my garden. I think they probably need

43
00:04:01,400 --> 00:04:05,889
a lot of water,&quot; but you might want to test that. How would you test that? Well, if you&#39;re

44
00:04:05,889 --> 00:04:10,590
like most people, you&#39;d give it a lot of water and see how they do. What you wouldn&#39;t do

45
00:04:10,590 --> 00:04:15,989
is give some a lot of water, some hardly any water at all, and see which one does better.

46
00:04:15,989 --> 00:04:19,220
You look for evidence for it rather than against it.

47
00:04:19,220 --> 00:04:24,750
That&#39;s a very natural tendency. At some level, it make sense because it reflects a broader

48
00:04:24,750 --> 00:04:27,840
belief that, &quot;Look, if this thing&#39;s true, there must be some evidence for it, so let

49
00:04:27,840 --> 00:04:31,220
me look for some evidence for it.&quot; You&#39;re doing a very reasonable thing. However, you&#39;re

50
00:04:31,220 --> 00:04:35,760
doing an incomplete thing as well. You need to look not only for evidence for something

51
00:04:35,760 --> 00:04:42,760
but evidence against it. So if you believe that cheerful people are more likely to overcome

52
00:04:43,180 --> 00:04:49,020
a bout of cancer, you need to look not just who are the cheerful people you know who&#39;ve

53
00:04:49,020 --> 00:04:55,390
done very well, but maybe you know some dour people also who&#39;ve recovered. That&#39;s the latter

54
00:04:55,390 --> 00:04:58,320
step that we tend not to do.

55
00:04:58,320 --> 00:05:03,470
In this episode, we started by introducing the intuitive scientist. We spoke about how

56
00:05:03,470 --> 00:05:09,190
we can take some of the formal claims of science and bring them into the kitchen and to our

57
00:05:09,190 --> 00:05:16,190
everyday lives. We also chatted about our tendency to misperceive random events and

58
00:05:16,700 --> 00:05:22,120
random relationships. We spoke a lot about how we can contest claims, how it is that

59
00:05:22,120 --> 00:05:27,360
we can convince ourselves and others that there&#39;s a real effect here. There&#39;s something

60
00:05:27,360 --> 00:05:29,670
genuine that we should pay attention to.

61
00:05:29,670 --> 00:05:33,610
Now next week in episode seven, we&#39;re going to build on this. We&#39;re going to talk more

62
00:05:33,610 --> 00:05:38,570
generally about finding things out, about testing claims, and how to change opinions.

