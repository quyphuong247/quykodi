0
00:00:00,940 --> 00:00:07,490
https://youtu.be/u6dnJkbdx2M
Now we’ve spoken about the availability heuristic, but there’s another heuristic

1
00:00:07,490 --> 00:00:12,199
I really like, called representativeness. Now Danny Kahneman already introduced us to

2
00:00:12,199 --> 00:00:19,199
this character called Linda the bank teller, and Linda is described as very outgoing and

3
00:00:19,620 --> 00:00:26,620
bright. As a student, she was really passionate about social justice issues and discrimination,

4
00:00:27,570 --> 00:00:31,789
and she even participated in anti-nuclear demonstrations.

5
00:00:31,789 --> 00:00:37,499
Now when you ask people, “Is Linda a bank teller or a feminist bank teller,” people

6
00:00:37,499 --> 00:00:42,780
are way more likely to report that Linda is a feminist bank teller, even though just thinking

7
00:00:42,780 --> 00:00:47,309
about the base rates and the probability, there are way more bank tellers than there

8
00:00:47,309 --> 00:00:54,309
are feminist bank tellers. So what the Linda example sets up is—kind of conflicts between

9
00:00:55,289 --> 00:01:00,729
probability and base rates on one hand, what is actually true, versus representativeness,

10
00:01:00,729 --> 00:01:07,729
on the other. So those two things conflict, and representativeness wins. The description

11
00:01:08,450 --> 00:01:15,450
of Linda being so representative of a feminist sort of pushes the probability down and were

12
00:01:15,960 --> 00:01:20,360
more likely to respond that Linda is a feminist bank teller.

13
00:01:20,360 --> 00:01:27,360
This works not only for toy scenarios like the Linda problem, but it’s broader than

14
00:01:29,020 --> 00:01:35,840
that. It’s more general in terms of category learning. If you think, for example, about

15
00:01:35,840 --> 00:01:42,840
fruit. When I say fruit, what’s the first thing that comes into mind? It’s probably

16
00:01:43,060 --> 00:01:49,730
an apple or an orange or something, not a tomato or pumpkin, which are also fruits but

17
00:01:49,730 --> 00:01:55,450
are probably not the first that you’d think of. You do the same thing with—I don’t

18
00:01:55,450 --> 00:02:02,240
know—a grocery store clerk. We have these ideas about how things are supposed to work.

19
00:02:02,240 --> 00:02:06,250
When you walk into a grocery store, for example, you have an idea about who works there and

20
00:02:06,250 --> 00:02:11,540
who doesn’t. I’ve made this mistake in the past. I walked into a grocery store and

21
00:02:11,540 --> 00:02:17,610
I asked somebody where the lime juice was—those little containers of lime juice. I walk in,

22
00:02:17,610 --> 00:02:23,460
“Where does this belong?” A guy says, “I don’t actually work here,” but he

23
00:02:23,460 --> 00:02:28,440
had a clipboard. That’s what gets me. The guy had a clipboard. Who walks around in a

24
00:02:28,440 --> 00:02:35,440
grocery store with a clipboard? But he doesn’t have—he totally fit the mold of somebody

25
00:02:35,959 --> 00:02:41,060
who worked in the store because he had a clipboard and he was walking. He even had a tie. So

26
00:02:41,060 --> 00:02:44,330
I was confused. But for the most part, I mean, that kind of

27
00:02:44,330 --> 00:02:49,630
example demonstrates that for the most part, it gets us by. When I walk into a store, I

28
00:02:49,630 --> 00:02:55,830
can always tell who works there 99 percent of the time. So this idea of representativeness,

29
00:02:55,830 --> 00:03:02,640
of relying on prototypes, gets us by most of the time, but when we can create these

30
00:03:02,640 --> 00:03:09,640
scenarios where we don’t operate with 100 percent accuracy.

31
00:03:10,530 --> 00:03:16,860
So Danny Kahneman and Amos Tversky had to create this Linda problem, so she really fit

32
00:03:16,860 --> 00:03:22,870
the mold of a feminist bank teller, to kind of trick people in the sense to fall in to

33
00:03:22,870 --> 00:03:26,489
this mistake. What we’re going to do now is present another

34
00:03:26,489 --> 00:03:33,380
example, one from, again, Danny Kahneman and Amos Tversky, that they came up with, where

35
00:03:33,380 --> 00:03:40,380
we talk about Rudy who’s in a similar sort of vein as Linda the famous feminist bank

36
00:03:43,739 --> 00:03:47,870
teller. Let’s see if people still make the same sort of error when it comes to Rudy.

