0
00:00:18,650 --> 00:00:24,590
https://youtu.be/Uyxb6ooKvUY
This is the final episode of Think101. Now, it&#39;s been an amazing experience. We have covered

1
00:00:24,590 --> 00:00:29,329
an enormous amount of material over the last 11 episodes, but because we presented it bit

2
00:00:29,329 --> 00:00:33,579
by bit, I suspect that people are going to be really surprised at how much they&#39;ve learned.

3
00:00:33,579 --> 00:00:39,040
In each of the episodes, we tackled a different topic, ranging from illusions, rationality,

4
00:00:39,040 --> 00:00:44,760
learning to learn, up to the scientific method, testing claims and exploiting the situation

5
00:00:44,760 --> 00:00:47,320
in order to predict and shape human behavior.

6
00:00:47,320 --> 00:00:53,839
There are a few themes that emerged throughout Think101, and I think we should try to integrate

7
00:00:53,839 --> 00:00:55,650
them here and make them explicit.

8
00:00:55,650 --> 00:01:00,299
That&#39;s right. The first theme that we talked about was the fact that the world is complex

9
00:01:00,299 --> 00:01:05,360
and ambiguous. Now, this is really apparent when you just look around the world and see

10
00:01:05,360 --> 00:01:10,600
the massive processing problem that we have when trying to integrate all of this information.

11
00:01:10,600 --> 00:01:15,930
Virtually every object and event that we encounter can be interpreted in different ways.

12
00:01:15,930 --> 00:01:20,790
For example, we provided a bunch of simple examples like: the Necker cube, or the spinning

13
00:01:20,790 --> 00:01:27,790
dancer that&#39;s either rotating counterclockwise or clockwise, the image of the duck or the

14
00:01:28,440 --> 00:01:35,190
rabbit, the young woman or old woman, or maybe the ambiguous letter or the digit, depending

15
00:01:35,190 --> 00:01:39,460
on how you&#39;re looking at that information, or the smiling or the smirking face, depending

16
00:01:39,460 --> 00:01:41,320
on whether you like that person or not.

17
00:01:41,320 --> 00:01:47,080
We travelled to the MindBodySpirit Festival. We were completely immersed in ambiguity.

18
00:01:47,080 --> 00:01:53,479
If you remember the vague and generic Barnum statements that psychics were making, or the

19
00:01:53,479 --> 00:01:59,300
people at the horoscope booth, or the dozens of particular symptoms that you should watch

20
00:01:59,300 --> 00:02:04,530
out for when visiting the chiropractor, or after visiting the Japanese healing booth,

21
00:02:04,530 --> 00:02:10,399
what sort of ambiguous health claims you can expect to receive.

22
00:02:10,399 --> 00:02:15,000
Ambiguity is operating absolutely everywhere, especially when it comes to other types of evidence.

23
00:02:15,000 --> 00:02:19,549
Whether it be formal evidence like forensic evidence, or evidence for or against

24
00:02:19,549 --> 00:02:25,500
climate change, or evidence as to whether your best friend is honest or adventurous or not.

25
00:02:25,500 --> 00:02:29,040
Ambiguity is operating all over the place.

26
00:02:29,040 --> 00:02:34,659
Now, it&#39;s also important when we&#39;re considering the general types of decisions that we make

27
00:02:34,659 --> 00:02:39,459
all over the place. It&#39;d be really nice if we had all of the information out in front

28
00:02:39,459 --> 00:02:43,150
of us and the luxury of having all the time in the world to make a decision, but that&#39;s

29
00:02:43,150 --> 00:02:49,439
rarely the case, isn&#39;t it? Most of the time, we have to make decisions fast, and even when

30
00:02:49,439 --> 00:02:54,560
we do make the decision, we have no idea whether it was the right one or not. Feedback is terrible,

31
00:02:54,560 --> 00:02:56,749
yet we still have to make these decisions.

32
00:02:56,749 --> 00:03:01,239
Yes. How do we deal with this complexity and ambiguity? Well, we have to use simplified

33
00:03:01,239 --> 00:03:06,849
models of the world. We use shortcuts, heuristics. We talked about the availability heuristic,

34
00:03:06,849 --> 00:03:11,900
representativeness, anchoring, the &quot;be fair to both sides&quot; and &quot;it must be somewhere in the middle&quot; heuristic. 

35
00:03:11,900 --> 00:03:18,500
We saw these operating when people were making and dealing with claims of the extraordinary.

36
00:03:18,559 --> 00:03:25,200
But it&#39;s more than that. We see patterns and relationships that just aren&#39;t there. We see what we expect to see.

37
00:03:25,200 --> 00:03:29,950
We preferentially seek out evidence that confirms our beliefs. We see what we

38
00:03:29,950 --> 00:03:35,950
want to see, and we develop all these superstitions like: bad things happen in threes and 

39
00:03:35,950 --> 00:03:41,510
I have to wear my lucky socks. These are all examples of fast thinking: system one.

40
00:03:41,510 --> 00:03:45,749
That&#39;s right. Now, the goal of the course is to figure out how everyday thinking can be improved.

41
00:03:45,749 --> 00:03:54,700
In order to improve everyday thinking, we need to be more analytic; use system two; unpack issues.

42
00:03:54,700 --> 00:04:02,799
These are all incredibly important when trying to figure out how to get better at thinking.

43
00:04:02,799 --> 00:04:08,599
Another bunch of issues that we covered are like the intuitive scientist. Well the intuitive

44
00:04:08,599 --> 00:04:12,379
scientist is important—in order to improve everyday thinking, you need to consider the

45
00:04:12,379 --> 00:04:16,549
scientific method if you&#39;re deciding whether or not to take a drug, or whether to change

46
00:04:16,548 --> 00:04:21,780
your diet or not. We talked about a lot of ways looking at the evidence for that.

47
00:04:21,779 --> 00:04:28,780
We talked about the double-blind randomized controlled trials. Now if you&#39;re deciding to whether

48
00:04:28,960 --> 00:04:33,860
take a drug or not, if it hasn&#39;t been subjected to that, then maybe you better think twice

49
00:04:33,860 --> 00:04:35,900
about whether to take that or not.

50
00:04:35,900 --> 00:04:40,819
We also talked about testimonials or anecdotes. If somebody says that a particular diet or

51
00:04:40,819 --> 00:04:47,000
a drug is fantastic, that&#39;s only one cell. That&#39;s pretty much useless. What about the other three cells?

52
00:04:47,020 --> 00:04:50,819
I think learning those general problem-solving skills are really important, and that will

53
00:04:50,819 --> 00:04:55,699
get us part of the way there, but we also need to learn how to learn. We showed people

54
00:04:55,699 --> 00:05:01,900
some really clever techniques that they can use to learn better and remember that information for longer. 

55
00:05:01,900 --> 00:05:07,360
We said that focusing on factors of the situation, rather than personalities,

56
00:05:07,360 --> 00:05:12,530
will get us much closer to predicting and shaping human behavior.

57
00:05:12,530 --> 00:05:19,020
We also talked about opinion change—that is, changing the minds of others or yourself.

58
00:05:19,020 --> 00:05:26,020
Now opinion change is really hard. It&#39;s cognitively effortful. It&#39;s intellectually difficult.

59
00:05:26,060 --> 00:05:31,870
If you give someone information that contradicts their current belief, they&#39;re unlikely just

60
00:05:31,870 --> 00:05:37,530
to accept it on the spot at face value. What you have to do is show them what they can

61
00:05:37,530 --> 00:05:42,610
change their mind to, show them how they can accept your new evidence while also retaining

62
00:05:42,610 --> 00:05:47,490
a large part of their previous belief. This goes for supernatural beliefs, whether it&#39;s

63
00:05:47,490 --> 00:05:52,639
stopping a hurricane with the power of prayer batteries, or belief in climate change, or

64
00:05:52,639 --> 00:05:55,830
belief in the cost and benefits of vaccinating your child or not.

65
00:05:55,830 --> 00:06:00,110
In order to improve everyday thinking, we need to be more analytic, as we said.

66
00:06:00,110 --> 00:06:04,080
Use system two. Read more, as the MythBusters said.

67
00:06:04,080 --> 00:06:09,009
It&#39;s incredibly important to get past the headlines. It&#39;s really tempting, when you&#39;re

68
00:06:09,009 --> 00:06:15,879
reading a newspaper or a webpage, to just sit back and keep score of who&#39;s right and

69
00:06:15,879 --> 00:06:20,389
who&#39;s wrong, but it&#39;s rarely that simple. You need to go into the article and try to

70
00:06:20,389 --> 00:06:23,500
see things from a different perspective.

71
00:06:23,500 --> 00:06:27,370
Also be wary of information that you&#39;ve gained while you&#39;re only partly paying attention.

72
00:06:27,370 --> 00:06:32,659
When we&#39;re trying to tackle a particular claim, look at the costs and benefits of the

73
00:06:32,659 --> 00:06:37,060
successes, of the two ways that you can be right. Look at the costs and benefits of the

74
00:06:37,060 --> 00:06:42,400
failures, of the two ways that you can be wrong. More generally, think more clearly.

75
00:06:42,400 --> 00:06:47,900
Seek out. Look for evidence. Just because that&#39;s the way we&#39;ve always done it doesn&#39;t make it right.

76
00:06:47,900 --> 00:06:51,819
Question what people tell you and what you believe.

