0
00:00:04,170 --> 00:00:10,510
https://youtu.be/Pt_R0mYbn90
So there we have it: directly from Danny Kahneman, talking about system one and system two. Now

1
00:00:10,510 --> 00:00:15,550
I think it&#39;s important to remember the point of this episode. We&#39;re looking at the difference

2
00:00:15,550 --> 00:00:20,880
between system one and system two. He makes that distinction clear, I think, when he was

3
00:00:20,880 --> 00:00:27,010
talking about some of the early work that he did with Jackson Beatty, in the 60&#39;s

4
00:00:27,010 --> 00:00:33,150
actually, on pupil dilation. He just mentioned it briefly, but what he was actually measuring—we

5
00:00:33,150 --> 00:00:37,769
know that pupils when you are measuring—what you can actually do is film somebody&#39;s pupil,

6
00:00:37,769 --> 00:00:41,430
and you can project it onto a wall beside them, for example, and you can measure it

7
00:00:41,430 --> 00:00:46,489
literally with a ruler. Measure the size of the pupil as it gets larger and smaller.

8
00:00:46,489 --> 00:00:51,200
Now we know that the pupil responds to things like light. So if you have bright light, the

9
00:00:51,269 --> 00:00:57,440
pupil dilates [sic]. Dark, and then it gets larger. But it also responds to cognitive effort.

10
00:00:57,440 --> 00:01:03,909
So it&#39;s actually responding to system two, essentially how hard your brain is working.

11
00:01:03,909 --> 00:01:10,880
It&#39;s not even how hard you feel like you&#39;re working, but it&#39;s actually how much effort,

12
00:01:10,880 --> 00:01:17,630
how much heat the brain is producing almost. So what you can do—the way that they tested

13
00:01:17,630 --> 00:01:24,549
it, he and Beatty, was by presenting people with a digit-span task. If I ask you to remember,

14
00:01:24,549 --> 00:01:31,549
for example, 6-4-3—that was three digits. I measure your pupil. Then I add a digit:

15
00:01:32,369 --> 00:01:39,219
6-4-3-2. You keep those four digits in mind, and I measure your pupil. 6-4-3-2-7. We can

16
00:01:39,219 --> 00:01:45,579
keep doing this and adding digits, and as you try to remember the digits span as you

17
00:01:45,579 --> 00:01:51,079
keep adding more and more digits, your pupil just keeps getting larger and larger, until

18
00:01:51,079 --> 00:01:58,079
one of two things happens: one, you report the number, so you say, &quot;Okay, 6-4-3-2-7,&quot;

19
00:01:59,020 --> 00:02:03,429
and then your pupil constricts again; or you give up.

20
00:02:03,429 --> 00:02:08,399
In his book, he talks about this really nice example where they&#39;re watching—they have

21
00:02:08,399 --> 00:02:12,379
somebody participating in the experiment, in this digit-span task, and they&#39;re remembering

22
00:02:12,379 --> 00:02:16,569
the digits, and they&#39;re outside of the room; they&#39;re watching this large pupil in the

23
00:02:16,569 --> 00:02:23,400
screen outside. When the person gave up, they just see and they say inside of it, &quot;So

24
00:02:23,400 --> 00:02:27,810
you gave up on the problem?&quot; The person was like, &quot;How did you know?&quot; It&#39;s almost

25
00:02:27,810 --> 00:02:32,140
like you had a window into their own mind, which is, I think, quite cool.

26
00:02:32,140 --> 00:02:36,519
That&#39;s cool. Danny Kahneman also talked about this phenomenon known as anchoring.

27
00:02:36,519 --> 00:02:40,900
Fritz Strack, a researcher, has a pretty cool example of this. He asked people to guess

28
00:02:40,900 --> 00:02:47,900
how old Gandhi was when he died. He put them into two groups. One group he asked, &quot;Was

29
00:02:48,080 --> 00:02:54,659
Gandhi older than 140 years old when he died?&quot; Another group he asked, &quot;Was Gandhi older

30
00:02:54,659 --> 00:03:00,430
than 9 years old when he died?&quot; These people responded—they were guessing how old Gandhi

31
00:03:00,430 --> 00:03:05,569
was when he died—and the people that were given the high anchor of 140 guessed that

32
00:03:05,569 --> 00:03:12,180
Gandhi died at 67 years old. People that were given the low anchor of 9 guessed that Gandhi

33
00:03:12,180 --> 00:03:19,180
died when he was 50 years old. Now he actually died when he was 78, but you can see that

34
00:03:19,689 --> 00:03:25,040
the high anchor pushed people in one direction, and the low anchor pushed them into another.

35
00:03:25,040 --> 00:03:31,540
Now you may think that, &quot;Well, that&#39;s kind of reasonable if an experimenter or someone,

36
00:03:31,540 --> 00:03:36,569
they might have some inside information about the correct answer to the question, and so

37
00:03:36,569 --> 00:03:43,010
it&#39;s quite reasonable to anchor your decision based on a number that they say,&quot; but it

38
00:03:43,010 --> 00:03:47,129
can&#39;t be working like that because there&#39;s another great example by Dan Ariely. He

39
00:03:47,129 --> 00:03:54,129
asked people to bid on bottles of wine and chocolate. Before the experiment, he asked

40
00:03:54,689 --> 00:03:59,840
participants to write down their social security number, just the last two digits, and then

41
00:03:59,840 --> 00:04:04,140
he split them into two groups. If their social security number is higher than 50, they go

42
00:04:04,140 --> 00:04:09,680
to this group; lower than 50, in other group. Then he asked them, &quot;How much would you

43
00:04:09,680 --> 00:04:14,420
bid on these things, on these bottles of wine and these chocolate?&quot; Now he found that

44
00:04:14,420 --> 00:04:20,820
people who had a high social security number, greater than 50, for example, they were willing

45
00:04:20,820 --> 00:04:26,460
to pay way more for these things than people who wrote down a low social security number

46
00:04:26,460 --> 00:04:32,750
before the experiment. You can see that this arbitrary writing down

47
00:04:32,750 --> 00:04:38,180
of a number is influencing their decisions. I think people with a high social security

48
00:04:38,180 --> 00:04:45,180
number were willing to pay 60 to 120 percent more for these things than the low social

49
00:04:45,920 --> 00:04:51,650
security number, which I think is pretty cool. This idea of anchoring, I think,

50
00:04:51,650 --> 00:04:57,430
is really good. It highlights what we&#39;re talking about when—the point of this episode

51
00:04:57,430 --> 00:05:04,430
is that we&#39;re operating under less-than-ideal conditions, and so we have to rely on shortcuts

52
00:05:04,560 --> 00:05:09,290
in order to be able to navigate the world obviously. When you&#39;re in this anchoring

53
00:05:09,290 --> 00:05:13,980
position, if you&#39;re given any number, any number, obviously, even random numbers, the

54
00:05:13,980 --> 00:05:19,110
same thing happens with the roll of a roulette wheel. If a number that comes up, say 10,

55
00:05:19,110 --> 00:05:24,290
then you use that as your anchor, regardless of whatever random process generated it—but

56
00:05:24,290 --> 00:05:28,690
under most conditions it&#39;s not random. Under most conditions, when we&#39;re operating in

57
00:05:28,690 --> 00:05:35,690
the world, a number appears, that&#39;s something to start with. But in complex scenarios, if

58
00:05:36,530 --> 00:05:43,530
you have no idea, for example, of the percentage of African countries in the UN, or the population

59
00:05:44,360 --> 00:05:49,960
of Australia, say, you have to start somewhere, and any number that you have is better than

60
00:05:49,960 --> 00:05:53,530
no number at all. So we have to deal with what we have.

61
00:05:53,530 --> 00:05:58,250
But that&#39;s just anchoring. We can deal with a whole bunch of other types of heuristics

62
00:05:58,250 --> 00:06:03,270
and biases. We&#39;re going to talk about one next called availability, but what we&#39;re

63
00:06:03,270 --> 00:06:09,900
going to do first is revisit the faces that we&#39;ve presented in the first part of the episode.

64
00:06:09,900 --> 00:06:12,820
Now what we want you to do is think back to

65
00:06:12,820 --> 00:06:18,450
the list of faces we&#39;ve presented earlier in the episode, so don&#39;t watch the video

66
00:06:18,450 --> 00:06:22,870
again. Just think back to that list that we presented. What we want you to do is estimate

67
00:06:22,870 --> 00:06:29,870
whether, in that list, there were more males or whether were more females that we presented.

68
00:06:31,340 --> 00:06:35,930
Think back and go into the next section and indicate whether there were more males or

69
00:06:35,930 --> 00:06:37,970
more females in that list.

