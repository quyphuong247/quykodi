0
00:00:03,550 --> 00:00:07,880
https://youtu.be/5WJKyBz35Q0
In this episode, we&#39;ve taken a load of the cognitive mechanisms that we&#39;ve learned about

1
00:00:07,880 --> 00:00:13,250
and applied them to cases where lives and livelihoods are at risk. We looked at Facilitated

2
00:00:13,250 --> 00:00:18,529
Communication and saw that Expectancy Effects are operating. We can use two-by-two contingency

3
00:00:18,529 --> 00:00:25,119
tables to help disentangle hits from false alarms and weigh the costs versus the benefits.

4
00:00:25,119 --> 00:00:29,980
Now Bill Thompson alluded to something that we&#39;re going to talk about next, which is expertise

5
00:00:29,980 --> 00:00:34,210
in fingerprint identification. Now you and I spend a lot of our time working on this

6
00:00:34,210 --> 00:00:39,600
stuff. Contrary to what you see on &quot;CSI,&quot; it&#39;s not computers that match fingerprints

7
00:00:39,600 --> 00:00:43,129
and interpret DNA profiles. It&#39;s actually a human.

8
00:00:43,129 --> 00:00:50,019
That&#39;s right, and because we&#39;re dealing with humans here, that&#39;s when things get interesting.

9
00:00:50,019 --> 00:00:55,699
It&#39;s not up to a computer. It&#39;s not simply a matter of going to a crime scene, dusting

10
00:00:55,699 --> 00:00:59,449
for prints, getting the bloody print, putting it into a computer, and up pops the...

11
00:00:59,449 --> 00:01:02,429
The driver&#39;s license of the person who committed the crime.

12
00:01:02,429 --> 00:01:07,780
Exactly, yes. It doesn&#39;t work like that. It doesn&#39;t work like it does on &quot;CSI.&quot; It&#39;s a

13
00:01:07,780 --> 00:01:14,580
lot more noisy than that. Yes, it might work like that, in a sense, with the computer if

14
00:01:14,580 --> 00:01:20,300
it&#39;s really high-quality fingerprints. That&#39;s what happens with your iPhone or at the airport.

15
00:01:20,300 --> 00:01:26,220
Often, it can be done without a human. But when you&#39;re dealing with bloody crime scene

16
00:01:26,220 --> 00:01:31,270
prints, that&#39;s when human judgment is involved.

17
00:01:31,270 --> 00:01:36,430
We know that, as Bill was saying, there&#39;s an enormous amount of ambiguity in those conditions.

18
00:01:36,430 --> 00:01:41,120
With a bloody print, often it&#39;s this partial print as well, so you only see just a little

19
00:01:41,120 --> 00:01:46,830
bit of it, and you have to match it to this fully rolled tenprint. We can see in this

20
00:01:46,830 --> 00:01:53,200
figure actually the print on the left is from person A; the print on the far right is also

21
00:01:53,200 --> 00:01:59,020
from person A, and they look pretty similar, but the print in the middle is from person

22
00:01:59,020 --> 00:02:06,020
B, and that looks really close to person A. It doesn&#39;t seem like all fingerprints are

23
00:02:06,350 --> 00:02:12,430
unique when you&#39;re looking at these examples. It&#39;s not clear-cut. There&#39;s a lot of ambiguity,

24
00:02:12,430 --> 00:02:18,770
and when you have ambiguity creeping in like that, that&#39;s when we&#39;re vulnerable to these

25
00:02:18,770 --> 00:02:20,300
Expectancy Effects that we&#39;ve been talking about.

26
00:02:20,300 --> 00:02:25,530
If I tell you, &quot;The person confessed to the crime. Now analyze these prints, and tell

27
00:02:25,530 --> 00:02:30,450
me whether they&#39;re from the same person or not,&quot; you can&#39;t look at them with new eyes.

28
00:02:30,450 --> 00:02:34,000
You can&#39;t look at them as though you don&#39;t know that information. It&#39;s going to creep in.

29
00:02:34,060 --> 00:02:41,060
DNA is also vulnerable. Bill Thompson talked about how much ambiguity creeps in here, so

30
00:02:41,590 --> 00:02:46,090
when you&#39;re looking at these DNA samples, it&#39;s not clear that the sample that you have

31
00:02:46,090 --> 00:02:51,819
is from this person or not. There&#39;s a lot of information, when you&#39;re dealing with mixed

32
00:02:51,819 --> 00:02:57,340
samples and so on, that points in one direction or another. Depending on the information you

33
00:02:57,340 --> 00:03:01,940
have in front of you, you can go one way or the other. They&#39;re multifaceted in that sense.

34
00:03:01,940 --> 00:03:08,459
CCTV footage—same thing. You&#39;re filming this sort of fuzzy crime that happened, and

35
00:03:08,459 --> 00:03:13,209
you have to judge whether the person in front of you is in fact that person in this grainy footage.

36
00:03:13,290 --> 00:03:14,360
Sitting in the dock there.

37
00:03:14,360 --> 00:03:20,600
That&#39;s right. So what do you do? Yes, that&#39;s when this sort of stuff really—we see what

38
00:03:20,600 --> 00:03:23,630
we expect to see, and that&#39;s a perfect example of that.

39
00:03:23,630 --> 00:03:27,350
Yes. There is also hearing what we expect to hear as well. There&#39;s a case out of New

40
00:03:27,350 --> 00:03:32,220
Zealand where a guy called David Bain was accused of murdering his whole family. Now

41
00:03:32,220 --> 00:03:39,220
there&#39;s a call to the police or the ambulance which was made by David, and he&#39;s panting.

42
00:03:40,080 --> 00:03:46,530
He&#39;s obviously scared. The quality of the audio recording across the phone line is pretty

43
00:03:46,530 --> 00:03:52,550
terrible, but sound engineers later on said that they heard David say, &quot;I shot the prick,&quot;

44
00:03:52,550 --> 00:03:56,250
even in all this noise and this panting, and everything that&#39;s going on.

45
00:03:56,250 --> 00:03:57,930
It&#39;s really hard to listen to.

46
00:03:57,930 --> 00:04:04,930
Yes, but if you are told, &quot;I shot the prick,&quot; and then you play that recording, just like,

47
00:04:04,989 --> 00:04:09,700
&quot;It&#39;s fun to smoke marijuana,&quot; you will hear it, I think because there&#39;s enough ambiguity there.

48
00:04:09,709 --> 00:04:16,220
Now think about what that means for the case. If that information was presented to a jury,

49
00:04:16,220 --> 00:04:20,849
what do you do about that? We know that they&#39;re likely to be influenced by that information,

50
00:04:20,849 --> 00:04:26,200
and so, again, it might be best to blind them into that and just let them listen to it in the first place.

51
00:04:26,229 --> 00:04:32,759
We saw in episode two that Beth Loftus is able to plant entire memories of events that

52
00:04:32,759 --> 00:04:36,650
never actually happened. That might not work if she&#39;s trying to influence you for what

53
00:04:36,650 --> 00:04:40,479
happened yesterday. You were lost in a shopping mall yesterday—that might not work. But

54
00:04:40,479 --> 00:04:45,270
think about the ambiguity that just comes from time—when you were eight years old,

55
00:04:45,270 --> 00:04:51,009
you were lost in a shopping mall—that&#39;s the space in which that she&#39;s able to convince

56
00:04:51,009 --> 00:04:52,889
you of something that never happened.

57
00:04:52,889 --> 00:04:57,830
Now back to forensic expertise. Fingerprint examiners have claimed that they won&#39;t be

58
00:04:57,830 --> 00:05:03,590
influenced by extraneous information about a case. If they know that the person committed—later

59
00:05:03,590 --> 00:05:07,330
confessed to the crime, or if they know that their colleague has already said that these

60
00:05:07,330 --> 00:05:11,819
two fingerprints match, they have claimed that they won&#39;t be biased or influenced by

61
00:05:11,819 --> 00:05:16,909
this information, but just as we saw in episode three &quot;Know Thyself,&quot; people have very little

62
00:05:16,909 --> 00:05:22,099
insight into what&#39;s going on inside their heads. We know that they will be influenced

63
00:05:22,099 --> 00:05:24,610
by this information in one way or another.

64
00:05:24,610 --> 00:05:30,050
In episode four &quot;Intuition and Rationality&quot;—this is essentially what I did my PhD in—I was

65
00:05:30,050 --> 00:05:35,669
looking at the influence of system one and system two on the judgments of fingerprint

66
00:05:35,669 --> 00:05:41,600
examiners, how much do they do really quickly and how much do they have to spend more time and analyzing.

67
00:05:41,639 --> 00:05:46,749
In episode five &quot;Learning to Learn,&quot; we&#39;re actually using—we&#39;re trying to use distributed

68
00:05:46,749 --> 00:05:53,700
practice and interleaving to turn novice fingerprint examiners into expert fingerprint examiners more quickly.

69
00:05:53,729 --> 00:05:59,319
Episode six &quot;The Experiment,&quot; now we did a trivial experiment on testing whether people

70
00:05:59,319 --> 00:06:05,229
can discriminate wines, but we&#39;re using exactly the same tools when we do our research to

71
00:06:05,229 --> 00:06:09,529
find, I think, out more important things about whether fingerprint experts can discriminate

72
00:06:09,529 --> 00:06:13,229
between matching and non-matching prints. The list goes on.

73
00:06:13,229 --> 00:06:18,499
That&#39;s right. Again, we&#39;re trying to apply all of the lessons learned in these previous

74
00:06:18,499 --> 00:06:21,059
episodes to these more applied topics.

75
00:06:21,059 --> 00:06:28,059
The next topic that we&#39;re going deal with is the idea of conspiracy theories. I talked

76
00:06:28,219 --> 00:06:33,009
to Steve Lewandowsky about exactly this. He&#39;s done an enormous amount of work on conspiracy

77
00:06:33,009 --> 00:06:40,009
theorists, specifically applying this stuff to climate-change deniers, and we can see

78
00:06:40,069 --> 00:06:47,200
all of these topics happening here as well—availability heuristic, confirmation bias—and I talked to Steve about these.

