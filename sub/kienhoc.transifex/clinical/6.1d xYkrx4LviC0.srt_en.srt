0
00:00:06,779 --> 00:00:11,190
The next question we should be asking is whether the test is reliable.

1
00:00:11,190 --> 00:00:15,480
If we wanted to measure something, for example, the height of this person, we could use a

2
00:00:15,480 --> 00:00:17,390
tape measure, like this.

3
00:00:17,390 --> 00:00:21,520
According to this tape measure, her height is xxx cm.

4
00:00:21,520 --> 00:00:26,689
Then, if we wanted to measure her height again, just to be sure, we get the tape measure out

5
00:00:26,689 --> 00:00:27,689
again.

6
00:00:27,689 --> 00:00:31,689
But it turns out that the tape measure is actually all wobbly and difficult to use,

7
00:00:31,689 --> 00:00:34,280
because I’m stingy and bought a really cheap one.

8
00:00:34,280 --> 00:00:38,760
So this time, we get a different measurement that is actually more than our first measurement,

9
00:00:38,760 --> 00:00:40,600
xxx cm.

10
00:00:40,600 --> 00:00:45,320
Now, because the measurement changed from the first time we measured to the second time,

11
00:00:45,320 --> 00:00:49,059
we would say that our tape measure is not reliable.

12
00:00:49,059 --> 00:00:52,569
Reliability is the extent to which a measure gives you consistent measures on repeated

13
00:00:52,569 --> 00:00:53,569
measurements.

14
00:00:53,569 --> 00:00:59,429
So, with regard to tests, reliability measures the extent to which the test yields consistent

15
00:00:59,429 --> 00:01:00,850
scores for individuals.

16
00:01:00,850 --> 00:01:05,280
Now, when it comes to an intelligence test, we can’t evaluate its reliability by just

17
00:01:05,280 --> 00:01:09,750
looking at it to see whether or not it wobbles all over the place like my cheap tape measure.

18
00:01:09,750 --> 00:01:14,960
There are different techniques we could use to evaluate the reliability of tests.

19
00:01:14,960 --> 00:01:22,340
These include: Alternate forms reliability, split half reliability, and test retest reliability.

20
00:01:22,340 --> 00:01:27,590
Alternate forms reliability involves the evaluation of two different versions of the same test.

21
00:01:27,590 --> 00:01:31,899
The scores from the two tests are then compared to see if the test is actually reliable.

22
00:01:31,899 --> 00:01:36,790
For example, I would like you to imagine that my research team was awarded a million dollars

23
00:01:36,790 --> 00:01:40,170
to develop an intelligence test for university students.

24
00:01:40,170 --> 00:01:44,030
We used half of that money to develop one version of the test, and developed a second

25
00:01:44,030 --> 00:01:47,609
version of the test with the other half of the money.

26
00:01:47,609 --> 00:01:52,250
To test the reliability of our newly developed intelligence tests, we then asked a large

27
00:01:52,250 --> 00:01:57,840
sample of university students to complete both version one and version two of the tests.

28
00:01:57,840 --> 00:02:03,539
Then, we compared student’s performance on version one of the test to version two.

29
00:02:03,539 --> 00:02:05,560
We graphed it like this.

30
00:02:05,560 --> 00:02:12,790
Here, someone has scored about a 10 on version 1 of the test, and about a 10 on version 2.

31
00:02:12,790 --> 00:02:19,170
This person here scored just under 40 on version 1 and about 40 on version 2.

32
00:02:19,170 --> 00:02:25,540
This person here scored about a 70 on version 1 and about a 70 on version 2.

33
00:02:25,540 --> 00:02:26,659
What do you notice there?

34
00:02:26,659 --> 00:02:31,340
Do you notice a positive correlation between the sores from version 1 of the test and scores

35
00:02:31,340 --> 00:02:33,069
from version 2?

36
00:02:33,069 --> 00:02:36,470
As scores on one go up, they go up on the other.

37
00:02:36,470 --> 00:02:40,599
You notice that they&#39;re quite closely clustered together on that diagonal.

38
00:02:40,599 --> 00:02:44,209
There&#39;s not a lot of error or variation in where the scores fall.

39
00:02:44,209 --> 00:02:48,690
They generally increase on both at the same rate.

40
00:02:48,690 --> 00:02:52,760
If you eyeball that, that&#39;s probably a correlation of at least 0.8.

41
00:02:52,760 --> 00:02:54,550
That&#39;s a pretty good correlation.

42
00:02:54,550 --> 00:02:59,560
That would tell us our measure is reliable, because the two versions of the test are effectively

43
00:02:59,560 --> 00:03:02,490
producing the same result.

44
00:03:02,490 --> 00:03:07,200
Split half reliability also involves the evaluation of two tests.

45
00:03:07,200 --> 00:03:12,580
However sometimes, maybe due to money and/or time constraints, it might not be possible

46
00:03:12,580 --> 00:03:15,739
for researchers to develop two versions of the test.

47
00:03:15,739 --> 00:03:20,409
So when this happens, what we can do is split the one test into two tests.

48
00:03:20,409 --> 00:03:25,519
From here, we can do what we did before, which was asking a large number of university students

49
00:03:25,519 --> 00:03:29,769
to complete our single test, and then compare their performance on the first half of the

50
00:03:29,769 --> 00:03:33,459
test and their performance on the second half.

51
00:03:33,459 --> 00:03:36,170
We can graph it, and it looks exactly the same.

52
00:03:36,170 --> 00:03:40,500
It&#39;s the same data because conceptually it&#39;s exactly the same idea.

53
00:03:40,500 --> 00:03:44,420
All we’re doing here is evaluating whether or not the students are responding similarly

54
00:03:44,420 --> 00:03:48,430
between the first half of the test and the second half.

55
00:03:48,430 --> 00:03:51,980
We can do the correlation again, and it’s about 0.8.

56
00:03:51,980 --> 00:03:55,650
From this we can conclude that this test is reliable.

57
00:03:55,650 --> 00:03:57,370
Is this a good way to do it?

58
00:03:57,370 --> 00:04:01,750
Do you see any problems with just cutting one test in half as a way to evaluate test

59
00:04:01,750 --> 00:04:02,600
reliability?

