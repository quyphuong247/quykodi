1
00:00:08,403 --> 00:00:09,389
wermarter 05/08/16 Thao reviewed
Chào mừng bạn đến với chương 15.

2
00:00:09,389 --> 00:00:13,349
Chương 15 sẽ khác so với những chương trước.

3
00:00:13,349 --> 00:00:15,733
Ta sẽ thực sự làm nên những 
chương trình phức tạp hơn,

4
00:00:15,733 --> 00:00:18,830
và thực hành chương trình
nhiều bước trong chương này.

5
00:00:18,830 --> 00:00:22,730
Ta sẽ sử dụng tất cả kiến thức

6
00:00:22,730 --> 00:00:24,270
đã được học trong các chương trước.

7
00:00:24,270 --> 00:00:28,000
Nếu không hiểu được video này, bạn cần ôn lại

8
00:00:28,000 --> 00:00:32,360
tất cả những chương trước, bởi vì
ta sẽ đi rất nhanh trong chương này.

9
00:00:32,360 --> 00:00:37,310
Trong chương này, ta sẽ
kết hợp các thao tác với mạng lưới

10
00:00:37,310 --> 00:00:41,020
và viết một chương trình đọc
thông tin lấy từ mạng.

11
00:00:41,020 --> 00:00:42,230
Ta đã biết làm nó.

12
00:00:42,230 --> 00:00:47,200
Và ta cũng đã học về cơ sở dữ liệu
cũng như lập trình Python thao tác với nó.

13
00:00:47,200 --> 00:00:51,770
Nhưng giờ, ta sử dụng cơ sở dữ liệu

14
00:00:51,770 --> 00:00:56,540
như một bước trung gian, ta sẽ lấy
dữ liệu từ một nguồn thông tin.

15
00:00:56,540 --> 00:01:00,455
Dữ liệu ngày càng nhiều trên mạng,
ta thường thấy nó ở bất cứ đâu.

16
00:01:00,455 --> 00:01:03,650
And you're doing something to,
you're doing something,

17
00:01:03,650 --> 00:01:07,200
Bạn sẽ lấy dữ liệu về thông qua
Twitter API như ta đã được học, hoặc

18
00:01:07,200 --> 00:01:10,190
GeoJSON API, nhưng lưu ý
nó có một số quy định nhất định

19
00:01:10,190 --> 00:01:13,640
như là bạn phải có mã API,
hoặc giới hạn về tỉ lệ, hoặc

20
00:01:13,640 --> 00:01:15,340
thông tin có thể không đủ tin cậy.

21
00:01:15,340 --> 00:01:19,570
Ở đây ta có một quá trình lấy thông tin rất chậm,

22
00:01:19,570 --> 00:01:21,630
dữ liệu có thể không đáng tin cậy, nguy hiểm, v.v.

23
00:01:21,630 --> 00:01:23,980
Đôi khi, ta phải khởi động lại nó.

24
00:01:23,980 --> 00:01:25,427
Đây là một quá trình rất khó.

25
00:01:25,427 --> 00:01:28,027
Nó có thể mất hàng tiếng đồng hồ,

26
00:01:28,027 --> 00:01:31,440
hoặc thậm chí là nhiều ngày,
có thể nó sẽ đứt đoạn,

27
00:01:31,440 --> 00:01:34,853
có thể phải sửa chữa.
Vì vậy, quá trình lấy thông tin này

28
00:01:34,853 --> 00:01:38,135
bạn cần phải hết sức cẩn thận,
và đó cũng là lí do ta đặt thông tin vào cơ sở dữ liệu.

29
00:01:38,135 --> 00:01:41,992
Bởi vì cơ sở dữ liệu là
cách rất tốt để tránh làm mất dữ liệu.

30
00:01:41,992 --> 00:01:45,590
Thậm chí nếu bạn
gặp phải một rắc rối giữa chừng,

31
00:01:45,590 --> 00:01:47,030
dữ liệu đã được lưu vào cơ sở dữ liệu.

32
00:01:47,030 --> 00:01:51,450
Quá trình lấy thông tin có thể hình dung thế này:
Mình đã thu được bao nhiêu dữ liệu nhỉ?

33
00:01:51,450 --> 00:01:55,420
Giờ thì tiếp tục lấy thêm dữ liệu
vào cơ sở dữ liệu. Ôi, bị lỗi rồi.

34
00:01:55,420 --> 00:01:59,440
Chương trình sẽ được khởi động lại
và tiếp tục cho đến khi lấy đủ thông tin.

35
00:01:59,440 --> 00:02:01,150
OK, đã khởi động lại,
kiểm tra lượng dữ liệu đã có,

36
00:02:01,150 --> 00:02:01,999
và tiếp tục lấy thêm.

37
00:02:01,999 --> 00:02:04,893
Khi khởi động lại, quá trình sẽ thu
dữ liệu từ nguồn khác và

38
00:02:04,893 --> 00:02:07,467
tiếp tục đưa nó vào cơ sở dữ liệu.

39
00:02:07,467 --> 00:02:09,789
Cứ thực hiện như vậy rất nhiều lần
cho đến khi đủ dữ liệu.

40
00:02:09,789 --> 00:02:14,790
Như tôi đã nhắc đến trong GeoJSON,
bởi ta chỉ có thể lấy 2500 địa điểm mỗi ngày,

41
00:02:14,790 --> 00:02:20,636
nên tôi đã mất rất nhiều ngày
để có 10.000 bit dữ liệu từ Geodata API.

42
00:02:20,636 --> 00:02:24,033
Trong quá trình lấy thông tin,

43
00:02:24,033 --> 00:02:26,800
ta chưa phân tích dữ liệu.

44
00:02:26,800 --> 00:02:30,370
Do đó, phần chương trình rất đơn giản.

45
00:02:30,370 --> 00:02:32,700
Nó sẽ đọc dữ liệu và đưa vào
cơ sở dữ liệu, rồi lại đọc tiếp

46
00:02:32,700 --> 00:02:33,580
và tiếp tục đưa vào cơ sở dữ liệu.

47
00:02:33,580 --> 00:02:36,690
Giải quyết trường hợp xảy ra lỗi
khi chương trình đã hoàn thành phân nửa.

48
00:02:37,760 --> 00:02:41,940
Do đó ta chỉ cần chương trình
rất đơn giản thôi. Và khi lấy dữ liệu,

49
00:02:41,940 --> 00:02:44,960
thỉnh thoảng ta sẽ có dữ liệu thô chưa xử lý,

50
00:02:44,960 --> 00:02:49,610
vì cơ sở dữ liệu ở đây chủ yếu
để xử lý các vấn đề phức tạp

51
00:02:49,610 --> 00:02:52,790
trong quá trình thu thập dữ liệu.

52
00:02:52,790 --> 00:02:56,310
Khi có dữ liệu chưa xử lý,
bạn có thể làm một bước khác,

53
00:02:56,310 --> 00:03:00,090
một chương trình Python chạy qua
và đọc tất cả dữ liệu trong cơ sở dữ liệu.

54
00:03:00,090 --> 00:03:03,380
Chạy chương trình Python đó,
hoặc thậm chí chạy một cơ sở dữ liệu khác.

55
00:03:03,380 --> 00:03:06,190
Và bạn có thể thêm các
cơ sở dữ liệu khác ở đây nữa.

56
00:03:06,190 --> 00:03:09,520
Tóm lại ta có một quá trình đọc dữ liệu thô,

57
00:03:09,520 --> 00:03:10,860
rồi bạn có thể tạo một cơ sở dữ liệu mới.

58
00:03:10,860 --> 00:03:13,345
Một số dữ liệu có thể
trực tiếp đi vào khâu phân tích

59
00:03:13,345 --> 00:03:14,924
hoặc minh họa qua hình ảnh.

60
00:03:14,924 --> 00:03:19,217
Nhưng sau khâu xử lý ta sẽ có dữ liệu sạch.

61
00:03:19,217 --> 00:03:21,410
Đây là dữ liệu có ý nghĩa.

62
00:03:21,410 --> 00:03:23,620
Ta gọi đó là dữ liệu sạch. Sau đó ta sẽ
viết một chương trình khác.

63
00:03:23,620 --> 00:03:24,970
Bạn lưu ý các khâu này đều được
thực hiện bởi chương trình Python.

64
00:03:24,970 --> 00:03:28,780
Giờ ta sẽ chạy thêm một số chương trình Python khác.

65
00:03:28,780 --> 00:03:32,260
Chương trình này sẽ đọc từ cơ sở dữ liệu sạch,
sau đó thực hiện một số phân tích

66
00:03:32,260 --> 00:03:36,340
và in ra các thông tin hoặc
minh họa chúng bằng hình ảnh.

67
00:03:36,340 --> 00:03:38,380
Đây là các bước riêng biệt, mỗi hình chữ nhật này

68
00:03:38,380 --> 00:03:41,820
là một chương trình Python riêng biệt.

69
00:03:41,820 --> 00:03:45,880
Cho tới giờ ta vẫn thường viết 1 chương trình Python

70
00:03:45,880 --> 00:03:50,860
để đưa ra kết quả, đúng không?

71
00:03:50,860 --> 00:03:53,620
Ta viết một vòng lặp để đọc thông tin,
tạo nên một mảng và

72
00:03:53,620 --> 00:03:55,050
in mảng đó ra.

73
00:03:55,050 --> 00:03:59,170
Nhưng đối với trường hợp này, vấn đề
khó giải quyết hơn, đôi khi không đủ độ tin cậy

74
00:03:59,170 --> 00:04:04,520
và có thể chịu một số tác động bên ngoài khác,
nên ta chia chương trình ra thành từng bước nhỏ hơn.

75
00:04:04,520 --> 00:04:07,439
Ta sẽ viết một chương trình Python
cho mỗi bước trong đây.

76
00:04:07,439 --> 00:04:14,200
Tuy nhiên, những gì ta đang làm không hẳn là
khai thác dữ liệu. Cách gọi này vừa đúng lại vừa sai.

77
00:04:14,200 --> 00:04:15,806
Tôi sẽ không gọi đây là khai thác dữ liệu,

78
00:04:15,806 --> 00:04:19,110
gọi như vậy sẽ phóng đại quá mức
những gì chúng ta đang làm.

79
00:04:19,110 --> 00:04:22,430
Có rất nhiều công nghệ phức tạp trong khai thác dữ liệu

80
00:04:22,430 --> 00:04:24,000
nhưng trong khóa này ta sẽ không học đến.

81
00:04:24,000 --> 00:04:26,860
Bạn có thể học khai thác dữ liệu ở nhiều nơi khác.

82
00:04:26,860 --> 00:04:31,200
Tôi tin khoá học này sẽ tạo nền tảng tốt

83
00:04:31,200 --> 00:04:33,190
để học về công nghệ khai thác dữ liệu.

84
00:04:33,190 --> 00:04:36,030
Có nhiều nguồn mở như Hadoop và Spark.

85
00:04:36,030 --> 00:04:39,591
Amazon thậm chí có cả một
công trình khai thác dữ liệu là Redshift.

86
00:04:39,591 --> 00:04:43,458
Có rất nhiều cộng đồng về khai thác dữ liệu.

87
00:04:43,458 --> 00:04:44,254
Vân vân.

88
00:04:44,254 --> 00:04:46,599
Bạn đừng nhận lầm rằng đây đã là
mọi kiến thức về khai thác dữ liệu.

89
00:04:46,599 --> 00:04:51,699
Đây là một kiểu khai thác dữ liệu
tôi gọi là "khai thác dữ liệu cá nhân".

90
00:04:51,699 --> 00:04:56,349
Tuy nhiên, học xong điều này,
bạn vẫn chưa là một chuyên gia khai thác dữ liệu được.

91
00:04:56,349 --> 00:04:58,980
Nói như vậy là phóng đại quá mức.

92
00:04:58,980 --> 00:05:01,988
Mục đích chủ yếu của chương này là

93
00:05:01,988 --> 00:05:03,780
để bạn lập trình Python tốt hơn,

94
00:05:03,780 --> 00:05:08,196
có thể giải quyết vấn đề cơ bản
về khai thác dữ liệu bằng Python và

95
00:05:08,196 --> 00:05:13,300
tiếp tục tiến bộ trong tương lai.

96
00:05:13,300 --> 00:05:16,200
Đầu tiên ta sẽ ôn lại một vấn đề
trong chương trước,

97
00:05:16,200 --> 00:05:20,900
sử dụng Geocoding API của Google.

98
00:05:20,900 --> 00:05:24,370
Ta sẽ đưa dữ liệu vào cơ sở dữ liệu,

99
00:05:24,370 --> 00:05:28,180
rồi minh họa hình ảnh dữ liệu từ cơ sở dữ liệu đó.
Ta sẽ sử dụng Google Maps API.

100
00:05:28,180 --> 00:05:31,190
Do đó, bạn cần kết nối mạng khi
chạy chương trình này.

101
00:05:33,230 --> 00:05:37,310
Đối với một số bước trong video này,

102
00:05:37,310 --> 00:05:40,676
tôi sẽ đưa cho bạn các đưởng dẫn (URLs)
của tôi thay vì từ các trang web chính.

103
00:05:40,676 --> 00:05:44,753
Bạn cũng có thể download từ các trang web
chính thức, nhưng ta không muốn gây rối loạn

104
00:05:44,753 --> 00:05:48,073
khi quá nhiều sinh viên tham gia lớp học
sử dụng những API này quá nhiều.

105
00:05:48,073 --> 00:05:51,299
Tôi có thể nhận email than phiền về vấn đề ấy.

106
00:05:51,299 --> 00:05:56,103
Tôi sẽ đưa API của tôi cho các bạn dùng khi nào có thể.

107
00:05:56,103 --> 00:06:00,290
Và tôi sẽ đưa ra cả một video
về những chương trình này.

108
00:06:00,290 --> 00:06:00,830
Nhưng bây giờ,

109
00:06:00,830 --> 00:06:05,680
tôi sẽ chỉ giảng qua về cách thức
hoạt động của những thứ này.

110
00:06:05,680 --> 00:06:08,216
Đây là Google Geodata API,

111
00:06:08,216 --> 00:06:12,068
ta đã "nghịch" cái này trong chương trước.
Còn đây là một chương trình, geoload.py,

112
00:06:12,068 --> 00:06:15,403
Bạn có thể download các thứ này
từ đường dẫn ở phía dưới đây,

113
00:06:15,403 --> 00:06:17,105
trong đó bao gồm các file được sử dụng.

114
00:06:17,105 --> 00:06:23,170
geoload.py giống với thứ bạn đã đọc,
nó được dùng để đọc các dữ liệu JSON,

115
00:06:23,170 --> 00:06:26,720
nó sẽ vào một URL, đọc các dữ liệu JSON,
phân tích chúng và

116
00:06:26,720 --> 00:06:31,210
đưa các dữ liệu JSON đó vào cơ sở dữ liệu.

117
00:06:31,210 --> 00:06:34,720
Chương trình sẽ lấy một danh sách các địa điểm.

118
00:06:34,720 --> 00:06:36,350
Bạn có nhớ thứ đã yêu cầu các địa điểm không?

119
00:06:36,350 --> 00:06:40,520
Nó lấy dữ liệu từ where.data,
một danh sách các địa điểm.

120
00:06:40,520 --> 00:06:45,500
Danh sách có thể chứa đến
hàng trăm ngàn địa điểm.

121
00:06:45,500 --> 00:06:49,180
Và khi tìm được mỗi địa điểm,
ta thêm một hàng vào cơ sở dữ liệu của mình.

122
00:06:49,180 --> 00:06:52,320
Sau đó ta được file geodata.sqlite.

123
00:06:52,320 --> 00:06:56,180
".sqlite" là phần mở rộng của dữ liệu SQL.

124
00:06:57,560 --> 00:07:01,530
Quá trình sẽ khởi động rồi dừng,
khởi động rồi lại dừng.

125
00:07:01,530 --> 00:07:04,550
Nhưng ta chỉ lấy 2500 địa điểm mỗi ngày.

126
00:07:04,550 --> 00:07:06,930
Ta xây dựng file này một cách chậm mà chắc.

127
00:07:06,930 --> 00:07:08,270
Điều thú vị là

128
00:07:09,360 --> 00:07:13,540
mặc dù chưa lấy hết các thông tin,
bạn vẫn có thể chạy những thứ này.

129
00:07:13,540 --> 00:07:16,020
Ví dụ như bạn đã có 500 bản ghi đầu tiên.

130
00:07:16,020 --> 00:07:19,787
Bạn vẫn có thể tạo một hình ảnh đẹp
từ 500 bản ghi này và sau đó,

131
00:07:19,787 --> 00:07:22,033
bạn có thể lấy thêm 500
nữa vào ngày mai hoặc

132
00:07:22,033 --> 00:07:25,584
1000 bản nữa tuỳ thuộc vào
đường truyền mạng của bạn, v.v.

133
00:07:25,584 --> 00:07:28,509
Và đừng gây chuyện với nhà cung cấp dịch vụ mạng

134
00:07:28,509 --> 00:07:33,154
bằng việc download liên tục 24 giờ
hàng Gigabyte dữ liệu,

135
00:07:33,154 --> 00:07:35,635
đặc biệt khi bạn sử dụng thiết bị di động.

136
00:07:35,635 --> 00:07:38,070
Nhìn chung, bạn nên chú ý
lượng dữ liệu mình tải về.

137
00:07:38,070 --> 00:07:40,740
Đến một lúc nào đó các dữ liệu sẽ được lưu lại trong cache.

138
00:07:40,740 --> 00:07:45,340
Cache (hay bộ nhớ đệm) là một bản lưu
cục bộ của một dữ liệu nào đó ở nơi khác.

139
00:07:45,340 --> 00:07:49,330
Bây giờ, ta đã có một bản lưu của dữ liệu
nên không cần làm việc với Google nữa.

140
00:07:49,330 --> 00:07:51,870
Dữ liệu của ta đã lưu trong cơ sở dữ liệu.

141
00:07:51,870 --> 00:07:54,740
Tiếp theo, ta viết một chương trình nhỏ, geodump.py

142
00:07:54,740 --> 00:07:57,820
với vai trò là quét qua từng
bản ghi trong cơ sở dữ liệu,

143
00:07:57,820 --> 00:07:59,210
và lặp, lặp, lặp, lặp, lặp,...

144
00:07:59,210 --> 00:08:03,020
Nó sẽ in ra các thứ trên màn hình,

145
00:08:03,020 --> 00:08:05,210
và nó cũng lưu

146
00:08:05,210 --> 00:08:08,500
cả đống dữ liệu vào một file gọi là where.js

147
00:08:08,500 --> 00:08:14,340
Đây là một file JavaScript,
bạn có thể xem nó nếu muốn.

148
00:08:14,340 --> 00:08:16,350
Nhưng đây không phải một lớp JavaScript.

149
00:08:16,350 --> 00:08:19,130
Tôi đã đưa cho bạn một đống file HTML và JavaScript.

150
00:08:19,130 --> 00:08:24,320
Và file HTML này sẽ đọc file JavaScript.

151
00:08:24,320 --> 00:08:29,540
Sau đó, sử dụng đến Google API để
tạo nên các chấm đỏ trên sơ đồ.

152
00:08:29,540 --> 00:08:33,920
Nếu bạn thêm dữ liệu vào đây
và chạy chương trình này,

153
00:08:33,920 --> 00:08:35,320
và chạy chương trình này nữa,

154
00:08:35,320 --> 00:08:39,400
rồi refresh màn hình, bạn sẽ thấy
các chấm mới xuất hiện. OK?

155
00:08:39,400 --> 00:08:42,840
Màn hình này không đi trực tiếp
từ cơ sở dữ liệu mà thông qua

156
00:08:42,840 --> 00:08:44,730
chương trình geodump.py.

157
00:08:44,730 --> 00:08:49,070
Đến giờ, ta đã thấy một quy trình nhiều bước:
Bạn dành nhiều thời gian thu thập dữ liệu.

158
00:08:49,070 --> 00:08:50,190
Bạn làm đầy dữ liệu,

159
00:08:50,190 --> 00:08:53,010
rồi khi dữ liệu thô đã được lưu vào cache,

160
00:08:53,010 --> 00:08:55,520
bạn chạy chương trình này xem

161
00:08:55,520 --> 00:08:57,220
nó có những gì rồi minh họa qua hình ảnh. OK?

162
00:08:58,400 --> 00:09:00,630
Như tôi đã nói, trong khoá học này,

163
00:09:00,630 --> 00:09:03,920
tôi sẽ không dạy bạn cách viết từng file này,

164
00:09:03,920 --> 00:09:09,140
mặc dù trong các dự án (Capstone Course),
bạn có thể dùng đến những thứ này.

165
00:09:09,140 --> 00:09:11,880
Đây là tóm tắt cho ví dụ đầu tiên trong

166
00:09:11,880 --> 00:09:14,250
3 ví dụ mẫu về cách thực hiện
khai thác dữ liệu cá nhân.

167
00:09:14,250 --> 00:09:17,480
Trong video tới, ta sẽ nói về
thuật toán xếp hạng trang web.