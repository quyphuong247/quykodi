1
00:00:08,970 --> 00:00:13,071
dungpham12002 11.08.2016
Ví dụ thứ ba trong Chương 15 như
đưa ta về điểm xuất phát vậy.

2
00:00:13,071 --> 00:00:15,040
Ta sẽ trở lại phần về
các hộp thư chung.

3
00:00:15,040 --> 00:00:19,407
Ta sẽ thu thập một mục lưu trữ
dựa trên nền tảng web,

4
00:00:19,407 --> 00:00:21,950
như trang gmane.org.

5
00:00:21,950 --> 00:00:23,672
Nó lưu trữ các hộp thư chung,

6
00:00:23,672 --> 00:00:28,520
nên nếu một dự án kết thúc, bạn
vẫn còn lưu trữ được dữ liệu rất lâu.

7
00:00:28,520 --> 00:00:30,812
Vậy ta sẽ thu thập nó,
sử dụng cách thu thập chuẩn,

8
00:00:30,812 --> 00:00:33,470
sau đó ta sẽ phân tích
và dọn dẹp,

9
00:00:33,470 --> 00:00:38,460
bởi với mail, rắc rối là nó có thể
tồn tại đến gần mười năm.

10
00:00:38,460 --> 00:00:41,890
Sau đó, ta sẽ 
minh họa dữ liệu.

11
00:00:41,890 --> 00:00:45,830
Vậy đây sẽ là bộ dữ liệu
lớn nhất mà ta sẽ dùng để thực hành,

12
00:00:45,830 --> 00:00:47,880
mặc dù mạng thì vô cùng lớn.

13
00:00:47,880 --> 00:00:53,180
Bạn có thể thực hiện hai ví dụ đầu: thứ nhất là 
ví dụ về địa lí, với khoảng 20 bản ghi,

14
00:00:53,180 --> 00:00:56,290
và thứ hai là ví dụ xếp hạng
trang web, với khoảng 40 đến 50 trang.

15
00:00:56,290 --> 00:01:00,570
Nhưng nếu xem kích thước bộ dữ liệu,
ta thấy nó lớn hơn 1 GB.

16
00:01:00,570 --> 00:01:02,600
Nếu ta cho chạy cả đêm,

17
00:01:04,240 --> 00:01:07,360
đặc biệt nếu bạn dùng gmane.org--
một API không giới hạn số lần request-- 

18
00:01:07,360 --> 00:01:11,698
thì khi đọc trang web của họ, 
họ có nói 'đừng làm hại chúng tôi'.

19
00:01:11,698 --> 00:01:14,410
Ta không muốn viết phần mềm
giới hạn số lần request,

20
00:01:14,410 --> 00:01:16,380
nên ta cần có ý thức tốt.

21
00:01:16,380 --> 00:01:19,340
Tôi sẽ cho bạn một URL
đặc biệt ở phần bài tập

22
00:01:19,340 --> 00:01:21,970
dẫn đến một bản sao không
giới hạn số lần request của bộ dữ liệu.

23
00:01:21,970 --> 00:01:26,140
Tôi sẽ đăng lên một trong các
máy chủ của trường

24
00:01:26,140 --> 00:01:28,700
một bản sao hoàn chỉnh, và nó
không bị giới hạn lượt request.

25
00:01:28,700 --> 00:01:30,480
Vậy hãy sử dụng bản sao
không giới hạn lượt request.

26
00:01:30,480 --> 00:01:35,130
Mặc dù bạn có thể trực tiếp
tìm hiểu dữ liệu, 

27
00:01:35,130 --> 00:01:39,350
hãy sử dụng bản sao ấy
nếu có thể.

28
00:01:40,570 --> 00:01:41,570
Giờ ta sẽ bắt đầu.

29
00:01:41,570 --> 00:01:44,160
Đây sẽ là thứ phức tạp nhất
mà ta sẽ làm.

30
00:01:44,160 --> 00:01:47,035
Ta sẽ bắt đầu với quá trình thu thập.

31
00:01:47,035 --> 00:01:49,450
gmane.org có các hộp thư chung.

32
00:01:49,450 --> 00:01:51,970
Và ta sẽ thực hiện rất nhiều thứ
với chúng.

33
00:01:51,970 --> 00:01:54,880
Điều đầu tiên ta sẽ làm
là tạo ra một bản sao cục bộ.

34
00:01:54,880 --> 00:01:59,146
Quy trình chuẩn là ta sẽ truy xuất nó,
rồi đến URL, phân tích nó,

35
00:01:59,146 --> 00:02:00,504
cuối cùng là đưa nó
vào cơ sở dữ liệu.

36
00:02:00,504 --> 00:02:05,432
Vậy đây sẽ là một quy trình khá đơn giản
được lặp đi lặp lại, trong đó,

37
00:02:05,432 --> 00:02:09,564
ta có dữ liệu ở đây, rồi ta sẽ xem
cái tiếp theo là gì,

38
00:02:09,564 --> 00:02:12,830
sau đó là đến vòng lặp, đọc
và thêm vào một số dữ liệu.

39
00:02:12,830 --> 00:02:17,020
Việc gặp lỗi là hoàn toàn ổn,
bởi ta không đảo lộn quy trình.

40
00:02:17,020 --> 00:02:21,520
Vậy ta đã có bản sao cục bộ, tức một
bản sao rất thô sơ của toàn bộ dữ liệu ta có.

41
00:02:22,750 --> 00:02:27,770
Nó sẽ hơi lộn xộn hơn so với
dữ liệu mà ta từng xử lý,

42
00:02:27,770 --> 00:02:31,630
bởi nó là các email tồn tại
đến mười năm.

43
00:02:31,630 --> 00:02:35,430
Và sẽ có rất nhiều dữ liệu
trong bộ dữ liệu này;

44
00:02:35,430 --> 00:02:36,670
nó có dung lượng lớn hơn 1GB.

45
00:02:38,100 --> 00:02:41,254
Đúng không? Nó chưa được nén
và phân tích.

46
00:02:41,254 --> 00:02:43,599
Và nếu ta phân tích bản sao cục bộ,

47
00:02:43,599 --> 00:02:46,789
thì tùy thuộc vào tốc độ của máy tính bạn,
nó có thể mất vài phút,

48
00:02:46,789 --> 00:02:50,740
thậm chí là vài giờ chỉ để đọc hết
dữ liệu và phân tích.

49
00:02:50,740 --> 00:02:52,710
Việc ta sẽ làm bây giờ là tạo ra
cơ sở dữ liệu thứ hai,

50
00:02:52,710 --> 00:02:55,680
trong đó có nhiều bảng.

51
00:02:55,680 --> 00:02:56,980
Ta sẽ sử dụng dạng chuẩn 3 - 3NF.

52
00:02:56,980 --> 00:02:58,760
Bạn còn nhớ khái niệm này
ở bài giảng trước không?

53
00:02:58,760 --> 00:03:01,160
Trong dạng chuẩn 3,
sẽ có các khóa là các số nguyên.

54
00:03:01,160 --> 00:03:02,090
Bạn còn nhớ điều đó không?

55
00:03:02,090 --> 00:03:02,790
Phải vậy không?

56
00:03:02,790 --> 00:03:05,770
Vậy đây sẽ là một cơ sở dữ liệu
được tạo ra một cách rất thông minh,

57
00:03:05,770 --> 00:03:09,430
nghĩa là nó sẽ có kích thước nhỏ hơn
do có ít dữ liệu thừa hơn.

58
00:03:09,430 --> 00:03:13,460
Và khi bạn cho chạy gmodel.py, một tập tin 
sử dụng dữ liệu từ cơ sở dữ liệu này,

59
00:03:13,460 --> 00:03:17,860
hãy suy nghĩ về thời gian cần có
để chạy gmodel.py,

60
00:03:17,860 --> 00:03:20,050
so với khi ta đã
làm sạch dữ liệu.

61
00:03:20,050 --> 00:03:24,060
Đó là lý do vì sao 
ta cần có bước làm sạch dữ liệu.

62
00:03:24,060 --> 00:03:27,220
Ta thường không làm bước này
khi đang chạy tập tin này, bởi

63
00:03:27,220 --> 00:03:31,830
ta sẽ tập trung vào khả năng tái khởi động, 
tính đáng tin cậy và sự đơn giản,

64
00:03:31,830 --> 00:03:35,080
bởi ta có thể biết thêm
điều gì đó về dữ liệu.

65
00:03:35,080 --> 00:03:37,950
Ta sẽ giữ lại dữ liệu thô sơ,
và phân tích lại mỗi khi ta cần.

66
00:03:37,950 --> 00:03:41,460
Vậy có thể bạn sẽ phải sửa code
thường xuyên hơn khi nhận ra rằng

67
00:03:41,460 --> 00:03:43,420
'Trong dữ liệu có thêm một lỗi nữa.

68
00:03:43,420 --> 00:03:47,220
Tôi sẽ phải chạy lại tập tin chuyển
dữ liệu thô sơ thành dữ liệu sạch.'

69
00:03:47,220 --> 00:03:48,860
Đây sẽ là dữ liệu sạch.

70
00:03:48,860 --> 00:03:52,600
Nó sẽ nhỏ hơn về kích thước,
đã được chuẩn hóa và dọn sạch.

71
00:03:52,600 --> 00:03:58,640
Nó sẽ là một cơ sở dữ liệu được sắp xếp
hợp lí, với dữ liệu nhỏ hơn lúc trước rất nhiều.

72
00:03:58,640 --> 00:04:02,390
Bây giờ, ta đã có tất cả dữ liệu
trong một cơ sở dữ liệu sạch

73
00:04:02,390 --> 00:04:05,010
với nhiều bảng trong ấy -- content.sqlite.

74
00:04:05,010 --> 00:04:08,270
Do vậy, ta có thể chạy một số
chương trình dựa vào nó, được chứ?

75
00:04:08,270 --> 00:04:10,170
Đây chính là phần phân tích.

76
00:04:10,170 --> 00:04:13,820
Đây sẽ là quá trình làm sạch,
quá trình thu thập và quá trình phân tích.

77
00:04:13,820 --> 00:04:17,390
Tôi đang chỉ cho bạn cách
để có một đường dẫn dữ liệu vào,

78
00:04:17,390 --> 00:04:21,480
rồi sau đó thực hiện các phân tích khác nhau 
với dữ liệu sạch.

79
00:04:21,480 --> 00:04:24,700
Vậy đây sẽ là một vòng lặp,
gửi một lệnh SQL

80
00:04:24,700 --> 00:04:26,280
yêu cầu chương trình
đọc hết dữ liệu.

81
00:04:26,280 --> 00:04:30,210
Sau đó nó sẽ làm một số việc,
như tạo một dictionary,

82
00:04:30,210 --> 00:04:34,910
tính xem 5 người gửi nhiều email nhất
trong hộp thư chung này là những ai,

83
00:04:34,910 --> 00:04:36,410
hay tính xem 5 tổ chức nào
gửi nhiều email nhất.

84
00:04:36,410 --> 00:04:40,220
Nó sẽ rất giống với các chương trình 
mà bạn đã viết trước đây.

85
00:04:40,220 --> 00:04:43,660
Parse, read, split, dictionary, get,

86
00:04:43,660 --> 00:04:46,540
bạn đã làm việc
với chúng hết rồi, đúng không?

87
00:04:46,540 --> 00:04:49,520
Giờ là lúc áp dụng chúng đó.
Ta thấy cách áp dụng rất giống nhau, trừ việc

88
00:04:49,520 --> 00:04:53,790
nguồn dữ liệu ở đây là dữ liệu
ta đã thu thập và dọn sạch.

89
00:04:53,790 --> 00:04:56,270
Ta còn có một chương trình
giúp tạo ra word map.

90
00:04:56,270 --> 00:04:58,470
Nó sẽ lấy thứ gì đó
tương tự như thế này.

91
00:04:58,470 --> 00:05:02,380
Thay vì tìm địa chỉ mail trong trường 'From',
nó sẽ lấy phần nội dung thư,

92
00:05:02,380 --> 00:05:05,921
rồi tách riêng lẻ các từ ra,
và bỏ đi những thứ khác,

93
00:05:05,921 --> 00:05:11,700
sau đó phân tích tần suất của các từ,
và trả lại kết quả dưới dạng JSON.

94
00:05:11,700 --> 00:05:13,580
Vậy khi chương trình gword.py chạy,

95
00:05:13,580 --> 00:05:16,510
nó sẽ tạo ra gword.js,
và bạn có thể xem tập tin này.

96
00:05:16,510 --> 00:05:19,990
Bạn sẽ thấy có các dấu ngoặc nhọn,
dấu chấm phẩy, dấu ngoặc ' ', v.v...

97
00:05:19,990 --> 00:05:24,760
nó thực ra chỉ dùng để ngăn cách
giữa từ và tần suất của nó.

98
00:05:24,760 --> 00:05:28,340
Ta sẽ sử dụng word map
để làm một 'đám mây chữ' - word cloud.

99
00:05:28,340 --> 00:05:31,110
Nó trông rất đẹp,
và tôi nhắc lại rằng

100
00:05:31,110 --> 00:05:34,565
làm các word map là
một chức năng của công cụ d3.js.

101
00:05:34,565 --> 00:05:37,737
Tôi không phải lo về nó,
bởi tôi đã tải nó,

102
00:05:37,737 --> 00:05:39,629
và tôi cũng đã viết xong gword.htm.

103
00:05:39,629 --> 00:05:40,940
Bạn không cần phải thay đổi gì cả.

104
00:05:40,940 --> 00:05:44,400
Bạn có thể làm vậy, nhất là khi
bạn thông thạo JavaScript,

105
00:05:44,400 --> 00:05:46,380
ngoài ra, bạn còn có thể tự
minh họa dữ liệu.

106
00:05:46,380 --> 00:05:48,890
Các tập tin đó sẽ được tải
và được đọc,

107
00:05:48,890 --> 00:05:53,390
rồi kết hợp với việc lấy dữ liệu từ gword.js
để tạo ra một word cloud cho bạn

108
00:05:53,390 --> 00:05:54,790
và nó trông rất đẹp.

109
00:05:54,790 --> 00:05:55,990
Vậy ta đã tạo xong một word cloud.

110
00:05:55,990 --> 00:06:01,890
Tương tự như vậy, ta sẽ xây dựng quy trình
để xuất biểu đồ thể hiện số email mỗi tổ chức gửi.

111
00:06:01,890 --> 00:06:06,550
Sẽ có một chương trình đọc
tất cả dữ liệu trong gline.py.

112
00:06:06,550 --> 00:06:13,630
Sau đó một tập tin JSON và gline.js
được tạo. Còn đây là một

113
00:06:13,630 --> 00:06:18,690
trang web minh họa dữ liệu. Nó sẽ đọc
gline.js và dùng d3.js để minh họa dữ liệu.

114
00:06:18,690 --> 00:06:21,130
Bạn không cần phải
viết những thứ này,

115
00:06:21,130 --> 00:06:25,240
những thứ này cũng vậy; nhưng chúng 
sẽ tạo ra những biểu đồ đường đẹp cho bạn.

116
00:06:25,240 --> 00:06:31,100
Thực ra phần lớn code
không có vai trò quan trọng.

117
00:06:31,100 --> 00:06:33,490
Câu hỏi thú vị hơn là: 
Qua quan sát,

118
00:06:33,490 --> 00:06:37,000
ta hiểu được gì về cách hoạt động
của chương trình thu thập dữ liệu

119
00:06:37,000 --> 00:06:38,980
và chương trình dọn sạch dữ liệu,

120
00:06:38,980 --> 00:06:41,000
cũng như câu hỏi:
Cấu trúc dữ liệu nên trông như thế nào?,

121
00:06:41,000 --> 00:06:43,430
Làm thế nào để thể hiện
dữ liệu sạch trong mô hình dữ liệu?,

122
00:06:43,430 --> 00:06:47,460
Làm thế nào để viết
các chương trình phân tích?,

123
00:06:47,460 --> 00:06:50,950
và tìm hiểu một trong nhiều
kĩ thuật để minh họa dữ liệu.

124
00:06:50,950 --> 00:06:55,550
Tôi dùng d3.js, bởi vì
nó được sử dụng rộng rãi,

125
00:06:55,550 --> 00:06:59,950
và nó cũng hoạt động được trong một trình duyệt web, 
nên bạn không phải tải thêm phần mềm khác.

126
00:06:59,950 --> 00:07:05,570
Bây giờ, ta sẽ quan sát
quy trình nhiều bước phức tạp nhất;

127
00:07:05,570 --> 00:07:07,990
cũn như là quan sát cách
hoạt động của từng phần.

128
00:07:09,660 --> 00:07:12,120
Như tôi đã nói, đây là trang gmane.

129
00:07:12,120 --> 00:07:13,590
Họ đang cố nhắc bạn có ý thức.

130
00:07:13,590 --> 00:07:15,770
Bạn nhớ sử dụng URL này.

131
00:07:15,770 --> 00:07:19,320
Tôi sẽ làm sao cho nó
có API giống với bản của gmane.

132
00:07:19,320 --> 00:07:23,160
Nó sẽ tạo ra một bản sao cục bộ tốt,
để ta không làm quá tải máy chủ của gmane,

133
00:07:23,160 --> 00:07:26,650
kể cả khi có tận 100000 người
muốn tải bộ dữ liệu hơn 1GB.

134
00:07:26,650 --> 00:07:29,490
Tôi sẽ cố nghĩ ra cách
để điều ấy xảy ra.

135
00:07:29,490 --> 00:07:34,347
Vậy, tóm lại, ta đã được xem ba ví dụ
cho một quy trình nhiều bước

136
00:07:34,347 --> 00:07:35,837
để bước đầu khai thác dữ liệu.

137
00:07:35,837 --> 00:07:40,004
Tôi nhấn mạnh là đây không phải là
tất cả những gì về khai thác dữ liệu.

138
00:07:40,004 --> 00:07:42,837
Khai thác dữ liệu 
phức tạp hơn thế này rất nhiều.

139
00:07:42,837 --> 00:07:46,004
Đây chỉ là một quy trình nhiều bước
được thực hiện chỉ với Python.

140
00:07:46,004 --> 00:07:50,422
Mục tiêu của tôi là cho bạn xem
một số chương trình phức tạp hơn;

141
00:07:50,422 --> 00:07:53,731
vì vậy trong các bài tiếp theo,
tôi sẽ cố đề cập đến chúng,

142
00:07:53,731 --> 00:07:57,096
để bạn có thể thấy tất cả các kĩ thuật
mỗi chương trình sử dụng để thực hiện

143
00:07:57,096 --> 00:07:58,255
những việc nó cần làm.