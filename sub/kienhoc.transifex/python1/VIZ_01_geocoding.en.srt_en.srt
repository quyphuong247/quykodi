1
00:00:08,403 --> 00:00:09,389
https://youtu.be/dPdPyM-nBx8
Welcome to Chapter 15.

2
00:00:09,389 --> 00:00:13,349
We're going to have a little bit of
a different take on Chapter 15.

3
00:00:13,349 --> 00:00:15,733
We're actually going to make
more complex programs, and

4
00:00:15,733 --> 00:00:18,830
we're going to actually do
multi-step programs in this chapter.

5
00:00:18,830 --> 00:00:22,730
And we're really just applying
all of the skills that we

6
00:00:22,730 --> 00:00:24,270
gained in the first chapters.

7
00:00:24,270 --> 00:00:28,000
And if you don't understand this material,
you really need to go back and

8
00:00:28,000 --> 00:00:32,360
review all those other chapters because
we're going to start moving pretty fast.

9
00:00:32,360 --> 00:00:37,310
So what we're really going to work on is
we're going to combine the act of working

10
00:00:37,310 --> 00:00:41,020
across the networks and we wrote a program
that read some stuff off the network.

11
00:00:41,020 --> 00:00:42,230
We've done that.

12
00:00:42,230 --> 00:00:47,200
We've looked at databases and how Python
programs can put stuff in databases.

13
00:00:47,200 --> 00:00:51,770
But now what we're going to do is
we're going to use a database as

14
00:00:51,770 --> 00:00:56,540
an intermediate step and we're going to be
gathering from some kind of a data source.

15
00:00:56,540 --> 00:01:00,455
Increasingly, data is found on the Web,
often you find it in the wild.

16
00:01:00,455 --> 00:01:03,650
And you're doing something to,
you're doing something,

17
00:01:03,650 --> 00:01:07,200
you're pulling something from a Twitter
API like we did in the previous, or

18
00:01:07,200 --> 00:01:10,190
a GeoJSON API but
then there's some rules about it.

19
00:01:10,190 --> 00:01:13,640
You might have to have an API key or
you might have a rate limit or

20
00:01:13,640 --> 00:01:15,340
it might even be unreliable.

21
00:01:15,340 --> 00:01:19,570
And so you have this gathering process
that basically says look, this is slow,

22
00:01:19,570 --> 00:01:21,630
yucky, unreliable, dangerous, and

23
00:01:21,630 --> 00:01:23,980
you might want to start this up and
then restart it.

24
00:01:23,980 --> 00:01:25,427
This is a hard process.

25
00:01:25,427 --> 00:01:28,027
This might take hours of time.

26
00:01:28,027 --> 00:01:31,440
It might even take days and it might
break and it might get fixed, right?

27
00:01:31,440 --> 00:01:34,853
And it might break and it might get fixed.
And so this gathering process is something

28
00:01:34,853 --> 00:01:38,135
we want to be real careful, and that's why
we tend to put the data in a database.

29
00:01:38,135 --> 00:01:41,992
Because databases are really good
at sort of not losing data and

30
00:01:41,992 --> 00:01:45,590
you're halfway through,
and something blows up,

31
00:01:45,590 --> 00:01:47,030
the data you have is in the database.

32
00:01:47,030 --> 00:01:51,450
And so the gathering, in many ways, it'll
be like, okay how much data do I have?

33
00:01:51,450 --> 00:01:55,420
Now I'm going to go get some more data,
put this in the database, oop, we blew up.

34
00:01:55,420 --> 00:01:59,440
So now we're going to run again,
we're going to start up again.

35
00:01:59,440 --> 00:02:01,150
Okay, start up. Let's
look at how much we got.

36
00:02:01,150 --> 00:02:01,999
We got more now.

37
00:02:01,999 --> 00:02:04,893
We're going to start at a different
place looking at the data and

38
00:02:04,893 --> 00:02:07,467
we're going to gather that and
add it on in the database.

39
00:02:07,467 --> 00:02:09,789
And we might have to do
this many, many times.

40
00:02:09,789 --> 00:02:14,790
As I mention in the GeoJSON thing,
because there's only 2500,

41
00:02:14,790 --> 00:02:20,636
it took me several days to get through
10,000 bits of data from the Geodata API.

42
00:02:20,636 --> 00:02:24,033
And what we tend to do is
in this gathering process,

43
00:02:24,033 --> 00:02:26,800
we tend not to do any
analysis of the data.

44
00:02:26,800 --> 00:02:30,370
We're just, like,
we keep these programs relatively simple.

45
00:02:30,370 --> 00:02:32,700
They read something,
they stick it in the database, read it,

46
00:02:32,700 --> 00:02:33,580
stick it in the database,

47
00:02:33,580 --> 00:02:36,690
deal with the fact that you've been blown
up and have to start halfway through.

48
00:02:37,760 --> 00:02:41,940
So we keep these really very simple.
And then we get our data and

49
00:02:41,940 --> 00:02:44,960
in here sometimes we'll have very raw data

50
00:02:44,960 --> 00:02:49,610
because we're really focusing this
database on handling the complex

51
00:02:49,610 --> 00:02:52,790
management of the problems that you
have while you're gathering the data.

52
00:02:52,790 --> 00:02:56,310
So at some point you've got your raw
data and you may have a separate step

53
00:02:56,310 --> 00:03:00,090
that is a Python program that goes through
and reads all the data in this database,

54
00:03:00,090 --> 00:03:03,380
runs a Python program, and
might even run another database.

55
00:03:03,380 --> 00:03:06,190
And frankly, you could have more
databases here, etc.

56
00:03:06,190 --> 00:03:09,520
But some process that basically
reads the raw data. And

57
00:03:09,520 --> 00:03:10,860
then you might write another database.

58
00:03:10,860 --> 00:03:13,345
Some of these will just actually
go straight to analysis or

59
00:03:13,345 --> 00:03:14,924
visualization in our earlier ones.

60
00:03:14,924 --> 00:03:19,217
But in later, what we'll do is have
this pretty data, this is the clean data.

61
00:03:19,217 --> 00:03:21,410
This is the data that makes sense, right?

62
00:03:21,410 --> 00:03:23,620
It's the clean data. And
then we're going to write another.

63
00:03:23,620 --> 00:03:24,970
So each one of these are Python program,

64
00:03:24,970 --> 00:03:28,780
Python program, and now we're going to run
maybe couple other Python programs.

65
00:03:28,780 --> 00:03:32,260
This is going to read from the clean database
and do some analysis and print us up some

66
00:03:32,260 --> 00:03:36,340
data or it might read from the clean database
and then try to visualize the results.

67
00:03:36,340 --> 00:03:38,380
And so, these are separate steps and

68
00:03:38,380 --> 00:03:41,820
each of these boxes is
a separate Python program.

69
00:03:41,820 --> 00:03:45,880
Now in a way, everything we've
done up to this point has been

70
00:03:45,880 --> 00:03:50,860
write one Python program to
produce some result, right?

71
00:03:50,860 --> 00:03:53,620
And we write a loop, and we read
the stuff, and we make an array, and

72
00:03:53,620 --> 00:03:55,050
then we print the array out.

73
00:03:55,050 --> 00:03:59,170
But in this, because the problem is harder
to solve and there's unreliability and

74
00:03:59,170 --> 00:04:04,520
other external things, we will basically
break it into multiple steps.

75
00:04:04,520 --> 00:04:07,439
And we'll write a little Python
program for each of these steps.

76
00:04:07,439 --> 00:04:14,200
Now what we're working on is not exactly
data mining. It is and it isn't.

77
00:04:14,200 --> 00:04:15,806
I don't call this data mining,

78
00:04:15,806 --> 00:04:19,110
because that would be
overstating what we're doing.

79
00:04:19,110 --> 00:04:22,430
There are many very complex
data mining technologies and

80
00:04:22,430 --> 00:04:24,000
that's not what we're going
to cover in this course.

81
00:04:24,000 --> 00:04:26,860
There are other places that you
can learn about data mining and

82
00:04:26,860 --> 00:04:31,200
I'd like to think that our course that
we're doing here is a good preparation for

83
00:04:31,200 --> 00:04:33,190
learning about data mining technology.

84
00:04:33,190 --> 00:04:36,030
So there's open source things
like Hadoop and Spark.

85
00:04:36,030 --> 00:04:39,591
Amazon has a whole data mining
operation called Redshift.

86
00:04:39,591 --> 00:04:43,458
And there's many community source, and
then dot, dot, dot, dot, dot, dot, dot,

87
00:04:43,458 --> 00:04:44,254
dot, dot, dot.

88
00:04:44,254 --> 00:04:46,599
And so, don't assume that this
is all there is to data mining.

89
00:04:46,599 --> 00:04:51,699
This is a particular style of data mining
that I call "Personal Data Mining", right?

90
00:04:51,699 --> 00:04:56,349
And it is not to say that once you're done
with this you're a data mining expert,

91
00:04:56,349 --> 00:04:58,980
because that would be a gross overstatement.

92
00:04:58,980 --> 00:05:01,988
We're really more interested
in this chapter on making

93
00:05:01,988 --> 00:05:03,780
you better Python programmers

94
00:05:03,780 --> 00:05:08,196
by solving some simple rudimentary data
mining problems with Python programs and

95
00:05:08,196 --> 00:05:13,300
then looking at those Python programs and
becoming better Python programmers.

96
00:05:13,300 --> 00:05:16,200
So the first thing that we're going to do
is we're going to build on something that we

97
00:05:16,200 --> 00:05:20,900
did in the last chapter, and
that is talk to Google's Geocoding API.

98
00:05:20,900 --> 00:05:24,370
And pull some data into a database
and then

99
00:05:24,370 --> 00:05:28,180
visualize something out of that database.
And we're going to use the Google Maps API.

100
00:05:28,180 --> 00:05:31,190
So you do need to be connected to
the Internet when you do this.

101
00:05:33,230 --> 00:05:37,310
And so, here we go, and of course,
whenever you're doing any of these things,

102
00:05:37,310 --> 00:05:40,676
I will generally give you URLs to
use other than the official URLs.

103
00:05:40,676 --> 00:05:44,753
You can use the official URLs, but at some
point, we don't want them to get annoyed

104
00:05:44,753 --> 00:05:48,073
with so many students taking the class and
pounding all of these APIs,

105
00:05:48,073 --> 00:05:51,299
I'll get some kind of email that
says quit talking about our API.

106
00:05:51,299 --> 00:05:56,103
So I will, whenever possible, give you my
own API to use for these kinds of things

107
00:05:56,103 --> 00:06:00,290
and I'll give you a whole video
showing you these programs in action.

108
00:06:00,290 --> 00:06:00,830
But right now,

109
00:06:00,830 --> 00:06:05,680
I just want to show you the general outline
of the picture of how these things work.

110
00:06:05,680 --> 00:06:08,216
And so we do have the Google Geodata
API here.

111
00:06:08,216 --> 00:06:12,068
We have played with this before. And so
if you look at this program, geoload.py,

112
00:06:12,068 --> 00:06:15,403
by the way, you download all
this stuff from right there, and

113
00:06:15,403 --> 00:06:17,105
these are just files in there.

114
00:06:17,105 --> 00:06:23,170
geoload.py is a lot like the thing that
you read before that reads some JSON,

115
00:06:23,170 --> 00:06:26,720
hits a URL, reads some JSON,
parses some JSON, and

116
00:06:26,720 --> 00:06:31,210
then writes the JSON into a database,
right?

117
00:06:31,210 --> 00:06:34,720
And this actually takes
as a list of locations.

118
00:06:34,720 --> 00:06:36,350
So if you remember the other thing
asking you for

119
00:06:36,350 --> 00:06:40,520
each location, this actually takes
where.data, which is a list of locations.

120
00:06:40,520 --> 00:06:45,500
And this can have thousands or even
hundreds of thousands of locations, and

121
00:06:45,500 --> 00:06:49,180
then as we retrieve each location,
we put lines in our database.

122
00:06:49,180 --> 00:06:52,320
And this ends up in a file
called geodata.sqlite.

123
00:06:52,320 --> 00:06:56,180
.sqlite is the suffix for SQL data.

124
00:06:57,560 --> 00:07:01,530
And so, this will run and this can
start and stop, and start and stop.

125
00:07:01,530 --> 00:07:04,550
And remember this is only
2500 of these per day.

126
00:07:04,550 --> 00:07:06,930
Start and stop and slowly but
surely, we build this up.

127
00:07:06,930 --> 00:07:08,270
Now the interesting thing is,

128
00:07:09,360 --> 00:07:13,540
even if you haven't got all the data
you can still run these other things,

129
00:07:13,540 --> 00:07:16,020
because let's say you've got the first
500 of these records.

130
00:07:16,020 --> 00:07:19,787
Well, you can still make a pretty picture
of 500 records and then later

131
00:07:19,787 --> 00:07:22,033
the next day you can
then go get 500 more or

132
00:07:22,033 --> 00:07:25,584
1000 more depending on your
network connection, etc., etc.

133
00:07:25,584 --> 00:07:28,509
And also don't get yourself in trouble
with your network service provider

134
00:07:28,509 --> 00:07:33,154
by running these things 24 hours a day
and downloading gigabytes of data, and

135
00:07:33,154 --> 00:07:35,635
all of a sudden you're
on some mobile device, and so

136
00:07:35,635 --> 00:07:38,070
just be care how much
data that you download.

137
00:07:38,070 --> 00:07:40,740
So at some point you have the data cached.

138
00:07:40,740 --> 00:07:45,340
We use the word cache, which is kind of a
local copy of something that's elsewhere.

139
00:07:45,340 --> 00:07:49,330
So we've got a nice copy. So now we
don't need to talk to Google any more.

140
00:07:49,330 --> 00:07:51,870
We've got all of our data
sitting in this database, so

141
00:07:51,870 --> 00:07:54,740
we will write a little
program called geodump.py

142
00:07:54,740 --> 00:07:57,820
And it will write a loop that's going to loop
through all the records in this database,

143
00:07:57,820 --> 00:07:59,210
loop, loop, loop, loop, loop.

144
00:07:59,210 --> 00:08:03,020
And this one prints it out, just on
the screen and it tells you, oh yeah,

145
00:08:03,020 --> 00:08:05,210
and I also wrote as a side effect

146
00:08:05,210 --> 00:08:08,500
a bunch of the data into
a file called where.js

147
00:08:08,500 --> 00:08:14,340
This is a JavaScript file and
you can take a look at it.

148
00:08:14,340 --> 00:08:16,350
This is not a JavaScript class.

149
00:08:16,350 --> 00:08:19,130
And what I've given you is I've given
you a whole bunch of HTML and

150
00:08:19,130 --> 00:08:24,320
JavaScript that takes care of all this and
this HTML file reads this JavaScript file.

151
00:08:24,320 --> 00:08:29,540
And then calls the Google API to make all
the little dots on the map for you, right?

152
00:08:29,540 --> 00:08:33,920
And so if you in effect pull more data in,
and then run this program, and

153
00:08:33,920 --> 00:08:35,320
then run the program, and

154
00:08:35,320 --> 00:08:39,400
then hit refresh on the screen, new
little dots will start popping up. Okay?

155
00:08:39,400 --> 00:08:42,840
Now, the screen doesn't
actually go straight to the database

156
00:08:42,840 --> 00:08:44,730
you have to run the geodump.py

157
00:08:44,730 --> 00:08:49,070
But now we're kind of seeing this multi-step
process, where you do this for a while.

158
00:08:49,070 --> 00:08:50,190
You get your data filled up, and

159
00:08:50,190 --> 00:08:53,010
then you say oh I've got
myself some nice raw data here

160
00:08:53,010 --> 00:08:55,520
that's been cached and
now I'm going to run it.

161
00:08:55,520 --> 00:08:57,220
See what's going on and
then I'll visualize it. Okay? 

162
00:08:58,400 --> 00:09:00,630
Like I said, I'm not going to teach you

163
00:09:00,630 --> 00:09:03,920
in this class exactly how to write
each one of these things, although in

164
00:09:03,920 --> 00:09:09,140
the Capstone some of you may play around
a bit with doing those kinds of things.

165
00:09:09,140 --> 00:09:11,880
So this is the summary
of our first of three

166
00:09:11,880 --> 00:09:14,250
examples of how we're going to
do this personal data mining.

167
00:09:14,250 --> 00:09:17,480
So we'll see you in the next one where
we'll talk about page rank algorithm.