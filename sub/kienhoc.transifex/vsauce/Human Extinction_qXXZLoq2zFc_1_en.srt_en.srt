1
00:00:00,329 --> 00:00:04,838
Hey, Vsauce. Michael here.
Do you want to be infected with Ebola

2
00:00:04,839 --> 00:00:08,370
without having to leave your own home or
deal with other people?

3
00:00:08,369 --> 00:00:13,669
Well, you might be in luck. You can
already download an Ebola virus

4
00:00:13,669 --> 00:00:14,379
genome.

5
00:00:14,380 --> 00:00:17,769
Right here on the Internet, right now.
And if you're willing to wait

6
00:00:17,769 --> 00:00:21,948
a few years for 3D bioprinting
technology to progress

7
00:00:21,949 --> 00:00:26,720
a little bit, you can just acquire one
then, submit the genome to it

8
00:00:26,719 --> 00:00:30,250
and ta da! All you can print Ebola.

9
00:00:30,250 --> 00:00:35,939
Or anthrax or whatever it is you wish to
mass-produce at home

10
00:00:35,939 --> 00:00:38,379
to wipe out humanity.

11
00:00:40,679 --> 00:00:42,520
Are humans going to go extinct

12
00:00:42,520 --> 00:00:46,530
soon? Will human extinction be

13
00:00:46,530 --> 00:00:49,989
anthropogenic? That is the result of human

14
00:00:49,988 --> 00:00:53,549
action. Or will it be one of the good old-fashioned kinds

15
00:00:53,549 --> 00:00:57,448
of extinction Earth's history knows pretty well?

16
00:00:57,448 --> 00:01:02,358
The Global Catastrophic Risks Survey,
issued by Oxford University's

17
00:01:02,359 --> 00:01:06,469
Future of Humanity Institute placed our risk of extinction

18
00:01:06,469 --> 00:01:10,950
before the year 2100 at 19%.

19
00:01:10,950 --> 00:01:15,969
Now, you might be thinking "whatever, blah
blah blah armageddon".

20
00:01:15,969 --> 00:01:19,400
"It'll be okay, humans are too smart

21
00:01:19,400 --> 00:01:22,859
to go extinct." Maybe you're right.

22
00:01:22,859 --> 00:01:25,569
But it's difficult to predict the distant future

23
00:01:25,569 --> 00:01:29,009
with a lot of certainty. What's really cool though

24
00:01:29,010 --> 00:01:32,990
is that if you embrace that uncertainty,
a simple argument

25
00:01:32,989 --> 00:01:37,329
can show that human extinction soon is actually

26
00:01:37,329 --> 00:01:41,359
more probable. It's called the Doomsday

27
00:01:41,359 --> 00:01:44,379
argument. Imagine a giant

28
00:01:44,379 --> 00:01:47,539
urn that contains either 10 balls

29
00:01:47,540 --> 00:01:51,259
numbered 1 to 10, or a million balls

30
00:01:51,259 --> 00:01:54,399
numbered 1 to a million. Now, you don't know

31
00:01:54,399 --> 00:01:58,000
which is the case, but you are allowed to pull out

32
00:01:58,000 --> 00:02:01,289
one ball. You go ahead and do that

33
00:02:01,289 --> 00:02:05,769
and it is ball number 4.

34
00:02:05,769 --> 00:02:10,000
That's pretty strong evidence in favour
of the 10 ball condition

35
00:02:10,000 --> 00:02:13,750
because drawing a four from a set of 1 through 10

36
00:02:13,750 --> 00:02:18,370
is a one in 10 chance. But drawing four
from a million different numbers

37
00:02:18,370 --> 00:02:21,650
is a one in a million chance.

38
00:02:21,650 --> 00:02:25,099
By analogy you are also a numbered

39
00:02:25,110 --> 00:02:28,470
ball. You are a human who knows

40
00:02:28,469 --> 00:02:31,789
approximately what your birth number is.

41
00:02:31,789 --> 00:02:35,048
It's probably somewhere around 100

42
00:02:35,049 --> 00:02:38,120
billion. That's how many other humans

43
00:02:38,120 --> 00:02:41,539
were most likely born before you were.

44
00:02:41,539 --> 00:02:45,039
Importantly, you didn't get to decide which birth number

45
00:02:45,039 --> 00:02:49,169
you would have. So, just like the number for a ball,

46
00:02:49,169 --> 00:02:53,419
you are a random sample from the set of all humans

47
00:02:53,419 --> 00:02:57,548
who will ever live. The Doomsday argument points out

48
00:02:57,549 --> 00:03:02,519
that from 200 billion people there's a
50 percent chance that a randomly chosen

49
00:03:02,519 --> 00:03:03,539
person,

50
00:03:03,539 --> 00:03:06,810
like you, would be born in the first one hundred billion.

51
00:03:06,810 --> 00:03:09,870
Whereas if there will be 10 trillion humans,

52
00:03:09,870 --> 00:03:13,950
there's only a one percent chance that any given human,

53
00:03:13,949 --> 00:03:17,208
say you, would happen to be born within the first

54
00:03:17,209 --> 00:03:21,439
100 billion. Either you are special

55
00:03:21,439 --> 00:03:27,050
and lucky to be born so improbably
early in the story of humanity

56
00:03:27,050 --> 00:03:30,390
or your birth number is to be expected

57
00:03:30,389 --> 00:03:33,839
because there will not be tens of trillions of humans.

58
00:03:33,840 --> 00:03:37,390
Human extinction will be sooner

59
00:03:37,389 --> 00:03:41,729
rather than later. But before you become

60
00:03:41,729 --> 00:03:46,439
too convinced that the end is nigh, keep
in mind that the Doomsday argument is

61
00:03:46,439 --> 00:03:47,240
not

62
00:03:47,240 --> 00:03:50,730
uncontroversial. One problem it might have

63
00:03:50,729 --> 00:03:54,560
is a reference class problem. Are you really a

64
00:03:54,560 --> 00:03:57,920
random sample from the set of all humans who will ever

65
00:03:57,919 --> 00:04:03,019
be born? Well, if you believe that in the
not so distant future

66
00:04:03,020 --> 00:04:06,420
humans will be quite different than they are today.

67
00:04:06,419 --> 00:04:09,459
For instance, there'll be full of more 3D printed

68
00:04:09,460 --> 00:04:13,800
organs. The mere fact that right now
there aren't very many humans

69
00:04:13,800 --> 00:04:17,660
with that trait could be evidence that
you aren't a random sample from the

70
00:04:17,660 --> 00:04:18,920
set of all humans,

71
00:04:18,920 --> 00:04:22,150
just from the set of all humans like

72
00:04:22,149 --> 00:04:25,959
you, like does around you. Those born

73
00:04:25,959 --> 00:04:29,649
earlier in human history. Also

74
00:04:29,649 --> 00:04:32,909
the Doomsday argument
doesn't consider the likelihoods

75
00:04:32,910 --> 00:04:36,060
of actual threats or human advantages

76
00:04:36,060 --> 00:04:39,629
over those threats in the future. It just assumes that

77
00:04:39,629 --> 00:04:43,180
we don't know which way the balance will lie; that

78
00:04:43,180 --> 00:04:46,610
human extinction soon and human extinction

79
00:04:46,610 --> 00:04:52,530
later are equally likely.
But maybe you don't believe that.

80
00:04:52,529 --> 00:04:55,539
Maybe you are convinced that human ingenuity will

81
00:04:55,540 --> 00:04:58,960
always stay one step ahead of any extinction event

82
00:04:58,959 --> 00:05:02,149
thrown at it. You could be right,

83
00:05:02,149 --> 00:05:05,699
but there's reason to doubt that optimism.

84
00:05:05,699 --> 00:05:09,899
For example, the Fermi paradox.

85
00:05:09,899 --> 00:05:13,899
If it is likely that intelligent
life forms in our universe are capable

86
00:05:13,910 --> 00:05:15,530
of living for billions

87
00:05:15,529 --> 00:05:20,198
and billions of years, where are they?

88
00:05:20,199 --> 00:05:24,250
Why are the skies so silent? Perhaps

89
00:05:24,250 --> 00:05:28,250
it is because extinction level threat events are just

90
00:05:28,250 --> 00:05:31,860
too common for intelligent life anywhere

91
00:05:31,860 --> 00:05:33,680
to ever catch up.

92
00:05:33,680 --> 00:05:35,400
So,

93
00:05:35,399 --> 00:05:38,929
does this mean we should just give up?

94
00:05:38,930 --> 00:05:42,030
The Voluntary Human Extinction Movement think so.

95
00:05:42,029 --> 00:05:46,439
Founded in 1991, its supporters believe that

96
00:05:46,439 --> 00:05:49,439
humans are a negative influence

97
00:05:49,439 --> 00:05:53,360
on Earth and always will be. Thus

98
00:05:53,360 --> 00:05:57,259
we have a moral obligation to just stop reproducing

99
00:05:57,259 --> 00:06:00,769
right now and fade away. But what would

100
00:06:00,769 --> 00:06:04,109
a computer do? In a way, that's

101
00:06:04,110 --> 00:06:10,050
kind what Tom 7 did. He created a
program that plays video games.

102
00:06:10,050 --> 00:06:14,210
The program came up with novel
techniques and strategies for playing

103
00:06:14,209 --> 00:06:16,509
games and even exploited glitches

104
00:06:16,509 --> 00:06:19,699
humans didn't know about, or at least

105
00:06:19,699 --> 00:06:24,240
hadn't told it about. He also had the
program play other games,

106
00:06:24,240 --> 00:06:27,720
like Tetris, which I think is relevant

107
00:06:27,720 --> 00:06:32,560
to our question. The computer struggled to
figure out what to do.

108
00:06:32,560 --> 00:06:36,918
You see, the computer wasn't programmed
to consider future repercussions far

109
00:06:36,918 --> 00:06:37,879
enough ahead

110
00:06:37,879 --> 00:06:41,819
to notice that stacking Tetriminos in
certain ways

111
00:06:41,819 --> 00:06:46,769
made a big difference. On one run, when faced with

112
00:06:46,769 --> 00:06:50,750
imminent demise, the computer did something

113
00:06:50,750 --> 00:06:53,819
eerie. Rather than

114
00:06:53,819 --> 00:06:56,969
lose, and receive a 'game over',

115
00:06:56,970 --> 00:07:01,340
it just paused the game. For

116
00:07:01,339 --> 00:07:05,279
ever. Tom 7 describes the computer's reasoning

117
00:07:05,279 --> 00:07:08,449
like this: "The only winning move

118
00:07:08,449 --> 00:07:12,870
is to not play." And that's right.

119
00:07:12,870 --> 00:07:15,990
If you pause a game for ever

120
00:07:15,990 --> 00:07:22,240
you will never lose that game. But you'll also never

121
00:07:22,240 --> 00:07:25,470
win that game or achieve a high score.

122
00:07:25,470 --> 00:07:29,430
Now, we might not know what achieving a

123
00:07:29,430 --> 00:07:32,490
sentient life high score in this universe

124
00:07:32,490 --> 00:07:35,750
means or whether or not we're capable of
achieving one.

125
00:07:35,750 --> 00:07:39,089
We might also sometimes panic

126
00:07:39,089 --> 00:07:42,839
when the future looks bleak. But if we keep playing

127
00:07:42,839 --> 00:07:47,509
and keep learning, chances are we could eventually

128
00:07:47,509 --> 00:07:50,750
figure it out and start playing

129
00:07:50,750 --> 00:07:52,870
really well.

130
00:07:53,459 --> 00:07:57,500
So, thanks for continuing to play, for being here.

131
00:07:57,500 --> 00:07:58,879
And as always,

132
00:07:58,879 --> 00:08:00,879
thanks for watching.

