0
00:00:16,699 --> 00:00:22,070
https://youtu.be/GebDm5yhMyA
In the last presentation I talked about how it’s been theorised that faces are processed

1
00:00:22,070 --> 00:00:27,779
in a much more holistic way than other objects, which seem to be processed on the basis of

2
00:00:27,779 --> 00:00:34,779
their individual features. So, what does that  tell us about photofits? Well, traditional

3
00:00:35,239 --> 00:00:40,820
photofit systems are very much focused on getting people to analyse faces feature by

4
00:00:40,820 --> 00:00:46,110
feature. That is, the eyewitness sits down with a big library of different features to

5
00:00:46,110 --> 00:00:52,780
build up a picture of the person that they saw. You choose a nose that fits, then you

6
00:00:52,780 --> 00:00:58,799
choose a mouth that fits, and so on. Here are some examples of photofits created in

7
00:00:58,799 --> 00:01:00,079
research on the topic.

8
00:01:00,079 --> 00:01:07,079
Even when the target face is actually in view we tend to get poor likenesses. Of course

9
00:01:07,320 --> 00:01:12,490
in a real crime, it’s likely to be even worse, because the witness will be doing it

10
00:01:12,490 --> 00:01:19,369
from memory – possibly a quite flaky memory. So why does this approach seem to work so poorly?

11
00:01:19,369 --> 00:01:25,729
Maybe it’s because it assumes that people recognise people feature by feature – when

12
00:01:25,729 --> 00:01:31,920
the research indicates that that’s exactly what they don’t do. That is, when you see

13
00:01:31,920 --> 00:01:36,119
someone in the street, you don’t look at their nose, then their eyes, then their mouth

14
00:01:36,119 --> 00:01:40,969
– to see if it’s someone you know. You look at the whole face all at once. That is,

15
00:01:40,969 --> 00:01:47,560
traditional photofits fail because, as revealed by psychological research, they make a fundamentally

16
00:01:47,560 --> 00:01:51,539
wrong assumption about how people recognise faces.

17
00:01:51,539 --> 00:01:58,539
So, what can we do about this? Well, in recent years, psychologists have attempted to come

18
00:01:58,859 --> 00:02:05,340
up with alternative photofit techniques that don’t rely on this feature by feature approach,

19
00:02:05,340 --> 00:02:11,670
and instead tap into cognitive psychology findings about face recognition and memory.

20
00:02:11,670 --> 00:02:17,569
One example of such a technique is known as Evofit, which was developed by Charlie Frowd

21
00:02:17,569 --> 00:02:21,740
of the University of Central Lancashire, Peter Hancock of the University of Stirling, and

22
00:02:21,740 --> 00:02:25,840
Vicki Bruce at Newcastle University.

23
00:02:25,840 --> 00:02:32,829
The eyewitness chooses, from an array of 72 random faces, the six that are most similar

24
00:02:32,829 --> 00:02:39,159
to the face that they’ve seen. The software integrates the facial features of the six

25
00:02:39,159 --> 00:02:46,159
chosen faces to produce 72 new composite faces, and the witness chooses the six most similar

26
00:02:46,939 --> 00:02:52,969
faces from this new array. After just three such iterations, the team found that people

27
00:02:52,969 --> 00:02:59,969
could accurately identify the face in the resulting composite around 25% of the time,

28
00:03:00,780 --> 00:03:07,090
while feature-based photofits only resulted in correct identification five percent of

29
00:03:07,090 --> 00:03:14,090
the time. So that is, Evofit produced five times the accuracy rate of the feature-based photofit.

30
00:03:15,359 --> 00:03:21,480
So, the key thing about this system is that it doesn’t rely on an eyewitness having

31
00:03:21,480 --> 00:03:28,010
to decompose a face into its individual features. Every judgement they make is on the whole

32
00:03:28,010 --> 00:03:33,480
face. Another advantage is that the system doesn’t rely on the eyewitness having to

33
00:03:33,480 --> 00:03:39,510
verbally describe the face, such as they would have to do with other methods of facial reconstruction

34
00:03:39,510 --> 00:03:44,069
(such as using a sketch artist) they only have to recognise it.

35
00:03:44,069 --> 00:03:50,159
Another thing that Evofit does is to deliberately blur what they call “external” features

36
00:03:50,159 --> 00:03:57,040
– so these are the hair, the ears, and the neck – in order to draw people’s attention to what they call the “internal

37
00:03:57,040 --> 00:04:04,040
features” such as the eyes, eyebrows, nose, and mouth. This is because the internal features

38
00:04:04,420 --> 00:04:10,689
are much more important to identification and the external features can distract from

39
00:04:10,689 --> 00:04:11,260
these.

40
00:04:11,260 --> 00:04:16,359
Finally, they also use sliding scales to allow the eyewitness to manipulate the image of

41
00:04:16,358 --> 00:04:22,570
the face. But, crucially, these scales all operate at the holistic level. That is, they

42
00:04:22,570 --> 00:04:29,570
adjust things that affect the whole face not just bits of it. Examples might include age,

43
00:04:29,940 --> 00:04:36,940
health, weight, honesty, and masculinity. So, the idea is that if you can produce the

44
00:04:37,890 --> 00:04:43,390
face of a suspect using these techniques, you’ll end up with a better likeness of

45
00:04:43,390 --> 00:04:45,010
the suspect.

46
00:04:45,010 --> 00:04:49,390
Of course, like everything, there are some caveats to bear in mind when we’re talking

47
00:04:49,390 --> 00:04:56,380
about the efficacy of Evofit. First, much of the research into Evofit has been carried

48
00:04:56,380 --> 00:05:01,440
out, quite naturally, by the people who created it and so it would be good to have more research

49
00:05:01,440 --> 00:05:08,440
by more independent researchers. It’s also worth noting that not every single study found

50
00:05:08,450 --> 00:05:15,280
a clear advantage of Evofit over more traditional feature-based Photofit techniques – though

51
00:05:15,280 --> 00:05:20,390
these studies seem to be the exception rather than the norm. There’s some variation in

52
00:05:20,390 --> 00:05:26,480
outcomes depending on the details of how the recognition task is performed and measured.

53
00:05:26,480 --> 00:05:32,010
It’s also worth remembering that, as mentioned earlier, the likenesses of criminals can also

54
00:05:32,010 --> 00:05:38,200
be created by using sketch artists, where they tend to use a holistic approach to recreating

55
00:05:38,200 --> 00:05:41,040
the face. Though, as previously noted, 

56
00:05:41,080 --> 00:05:46,420
this approach does require eyewitnesses to verbally describe the suspect.

57
00:05:46,620 --> 00:05:51,520
I should mention that, in the interests of balance, given that Evo-Fit is a commercial

58
00:05:51,520 --> 00:05:58,520
product, there are other products – such as EFIT-V – which are based on similar principles.

59
00:05:58,550 --> 00:06:05,550
So, overall, we have a nice example of a situation where psychologists have applied the findings

60
00:06:05,780 --> 00:06:12,060
from basic psychological research on face recognition to come up with a tool that appears

61
00:06:12,060 --> 00:06:17,990
to do its job. In this case, generating a better likeness of a suspect, better than

62
00:06:17,990 --> 00:06:21,990
previous tools that ignored psychological research.

63
00:06:21,990 --> 00:06:28,230
Next, we’ll look at research into one of the main methods of getting eyewitnesses to

64
00:06:28,230 --> 00:06:33,490
identify a suspect: namely the lineup.

