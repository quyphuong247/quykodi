1
00:00:00,110 --> 00:00:04,810
In February 1999, four New York City police
officers were on patrol in the Bronx when

2
00:00:04,809 --> 00:00:09,699
they saw a young black man standing on a stoop.
They thought he looked suspicious. When they

3
00:00:09,699 --> 00:00:14,570
pulled over, he retreated into the doorway
and began digging in his pocket. He kept digging

4
00:00:14,570 --> 00:00:18,929
as the police shouted at him to show his hands;
a few seconds later, the man, Amadou Diallo,

5
00:00:18,929 --> 00:00:24,559
a 23-year-old immigrant from Guinea, was
dead, hit by 19 of the 41 bullets that the

6
00:00:24,559 --> 00:00:29,960
police fired at him. What Diallo was reaching
for was his wallet. He was going for his ID

7
00:00:29,960 --> 00:00:32,340
as he stood on the steps of his own apartment
building.

8
00:00:32,340 --> 00:00:37,180
Diallo's story, and the officer's fatal pre-judgment
of him, is recounted in Malcolm Gladwell's

9
00:00:37,179 --> 00:00:40,969
2005 bestseller Blink. Gladwell, and
the social psychologists whose

10
00:00:40,969 --> 00:00:46,509
work he draws upon, explores Diallo's case
as an example of that grey area between deliberate

11
00:00:46,509 --> 00:00:51,059
violence and an accident, propagated by
non-conscious, or implicit biases.

12
00:00:51,060 --> 00:00:55,450
The officers did discriminate against Diallo,
but the prejudice they acted on may have been

13
00:00:55,450 --> 00:00:58,380
driven by something more subtle than simple
hatred.

14
00:00:58,380 --> 00:01:02,500
And that's an important thing to think about.
Yes, there are lots of overtly bigoted people

15
00:01:02,500 --> 00:01:06,859
and policies at work all over the world, but
what we're interested in today is the more

16
00:01:06,859 --> 00:01:11,590
insidious, non-conscious automatic bias, and
how it can affect our behavior.

17
00:01:11,590 --> 00:01:16,630
The fact is, our implicit biases affect the
way we relate to others in a very real way.

18
00:01:16,629 --> 00:01:21,659
Our race, gender, age, religion, or sexual
orientation can make the difference between

19
00:01:21,670 --> 00:01:26,170
whether we get a job or not, a fair paycheck,
or a good rental, or whether we get randomly

20
00:01:26,170 --> 00:01:29,100
pulled over or shot and killed for reaching
for a wallet.

21
00:01:29,099 --> 00:01:33,548
In the last two episodes, we've examined how
we think about and how we influence one another,

22
00:01:33,549 --> 00:01:36,770
but social psychology is also about how we
relate to one another.

23
00:01:36,769 --> 00:01:41,188
Like what factors might cause us to help another
person, or harm them, or fear them? What are

24
00:01:41,188 --> 00:01:44,989
the social, and cognitive, and emotional roots
of prejudice, racism, and sexism, and how

25
00:01:44,989 --> 00:01:48,199
do they shape our society? These are some
of the aspects of ourselves that are the hardest

26
00:01:48,200 --> 00:01:52,939
and most uncomfortable for us to explore,
which is why they're so important to understand.

27
00:02:02,719 --> 00:02:07,219
We've all been unfairly judged in our time,
and let's not pretend that we haven't done

28
00:02:07,228 --> 00:02:09,868
our fair share of uninformed judging too.

29
00:02:09,868 --> 00:02:12,769
Like it or not, prejudice is a common human
condition.

30
00:02:12,769 --> 00:02:17,840
Prejudice just means "prejudgment." It's an
unjustified, typically negative attitude toward

31
00:02:17,840 --> 00:02:20,909
an individual or group.
Prejudicial attitudes are often directed along

32
00:02:20,909 --> 00:02:25,900
the lines of gender, ethnic, socioeconomic
status, or culture, and by definition, prejudice

33
00:02:25,900 --> 00:02:31,420
is not the same thing as stereotyping or discrimination,
although the three phenomena are intimately related.

34
00:02:31,419 --> 00:02:36,479
People may distrust a female mechanic. That's
a prejudicial attitude, but it's rooted in

35
00:02:36,479 --> 00:02:40,429
a stereotype, or over-generalized belief about
a particular group.

36
00:02:40,430 --> 00:02:44,080
Although it's often discussed in a negative
way, stereotyping is really more of a general

37
00:02:44,080 --> 00:02:48,840
cognitive process that doesn't have to be
negative. It can even be accurate at times.

38
00:02:48,840 --> 00:02:54,080
Like, I have the stereotype that all crows
have wings, injuries and birth defects aside.

39
00:02:54,080 --> 00:02:55,730
And that happens to be true.

40
00:02:55,729 --> 00:03:00,009
But on the negative end, your prejudice against
female mechanics may be rooted in some inaccurate

41
00:03:00,009 --> 00:03:02,639
stereotype about women's skills with a socket
wrench.

42
00:03:02,639 --> 00:03:07,000
And when stereotypical beliefs combine with
prejudicial attitudes and emotions, like fear

43
00:03:07,000 --> 00:03:10,818
and hostility, they can drive the behavior
we call discrimination.

44
00:03:10,818 --> 00:03:16,208
So a prejudiced person won't necessarily act
on their attitude. Say you believe in the

45
00:03:16,209 --> 00:03:20,519
stereotype that overweight people are lazy.
You might then feel a prejudiced distaste

46
00:03:20,519 --> 00:03:22,450
when you see someone who appears overweight.

47
00:03:22,449 --> 00:03:26,109
But if you act on your prejudice, and, say,
refuse to hire them for a job or don't let

48
00:03:26,110 --> 00:03:30,019
them sit at your lunch counter, then you've
crossed over into discriminating against them.

49
00:03:30,019 --> 00:03:34,360
The former apartheid system of racial segregation
in South Africa, the Nazis' mass killing of

50
00:03:34,360 --> 00:03:38,230
Gypsies, Jewish people, and other groups,
and centuries of bloodshed between Protestants

51
00:03:38,229 --> 00:03:42,719
and Catholics, are all extreme examples of
violent prejudice and discrimination.

52
00:03:42,719 --> 00:03:48,158
The good news is that in many cultures, certain
forms of overt prejudice have waned over time.

53
00:03:48,158 --> 00:03:52,179
For example, in 1937 only 1/3 of Americans
said that they'd vote for a qualified woman to

54
00:03:52,180 --> 00:03:56,580
be president, while in 2007, that figure was
up to nearly 90 percent.

55
00:03:56,580 --> 00:03:59,160
But of course more subtle prejudices can still
linger.

56
00:03:59,159 --> 00:04:02,979
In the past, we've talked about dual-process
theories of thought, memories, and attitudes,

57
00:04:02,979 --> 00:04:08,378
and that while we're aware of our explicit
thoughts, or implicit cognition still operates

58
00:04:08,378 --> 00:04:12,899
under the radar, leaving us clueless about
its effect on our attitudes and behavior.

59
00:04:12,900 --> 00:04:18,348
In the same way, prejudice can be non-conscious
and automatic. And I mean it can be so non-conscious

60
00:04:18,348 --> 00:04:22,868
that even when people ask us point-blank about
our attitudes, we unwillingly or unknowingly

61
00:04:22,869 --> 00:04:24,659
don't always give them an honest answer.

62
00:04:24,658 --> 00:04:28,468
Do you think that men are better at science
the women? Or that Muslims are more violent

63
00:04:28,468 --> 00:04:31,199
than Christians? Or that overweight people
are unhealthy?

64
00:04:31,199 --> 00:04:36,098
Our tendency to unwittingly doctor our answers
to questions like these is why we have the

65
00:04:36,098 --> 00:04:40,998
implicit association test, or IAT. The test
was implemented in the late 1990s to try to

66
00:04:40,999 --> 00:04:47,559
gauge implicit attitudes, identities, beliefs, and biases
that people are unwilling or unable to report.

67
00:04:47,560 --> 00:04:51,838
You can take the IAT online and measure your
implicit attitudes in all kinds of topics,

68
00:04:51,838 --> 00:04:57,959
from race, religion, and gender to disability, weight, and
sexuality. It's basically a timed categorization task.

69
00:04:57,959 --> 00:05:02,019
For example, the age-related IAT looks at
implicit attitudes about older vs. younger

70
00:05:02,019 --> 00:05:07,008
people. In it, you might be shown a series
of faces, old and young, and objects, pleasant

71
00:05:07,009 --> 00:05:10,229
and unpleasant, like pretty flowers vs. a
pile of garbage.

72
00:05:10,228 --> 00:05:13,778
You're then asked to sort these pictures,
so you'd press the left key if you see a young

73
00:05:13,778 --> 00:05:17,930
face or a pleasant object, and press the right
key if you see an old face or an unpleasant

74
00:05:17,930 --> 00:05:22,329
object. That's the stereotypic condition.
Your keystrokes correspond to stereotypical

75
00:05:22,329 --> 00:05:27,149
pairs; in this case, associating good stuff
with youth and bad stuff with older age.

76
00:05:27,149 --> 00:05:31,439
Then the test asks you to do the same thing
in a counter-stereotypic condition, pressing

77
00:05:31,439 --> 00:05:35,399
the left key if you see a young face or an
unpleasant object and the right key if you

78
00:05:35,399 --> 00:05:37,509
see an old face or a pleasant object.

79
00:05:37,509 --> 00:05:41,869
The core of the test is your reaction time.
Are you faster at sorting when you're working

80
00:05:41,869 --> 00:05:45,819
with a stereotypical pairing than you are
with counter-stereotypical pairings? If that's

81
00:05:45,819 --> 00:05:49,619
the case, even though you may think you're
unprejudiced, you've got an implicit association

82
00:05:49,619 --> 00:05:53,999
between youth and goodness, which, as you
might guess, may have some implications about

83
00:05:53,999 --> 00:05:56,088
how you think and act toward older people.

84
00:05:56,088 --> 00:06:00,490
The test is widely used in research, and contrary
to what some critics think, it's surprisingly

85
00:06:00,490 --> 00:06:04,499
predictive of discriminatory behavior in all
kinds of experimental settings.

86
00:06:04,499 --> 00:06:09,080
So that's one way to measure subtle, implicit
prejudice. But obviously, overt prejudice

87
00:06:09,079 --> 00:06:13,588
is far from dead. That's why discrimination
studies are prominent in social psychology

88
00:06:13,588 --> 00:06:18,439
research, and they can also predict, sometimes
with scary accuracy, how discrimination might

89
00:06:18,439 --> 00:06:23,080
show up in broad social patterns, like wage
inequality and job opportunity gaps.

90
00:06:23,079 --> 00:06:27,998
For instance, the 2012 Yale study led by social
scientist Corinne Moss-Racusin demonstrated

91
00:06:27,999 --> 00:06:32,969
that science faculty across the country systematically
discriminated against female science students.

92
00:06:32,968 --> 00:06:37,069
In a double-blind study, a representative
sample of science faculty members were asked

93
00:06:37,069 --> 00:06:40,869
to hire a fictional student applicant for
a lab-manager job.

94
00:06:40,869 --> 00:06:45,339
When the applicant's name was Jennifer, instead
of John, they viewed her as less competent,

95
00:06:45,338 --> 00:06:49,658
were less likely to hire her, offered her less
money, and were less likely to mentor her.

96
00:06:49,658 --> 00:06:52,248
And this prejudice was even exhibited by women
faculty members.

97
00:06:52,249 --> 00:06:56,990
And that's an important point. People on both
sides of the stereotype tend to respond similarly,

98
00:06:56,990 --> 00:07:01,009
with the subjects of prejudice themselves
often holding the same stereotypical implicit

99
00:07:01,009 --> 00:07:04,088
attitudes or engaging in the same discriminatory
behavior.

100
00:07:04,088 --> 00:07:07,879
So when we say that stereotypes are pervasive,
we mean pervasive.

101
00:07:07,879 --> 00:07:11,838
Now it's all too easy to hold up examples
of how people are prejudiced, but the real

102
00:07:11,838 --> 00:07:14,288
root of the issue is why they are.

103
00:07:14,288 --> 00:07:15,778
Here are a few possibilities:

104
00:07:15,778 --> 00:07:20,240
For one, prejudices can come up as a way of
justifying social inequalities. This happens

105
00:07:20,240 --> 00:07:23,829
when people on both sides of the power and
wealth spectrum start believing that people

106
00:07:23,829 --> 00:07:29,569
get what they deserve, and they deserve what
they get. This is called the just-world phenomenon.

107
00:07:29,569 --> 00:07:34,279
Prejudices can also be driven by the "us vs.
them," or as social psychologists often call

108
00:07:34,288 --> 00:07:38,110
it, the ingroup-outgroup phenomenon. Whether
you're in a soccer stadium, or the political

109
00:07:38,110 --> 00:07:43,038
arena or school lunchroom, or, you know, in
the comments of this video, dividing the world

110
00:07:43,038 --> 00:07:46,998
into in-groups and out-groups definitely drives
prejudice and discrimination.

111
00:07:46,999 --> 00:07:51,239
But an in-group identity also gives its members
the benefits of communal solidarity and a

112
00:07:51,238 --> 00:07:56,109
sort of safety in numbers. This in-group bias,
or tendency to favor your own group at the

113
00:07:56,110 --> 00:08:00,800
expense of others, is powerful, even when
it's totally irrational. One common social

114
00:08:00,800 --> 00:08:04,899
psychology exercise on in-group favoritism
involves dividing a class into two arbitrary

115
00:08:04,899 --> 00:08:09,228
groups, say, those wearing sneakers and those
not wearing sneakers. Each person sits with

116
00:08:09,228 --> 00:08:13,459
his or her group and is told to list differences
between themselves and the opposing group.

117
00:08:13,459 --> 00:08:18,788
The lists usually start out pretty tame, but
become more strident as they grow longer. Eventually,

118
00:08:18,788 --> 00:08:22,598
you have sneaker-wearing kids saying that
they're just smarter than the people without

119
00:08:22,598 --> 00:08:26,218
sneakers. The kids who don't have sneakers
say that the other kids are trashy and low-class.

120
00:08:26,218 --> 00:08:30,399
Soon enough, each group has inflated itself
and derided the opposing group, even though

121
00:08:30,399 --> 00:08:33,719
the division between the two was essentially
meaningless to begin with.

122
00:08:33,719 --> 00:08:37,639
Little exercises like this illustrate the
power of any ingroup-outgroup distinction

123
00:08:37,639 --> 00:08:43,198
in creating conflict between groups, and that brings
us to the psychological nature of conflict itself.

124
00:08:43,198 --> 00:08:47,758
History is littered with examples of how the
us vs. them mentality has fueled violence

125
00:08:47,759 --> 00:08:51,568
in warfare, which is exactly what we'll be
talking about next time.

126
00:08:51,568 --> 00:08:55,659
Today, you learned about how prejudice, stereotyping,
and discrimination affect how we interact

127
00:08:55,659 --> 00:09:00,549
and relate to one another. You learned how
prejudice can often be non-conscious and automatic

128
00:09:00,549 --> 00:09:05,469
and how tools like the Implicit Association
Test help reveal and measure it. We also looked

129
00:09:05,470 --> 00:09:10,040
at the implications of the ingroup-outgroup
phenomenon, and how it can lead to strong

130
00:09:10,039 --> 00:09:13,360
in-group bias that often turns aggressive.

131
00:09:13,360 --> 00:09:17,320
This episode of Crash Course Psychology was
sponsored by Shane Barr, whose young adult

132
00:09:17,328 --> 00:09:21,019
sci-fi adventure book, Reset, is available
on Amazon.

133
00:09:21,019 --> 00:09:24,568
Thanks for watching, especially to all of our
Subbable subscribers who make Crash Course

134
00:09:24,568 --> 00:09:28,889
possible. To find out how you can become a
supporter or lead sponsor like Shane, just

135
00:09:28,889 --> 00:09:30,799
go to Subbable.com/CrashCourse.

136
00:09:30,799 --> 00:09:34,799
This episodes was written by Kathleen Yale,
edited by Blake de Pastino, and our consultant

137
00:09:34,799 --> 00:09:39,878
is Dr. Ranjit Bhagwat. Our director and editor
is Nicholas Jenkins, the script supervisor and sound

138
00:09:39,879 --> 00:09:43,199
designer is Michael Aranda, and the graphics
team is Thought Cafe.

