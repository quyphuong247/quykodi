1
00:00:00,160 --> 00:00:04,200
Can week-old pizza cause psychedelic hallucinations?
Does coffee make you smarter? Or does it just

2
00:00:04,200 --> 00:00:05,540
make you do dumb stuff faster?

3
00:00:05,540 --> 00:00:09,138
Like a bunch of psychology itself, questions
like this can seem pretty intuitive. I mean,

4
00:00:09,138 --> 00:00:13,128
people may not be the easiest organisms to
understand, but you're a person, right? So

5
00:00:13,128 --> 00:00:17,679
you must be qualified to draw, like, some
conclusions about other people and what makes

6
00:00:17,679 --> 00:00:18,250
them tick.

7
00:00:18,250 --> 00:00:23,528
But it's important to realize that your intuition
isn't always right. In fact, sometimes it

8
00:00:23,528 --> 00:00:28,849
is exactly wrong, and we tend to grossly underestimate
the dangers of false intuition. If you have

9
00:00:28,849 --> 00:00:32,820
an idea about a person and their behavior
that turns out to be right, that reinforces

10
00:00:32,820 --> 00:00:36,488
your trust in your intuition. Like if one
of my buddies, Bob, begins eating that deep-dish

11
00:00:36,488 --> 00:00:40,029
pizza that's been in the fridge for the past
week but he eats it anyway and soon starts

12
00:00:40,030 --> 00:00:45,579
to wig out, I'll say "Dude, I told you so".
But if I'm wrong and he's totally fine, I

13
00:00:45,579 --> 00:00:48,750
probably won't even think about it ever again.

14
00:00:48,750 --> 00:00:53,780
This is known as 'Hindsight Bias" or the "I-Knew-It-All-Along"
phenomenon. This doesn't mean the common sense

15
00:00:53,780 --> 00:00:58,600
is wrong, it just means that our intuitive
sense more easily describes what just happened,

16
00:00:58,600 --> 00:01:02,570
than what will happen in the future. Another
reason you can't blindly trust your intuition

17
00:01:02,570 --> 00:01:08,269
is your natural tendency toward overconfidence.
Sometimes, you just really, really feel like

18
00:01:08,269 --> 00:01:13,140
you're right about people when actually you're
really, really wrong. We've all been there.

19
00:01:13,140 --> 00:01:18,140
We also tend to perceive order in random events,
which can lead to false assumptions. For example,

20
00:01:18,140 --> 00:01:23,150
if you flip a coin five times you have equal
chances of getting all tails as you do getting

21
00:01:23,150 --> 00:01:28,270
alternating heads and tails. But we see the
series of five tails as something unusual,

22
00:01:28,269 --> 00:01:32,569
as a streak, and thus giving that result some
kind of meaning that it very definitely does

23
00:01:32,569 --> 00:01:33,429
not have.

24
00:01:33,430 --> 00:01:38,740
That is why we have the methods and safe-guards
of psychological research and experimentation,

25
00:01:38,739 --> 00:01:43,669
and the glorious process of scientific inquiry.
They help us to get around these problems

26
00:01:43,670 --> 00:01:48,670
and basically save the study of our minds
from the stupidity of our minds. So I hope

27
00:01:48,670 --> 00:01:53,849
that it won't be a spoiler if I tell you now
that pizza won't make you trip, and coffee

28
00:01:53,849 --> 00:02:00,849
doesn't make you smart. Sorry.

29
00:02:01,450 --> 00:02:03,799
[Intro]

30
00:02:03,799 --> 00:02:10,439
In most ways psychological research is no
different than any other scientific discipline,

31
00:02:10,439 --> 00:02:15,210
like step one is always figuring out how to
ask general questions about your subject and

32
00:02:15,210 --> 00:02:20,960
turn them into measurable, testable propositions.
This is called operationalizing your questions.

33
00:02:20,960 --> 00:02:24,770
So you know how the scientific method works
-- it starts with a question and a theory,

34
00:02:24,770 --> 00:02:29,330
and I don't mean theory in the sense of like,
a hunch that say, a quad-shot of espresso

35
00:02:29,330 --> 00:02:34,700
makes you think better. Instead, in science
a theory is what explains and organizes lots

36
00:02:34,699 --> 00:02:39,679
of different observations and predicts outcomes.
And when you come up with a testable prediction,

37
00:02:39,680 --> 00:02:40,939
that's your hypothesis.

38
00:02:40,939 --> 00:02:45,319
Once your theory and hypothesis are in place,
you need a clear and common language to report

39
00:02:45,319 --> 00:02:48,989
them with, so for example, defining exactly
what you mean by "thinking better" with your

40
00:02:48,990 --> 00:02:54,340
espresso hypothesis will allow other researchers
to replicate the experiment. And replication

41
00:02:54,340 --> 00:02:59,640
is key. You can watch a person exhibit a certain
behavior once, and it won't prove very much,

42
00:02:59,639 --> 00:03:03,929
but if you keep getting consistent results,
even as you change subjects or situations,

43
00:03:03,930 --> 00:03:05,400
you're probably on to something.

44
00:03:05,400 --> 00:03:09,810
This is a problem with one popular type of
psychological research: case studies, which

45
00:03:09,810 --> 00:03:14,420
take an in-depth look at one individual. Case
studies can sometimes be misleading, because

46
00:03:14,419 --> 00:03:18,159
by their nature, they can't be replicated,
so they run the risk of over-generalizing.

47
00:03:18,159 --> 00:03:22,930
Still, they're good at showing us what CAN
happen, and end up framing questions for more

48
00:03:22,930 --> 00:03:27,390
extensive and generalizable studies. They're
also often memorable and a great story telling

49
00:03:27,389 --> 00:03:32,439
device psychologists use to observe and describe
behavior. Like, say the smell of coffee makes

50
00:03:32,439 --> 00:03:36,400
Carl suddenly anxious and irritable -- that
obviously doesn't mean that it has that same

51
00:03:36,400 --> 00:03:41,750
effect on everyone. In fact, Carl has terrible
memories associated with that smell, and so

52
00:03:41,750 --> 00:03:46,039
his case is actually quite rare. Poor Carl.
But you would still have to look at lots of

53
00:03:46,039 --> 00:03:48,099
other cases to determine that conclusively.

54
00:03:48,099 --> 00:03:52,650
Another popular method of psychological research
is naturalistic observation, where researchers

55
00:03:52,650 --> 00:03:57,490
simply watch behavior in a natural environment,
whether that's chimps poking ant-hills in

56
00:03:57,490 --> 00:04:02,040
the jungle, kids clowning in a classroom or
drunk dudes yelling at soccer games. The idea

57
00:04:02,039 --> 00:04:05,989
is to let the subjects just do their thing
without trying to manipulate or control the

58
00:04:05,990 --> 00:04:10,200
situation. So yeah, basically just spying
on people. Like case studies, naturalistic

59
00:04:10,199 --> 00:04:15,129
observations are great at describing behavior,
but they're very limited in explaining it.

60
00:04:15,129 --> 00:04:19,180
Psychologists can also collect behavioral
data using surveys or interviews, asking people

61
00:04:19,180 --> 00:04:23,959
to report their opinions and behaviors. Sexuality
researcher Alfred Kinsey famously used this

62
00:04:23,959 --> 00:04:28,180
technique when he surveyed thousands of men
and women on their sexual history and published

63
00:04:28,180 --> 00:04:34,379
his findings in a pair of revolutionary texts,
Sexual Behavior in the Human Male and Female

64
00:04:34,379 --> 00:04:35,180
respectively.

65
00:04:35,180 --> 00:04:39,550
Surveys are a great way to access consciously
held attitudes and beliefs, but how to ask

66
00:04:39,550 --> 00:04:44,720
the questions can be tricky; subtle word choices
can influence results. For example more forceful

67
00:04:44,720 --> 00:04:50,280
words like "ban" or "censor" may elicit different
reactions than "limit" or "not allow". Asking

68
00:04:50,279 --> 00:04:54,000
"Do you believe in space aliens?" is a much
different question than "Do you think that

69
00:04:54,000 --> 00:04:57,490
there is intelligent life somewhere else in
the universe?" It's the same question, but

70
00:04:57,490 --> 00:05:01,519
in the first the subject might assume you
mean aliens visiting earth, and making crop

71
00:05:01,519 --> 00:05:03,709
circles and abducting people and poking them.

72
00:05:03,709 --> 00:05:07,560
And if how you phrase surveys is important,
so is who you ask. I could ask a room full

73
00:05:07,560 --> 00:05:11,149
of students at a pacifist club meeting what
they think about arms control, but the result

74
00:05:11,149 --> 00:05:15,149
wouldn't be a representative measure of where
students stand, because there's a pretty clear

75
00:05:15,149 --> 00:05:20,069
sampling bias at work here. To fairly represent
a population, I'd need to get a random sample

76
00:05:20,069 --> 00:05:24,349
where all members of the target group, in
this case students, had an equal chance of

77
00:05:24,350 --> 00:05:26,220
being selected to answer the question.

78
00:05:26,220 --> 00:05:30,800
So once you've described behavior with surveys,
case studies, or naturalistic observation,

79
00:05:30,800 --> 00:05:35,079
you can start making sense out of it, and
even predict future behavior. One way to do

80
00:05:35,079 --> 00:05:39,819
that is to look at one trait or behavior is
related to another, or how they correlate.

81
00:05:39,819 --> 00:05:43,209
So let's get back to my buddy Bob who seems
to think that his refrigerator is actually

82
00:05:43,209 --> 00:05:47,180
some kind of time machine that can preserve
food indefinitely. Let's say that Bob has

83
00:05:47,180 --> 00:05:50,780
just tucked into a lunch of questionable leftovers,
pizza that may very well have had a little

84
00:05:50,779 --> 00:05:56,359
bit of fungus on it. But he was hungry, and
lazy, and so he doused it in Sriracha. Suddenly,

85
00:05:56,360 --> 00:05:59,490
he starts seeing things: green armadillos
with laser beam eyes.

86
00:05:59,490 --> 00:06:04,460
From here we could deduce that eating unknown
fungus predicts hallucination, that's a correlation.

87
00:06:04,459 --> 00:06:09,329
But correlation is not causation. Yes, it
makes sense that eating questionable fungus

88
00:06:09,329 --> 00:06:13,990
would cause hallucinations, but it's possible
that Bob was already on the verge of a psychotic

89
00:06:13,990 --> 00:06:18,840
episode, and those fuzzy leftovers were actually
benign. Or there could be an entirely different

90
00:06:18,839 --> 00:06:23,549
factor involved, like maybe he hadn't slept
in 72 hours, or had an intense migraine coming

91
00:06:23,550 --> 00:06:28,620
on, and one of those factors caused his hallucinations.
It's tempting to draw conclusions from correlations,

92
00:06:28,620 --> 00:06:33,459
but it's super-important to remember that
correlations predict the possibility of cause-and-effect

93
00:06:33,459 --> 00:06:35,909
relationships; they cannot prove them.

94
00:06:35,910 --> 00:06:40,400
So we've talked about how to describe behavior
without manipulating it and how to make connections

95
00:06:40,399 --> 00:06:44,189
and predictions from those findings. But that
can only take you so far; to really get to

96
00:06:44,189 --> 00:06:48,939
the bottom of cause-and-effect behaviors,
you're gonna have to start experimenting.

97
00:06:48,939 --> 00:06:52,889
Experiments allow investigators to isolate
different effects by manipulating an independent

98
00:06:52,889 --> 00:06:57,610
variable, and keeping all other variables
constant, or as constant as you can. This

99
00:06:57,610 --> 00:07:01,439
means that they need at least two groups:
the experimental group, which is gonna get

100
00:07:01,439 --> 00:07:05,110
messed with, and the control group, which
is not gonna get messed with.

101
00:07:05,110 --> 00:07:09,350
Just as surveys use random samples, experimental
researchers need to randomly assign participants

102
00:07:09,350 --> 00:07:14,110
to each group to minimize potential confounding
variables, or outside factors that may skew

103
00:07:14,110 --> 00:07:18,100
the results. You don't want all grumpy teenagers
in one group and all wealthy Japanese surfers

104
00:07:18,100 --> 00:07:19,379
in the other; they gotta mingle.

105
00:07:19,379 --> 00:07:25,418
Now sometimes one or both groups are not informed
about what's actually being tested. For example,

106
00:07:25,418 --> 00:07:29,418
researchers can test how substances effect
people by comparing their effects to placebos,

107
00:07:29,418 --> 00:07:34,349
or inert substances. And often, the researchers
themselves don't know which group is experimental

108
00:07:34,350 --> 00:07:39,360
and which is control, so they don't unintentionally
influence the results through their own behavior,

109
00:07:39,360 --> 00:07:43,540
in which case it's called, you guessed it,
a double blind procedure.

110
00:07:43,540 --> 00:07:47,789
So let's put these ideas into practice in
our own little experiment. Like all good work,

111
00:07:47,788 --> 00:07:50,959
it starts with a question. So the other day
my friend Bernice and I were debating. We

112
00:07:50,959 --> 00:07:55,508
were debating caffeine's effect on the brain.
Personally, she convinced that coffee helps

113
00:07:55,509 --> 00:07:59,680
her focus and think better, but I get all
jittery like a caged meerkat and can't focus

114
00:07:59,680 --> 00:08:03,350
on anything. And because we know that overconfidence
can lead you to believe things that are not

115
00:08:03,350 --> 00:08:05,699
true, we decided to use some critical thinking.

116
00:08:05,699 --> 00:08:10,288
So let's figure out our question: "Do humans
solve problems faster when given caffeine?"

117
00:08:10,288 --> 00:08:15,300
Now we gotta boil that down into a testable
prediction. Remember: keep it clear, simple,

118
00:08:15,300 --> 00:08:19,689
and eloquent so that it can be replicated.
"Caffeine makes me smarter" is not a great

119
00:08:19,689 --> 00:08:25,329
hypothesis. A better one would be, say, "Adult
humans given caffeine will navigate a maze

120
00:08:25,329 --> 00:08:29,339
faster than humans not given caffeine." The
caffeine dosage is your independent variable,

121
00:08:29,339 --> 00:08:33,610
the thing that you can change. So, you'll
need some coffee. Your result or dependent

122
00:08:33,610 --> 00:08:37,490
variable, the thing that depends on the thing
that you can change is going to be the speed

123
00:08:37,490 --> 00:08:40,079
at which the subject navigates through this
giant corn maze.

124
00:08:40,078 --> 00:08:43,899
Go out on the street, wrangle up a bunch of
different kinds of people and randomly assign

125
00:08:43,899 --> 00:08:47,778
them into three different groups. Also at
this point, the American Psychological Association

126
00:08:47,778 --> 00:08:52,350
suggests that you acquire everyone's informed
consent to participate. You don't want to

127
00:08:52,350 --> 00:08:55,308
force anyone to be in your experiment, no
matter how cool you think it is.

128
00:08:55,308 --> 00:08:59,499
So the control group gets a placebo, in this
case decaf. Experimental group one gets a

129
00:08:59,499 --> 00:09:03,579
low dose of caffeine, which we'll define at
a 100 milligrams; just an eye opener, like,

130
00:09:03,578 --> 00:09:08,318
a cup of coffee's worth. Experimental group
two gets 500 milligrams, more than a quad

131
00:09:08,318 --> 00:09:12,729
shot of espresso dunked in a Red Bull. Once
you dose everyone, turn them lose in the maze

132
00:09:12,730 --> 00:09:14,730
and wait at the other end with a stopwatch.

133
00:09:14,730 --> 00:09:17,860
All that's left is to measure your results
from the three different groups and compare

134
00:09:17,860 --> 00:09:21,928
them to see if there were any conclusive results.
If the highly dosed folks got through it twice

135
00:09:21,928 --> 00:09:26,129
as fast as the low dose and the placebo groups,
then Bernice's hypothesis was correct, and

136
00:09:26,129 --> 00:09:30,550
she can rub my face in it saying she was right
all along, but really that would just be the

137
00:09:30,549 --> 00:09:35,568
warm flush of hindsight bias telling her something
she didn't really know until we tested it.

138
00:09:35,568 --> 00:09:39,519
Then, because we've used clear language and
defined our parameters, other curious minds

139
00:09:39,519 --> 00:09:43,629
can easily replicate this experiment, and
we can eventually pool all the data together

140
00:09:43,629 --> 00:09:48,249
and have something solid to say about what
that macchiato was doing to your cognition–

141
00:09:48,249 --> 00:09:52,350
or at least the speed at which you can run
through a maze. Science: probably the best

142
00:09:52,350 --> 00:09:54,129
tool that you have for understanding other
people.

143
00:09:54,129 --> 00:09:57,850
Thanks for watching this episode of Crash
Course Psychology; if you paid attention you

144
00:09:57,850 --> 00:10:01,839
learned how to apply the scientific method
to psychological research through case studies,

145
00:10:01,839 --> 00:10:06,489
naturalistic observation, surveys, and interviews
and experimentation. You also learned about

146
00:10:06,489 --> 00:10:11,509
different kinds of bias in experimentation
and how research practices help us avoid them.

147
00:10:11,509 --> 00:10:15,980
Thanks especially to our Subbable subscribers,
who make this and all of Crash Course possible.

148
00:10:15,980 --> 00:10:20,289
If you'd like to contribute to help us keep
Crash Course going, and also get awesome perks

149
00:10:20,289 --> 00:10:24,808
like an autographed science poster, or even
be animated into an upcoming episode, go to

150
00:10:24,808 --> 00:10:27,629
Subbable.com/CrashCourse to find out how.

151
00:10:27,629 --> 00:10:31,399
Our script was written by Kathleen Yale and
edited by Blake de Pastino and myself. Our

152
00:10:31,399 --> 00:10:36,178
consultant is Dr. Ranjit Bhagwat. Our director
and editor is Nicholas Jenkins, our script

153
00:10:36,178 --> 00:10:39,980
supervisor is Michael Aranda, who is also
our sound designer, and our graphics team

154
00:10:39,980 --> 00:10:40,399
is Thought Café.

