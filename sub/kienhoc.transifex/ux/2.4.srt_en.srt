0
00:00:08,618 --> 00:00:14,187
https://youtu.be/5jB9DCLKdPk
After the tasks, you&#39;re gonna take a few minutes to debrief with the participant,

1
00:00:14,187 --> 00:00:17,404
to try to find out a little bit more information,

2
00:00:17,404 --> 00:00:22,140
things that maybe weren&#39;t clear during the tasks themselves.

3
00:00:22,140 --> 00:00:26,050
So one thing that you can do is review problems that came up

4
00:00:26,050 --> 00:00:27,790
to try to get more information about them.

5
00:00:27,790 --> 00:00:30,990
Maybe somebody was really stuck in a particular place,

6
00:00:30,990 --> 00:00:34,010
rather than have a conversation with them in the middle of their task and

7
00:00:34,010 --> 00:00:37,030
get them off track, you might just kind of let that go.

8
00:00:37,030 --> 00:00:41,650
But come back to it in the debrief and say he, that place where you got stuck and

9
00:00:41,650 --> 00:00:45,160
you weren&#39;t really sure what that button meant, or what it was going to do?

10
00:00:45,160 --> 00:00:46,860
What was going through your mind at that time?

11
00:00:46,860 --> 00:00:49,620
So you can get more information about problems that came up.

12
00:00:50,840 --> 00:00:55,150
This is the time when you might ask about other aspects of the experience.

13
00:00:55,150 --> 00:00:58,285
Is this product something that you would actually find useful?

14
00:00:58,285 --> 00:00:59,702
What would you find it useful for?

15
00:00:59,702 --> 00:01:00,561
How would it fit in?

16
00:01:00,561 --> 00:01:02,036
How would you value this?

17
00:01:02,036 --> 00:01:05,214
Where would this provide a real benefit for you or

18
00:01:05,214 --> 00:01:08,350
would it provide a benefit at all?

19
00:01:08,350 --> 00:01:11,870
And you can ask about other qualities like perceived usability.

20
00:01:11,870 --> 00:01:13,600
Did they feel like it was usable?

21
00:01:13,600 --> 00:01:17,230
Maybe they struggled a lot but they actually felt at the end, actually,

22
00:01:17,230 --> 00:01:18,970
that was pretty easy and I enjoyed using it.

23
00:01:18,970 --> 00:01:21,420
Or the other way around, they may have just sailed through it and

24
00:01:21,420 --> 00:01:25,330
said I found it really confusing, I found it really difficult to use.

25
00:01:25,330 --> 00:01:28,580
So the perception can sometimes be different from

26
00:01:28,580 --> 00:01:31,890
the observations that you made.

27
00:01:31,890 --> 00:01:34,210
You can ask them about the aesthetics, the credibility, and

28
00:01:34,210 --> 00:01:38,340
all those other aspects of user experience that we&#39;ve been talking about.

29
00:01:38,340 --> 00:01:42,590
And you can also ask them to compare to the alternatives that they currently use.

30
00:01:42,590 --> 00:01:46,350
If they do the same tasks and they use a different product for

31
00:01:46,350 --> 00:01:48,410
doing it, how does this compare to that?

32
00:01:48,410 --> 00:01:48,970
Is it better?

33
00:01:48,970 --> 00:01:49,610
Is it worse?

34
00:01:49,610 --> 00:01:50,500
What are the advantages?

35
00:01:50,500 --> 00:01:51,870
What are the disadvantages?

36
00:01:51,870 --> 00:01:52,390
And so forth.

37
00:01:53,670 --> 00:01:56,970
Okay, after that you&#39;ve gone through the tasks,

38
00:01:56,970 --> 00:02:00,280
you&#39;ve observed the issues that people had in conducting the tests.

39
00:02:00,280 --> 00:02:01,890
You&#39;ve conducted a debrief.

40
00:02:01,890 --> 00:02:03,280
Now you have to make sense.

41
00:02:03,280 --> 00:02:04,910
What did you learn from this whole process?

42
00:02:06,520 --> 00:02:11,360
What you are primarily interested in is capturing critical incidents that occurred

43
00:02:11,360 --> 00:02:12,748
during the tests.

44
00:02:12,748 --> 00:02:15,710
So these will be places where people made errors,

45
00:02:15,710 --> 00:02:18,080
where they didn&#39;t do what you expected.

46
00:02:18,080 --> 00:02:21,030
They didn&#39;t follow the right path for accomplishing something.

47
00:02:21,030 --> 00:02:26,927
Places where they expressed frustration perhaps using inappropriate language.

48
00:02:26,927 --> 00:02:31,070
Places where they were breakdowns where something took a really long time when it

49
00:02:31,070 --> 00:02:32,930
was supposed to be really quick.

50
00:02:32,930 --> 00:02:35,880
Or where people followed a path that you didn&#39;t expect, but

51
00:02:35,880 --> 00:02:39,400
they ended up in the right place but maybe it was an inefficient path.

52
00:02:39,400 --> 00:02:41,270
And also, these can be pleasant surprises,

53
00:02:41,270 --> 00:02:46,500
places where the system made something easier for them than they expected.

54
00:02:46,500 --> 00:02:51,220
So these would all be critical incidents, things that would be worth noting and

55
00:02:51,220 --> 00:02:56,860
thinking about in terms of understanding what was important about a test.

56
00:02:57,910 --> 00:03:02,570
And as part of this you also wanna assess overall the success or

57
00:03:02,570 --> 00:03:08,270
failure of that participant in engaging with the tests that you ask them to do.

58
00:03:08,270 --> 00:03:12,900
And the thing about success and failure is it can actually lie along a spectrum.

59
00:03:12,900 --> 00:03:17,560
It&#39;s not necessarily a hard line between success and failure.

60
00:03:17,560 --> 00:03:21,860
But somebody may have partially accomplished a task.

61
00:03:21,860 --> 00:03:23,340
Or they may have accomplished a task but

62
00:03:23,340 --> 00:03:27,100
missed some particular characteristic that you were looking for.

63
00:03:27,100 --> 00:03:30,790
So for example, if we were doing a task with looking for

64
00:03:31,840 --> 00:03:35,910
a gift list, a gift idea list for my ten year old nephew.

65
00:03:35,910 --> 00:03:38,740
But I actually found one that was more appropriate for 13 year olds.

66
00:03:38,740 --> 00:03:43,210
Well, I got pretty close but maybe I missed it by a little bit.

67
00:03:43,210 --> 00:03:47,270
But you need to assess the extent to which people succeeded or failed so

68
00:03:47,270 --> 00:03:52,550
that you can go back and say, how important were these errors or

69
00:03:52,550 --> 00:03:54,340
frustrations or breakdowns.

70
00:03:54,340 --> 00:03:56,210
Did they actually lead to failure or

71
00:03:56,210 --> 00:03:58,310
were they just kinda stumbling blocks along the way?

72
00:03:59,940 --> 00:04:03,010
And you also wanna capture they&#39;re overall reaction and

73
00:04:03,010 --> 00:04:04,770
their reaction to specific aspects.

74
00:04:06,210 --> 00:04:07,960
What was the participant&#39;s demeanor?

75
00:04:07,960 --> 00:04:12,670
Were they positive and upbeat and energetic while interacting with it or

76
00:04:12,670 --> 00:04:18,370
did they sort of seemed deflated or frustrated or bored?

77
00:04:18,370 --> 00:04:21,240
And what were the causes of those different reactions

78
00:04:21,240 --> 00:04:22,130
if you can tease them out?

79
00:04:23,200 --> 00:04:27,470
And what you wanna do is link those critical incidents to successes and

80
00:04:27,470 --> 00:04:29,650
failures and to the subjective reaction.

81
00:04:29,650 --> 00:04:33,810
Did they become frustrated and angry because of particular incidents

82
00:04:33,810 --> 00:04:36,910
that are connected to particular aspects of the design?

83
00:04:36,910 --> 00:04:39,590
Or were there other reasons that that happened.

84
00:04:39,590 --> 00:04:45,210
Were there specific incidents that led to a positive subjective reaction?

85
00:04:45,210 --> 00:04:49,760
That led to success or failure and those kinds of things.

86
00:04:49,760 --> 00:04:52,620
And from this you need to think about,

87
00:04:52,620 --> 00:04:55,170
what did you learn from the test that you could actually use?

88
00:04:55,170 --> 00:04:59,960
Whether that&#39;s to communicate with the team that&#39;s going to improve their

89
00:04:59,960 --> 00:05:02,720
product or whether you&#39;re the person that&#39;s gonna improve it yourself and

90
00:05:02,720 --> 00:05:05,590
you need to figure out what is it about that I need to fix.

91
00:05:06,720 --> 00:05:10,180
Most important thing to consider here

92
00:05:10,180 --> 00:05:13,870
is that you got to write it down right after the test.

93
00:05:13,870 --> 00:05:18,520
Your memory will not serve you well if you wait until the next day or

94
00:05:18,520 --> 00:05:20,680
the day after or whatever it is.

95
00:05:20,680 --> 00:05:22,030
You won&#39;t remember the details.

96
00:05:22,030 --> 00:05:23,520
You won&#39;t remember those incidents.

97
00:05:23,520 --> 00:05:27,350
So you wanna take a few minutes right after the test to write down what were

98
00:05:27,350 --> 00:05:28,280
the critical incidents?

99
00:05:28,280 --> 00:05:30,170
What were the subjective reactions?

100
00:05:30,170 --> 00:05:31,640
What were the successes and failures?

101
00:05:31,640 --> 00:05:34,228
So that you can capture it while your memory is still fresh.

102
00:05:34,228 --> 00:05:37,640
So you wanna capture those critical incidents but

103
00:05:37,640 --> 00:05:40,670
you also wanna think, right away about why they happened.

104
00:05:40,670 --> 00:05:43,840
Did they happen because the user&#39;s mental model or

105
00:05:43,840 --> 00:05:48,060
the way that they thought that this particular test should work didn&#39;t match

106
00:05:48,060 --> 00:05:51,720
the way that the system thought it should work, that it can be a cause of errors.

107
00:05:51,720 --> 00:05:53,640
Was it just a simple misinterpretation?

108
00:05:53,640 --> 00:05:58,000
You had Labelled a particular option or a particular button or particular

109
00:05:58,000 --> 00:06:02,230
link in certain way and they interpret it a different way and it led them off track.

110
00:06:02,230 --> 00:06:04,850
Were there invalid assumptions made by the system.

111
00:06:04,850 --> 00:06:07,700
Did you assume that the user would have information or

112
00:06:07,700 --> 00:06:12,170
have knowledge that they don&#39;t actually have at that point in the interaction.

113
00:06:12,170 --> 00:06:14,640
Did it turn out that you misinterpret the user needs?

114
00:06:14,640 --> 00:06:17,840
Just that what they actually needed to do in order to accomplish this task was

115
00:06:17,840 --> 00:06:20,330
different than from what the system provides?

116
00:06:20,330 --> 00:06:24,760
Does the system provide too little flexibility and force the user to go down

117
00:06:24,760 --> 00:06:27,970
a particular path when they had a different way that they wanted to do it?

118
00:06:27,970 --> 00:06:31,400
And maybe that led to frustration, or maybe that led to failure.

119
00:06:31,400 --> 00:06:33,600
Or did the system provide too little guidance?

120
00:06:33,600 --> 00:06:35,080
Maybe it was too flexible.

121
00:06:35,080 --> 00:06:38,120
It gave too many options, and in fact the user really needed

122
00:06:38,120 --> 00:06:41,750
guidance to go down the path to accomplish that particular task.

123
00:06:41,750 --> 00:06:46,060
So again, you need to write this down as quickly as possible and

124
00:06:46,060 --> 00:06:47,810
capture it while it&#39;s still fresh in your mind.

125
00:06:49,980 --> 00:06:52,800
Another important thing is that now you&#39;ve identified the problems, you&#39;ve

126
00:06:52,800 --> 00:06:57,350
identified why they&#39;ve happened, you need to think about how important they are.

127
00:06:57,350 --> 00:07:01,710
When assessing the severity of a problem, a couple things you can think about

128
00:07:01,710 --> 00:07:04,980
are what were the impacts of that problem on success or failure?

129
00:07:04,980 --> 00:07:09,560
Again, was this a show stopper that caused the participant

130
00:07:09,560 --> 00:07:15,150
to fail a critical task or was it just a stumbling block or a minor annoyance.

131
00:07:15,150 --> 00:07:17,480
What was the impact on their subjective experience?

132
00:07:17,480 --> 00:07:21,240
Did this problem lead to a change in their judgement of

133
00:07:21,240 --> 00:07:23,400
the overall experience of the system.

134
00:07:23,400 --> 00:07:25,540
And what was the impact on the product goals?

135
00:07:25,540 --> 00:07:30,850
So maybe they were successful, maybe they had a good time accomplishing the tasks

136
00:07:30,850 --> 00:07:35,230
but they actually did it in a way that wouldn&#39;t serve the goals of the product.

137
00:07:35,230 --> 00:07:39,800
Maybe they were not successful in buying the product that you hope they would be

138
00:07:39,800 --> 00:07:44,220
able to buy, or they didn&#39;t do it in a way that would facilitate

139
00:07:44,220 --> 00:07:48,430
the ultimate goals that you have in building and delivering this product.

140
00:07:48,430 --> 00:07:52,370
And what else did you learn about other UX factors that we&#39;ve talking about?

141
00:07:52,370 --> 00:07:57,020
Things like the usefulness, desirability, credibility, accessibility and

142
00:07:57,020 --> 00:07:58,260
other things like that.

143
00:07:58,260 --> 00:08:02,900
These are the things that you need consider when extracting and

144
00:08:02,900 --> 00:08:05,560
distilling what it is that you learn from a user test.

145
00:08:07,570 --> 00:08:11,710
And one other very important thing before you go off and do this on your own,

146
00:08:11,710 --> 00:08:16,660
is that there&#39;s a few things that you need to keep in mind when interacting with

147
00:08:16,660 --> 00:08:21,380
users who have graciously given you their time to participate in these things, and

148
00:08:21,380 --> 00:08:24,600
things that you need to communicate to them, that you understand.

149
00:08:24,600 --> 00:08:29,120
So one is that you understand that their participation is voluntary.

150
00:08:29,120 --> 00:08:33,360
That may seem obvious to you, but it&#39;s useful to keep that in mind and

151
00:08:33,360 --> 00:08:35,880
remind them that they can stop at any time.

152
00:08:35,880 --> 00:08:38,220
They&#39;ve come here willingly, they can leave at any time.

153
00:08:38,220 --> 00:08:43,160
If they frustrated, if they don&#39;t like the questions that you&#39;re asking them,

154
00:08:43,159 --> 00:08:46,540
they can leave at any time, and that&#39;s okay with you.

155
00:08:46,540 --> 00:08:49,300
Another thing that&#39;s very important to make clear and

156
00:08:49,300 --> 00:08:53,540
to remember is that you&#39;re testing the system, not the participant.

157
00:08:53,540 --> 00:08:57,970
As I mentioned before, this can be a stressful experience for people.

158
00:08:57,970 --> 00:09:03,600
People have left user tests in tears, hopefully that won&#39;t happen with you.

159
00:09:03,600 --> 00:09:07,100
But it can be a very frustrating experience, it&#39;s a very unusual experience

160
00:09:07,100 --> 00:09:10,130
for a lot of people if they haven&#39;t done this kind of thing before.

161
00:09:10,130 --> 00:09:14,620
So what you wanna remember and what you wanna remind them is that

162
00:09:14,620 --> 00:09:19,760
the system is what&#39;s being test and if they have struggle accomplishing the task

163
00:09:19,760 --> 00:09:23,450
that you&#39;re asking them to do, it&#39;s because the system needs to be better.

164
00:09:23,450 --> 00:09:25,920
Not because you think that they don&#39;t have the skills or

165
00:09:25,920 --> 00:09:29,130
the ability to do it correctly, that that&#39;s not what&#39;s being tested.

166
00:09:29,130 --> 00:09:33,430
You&#39;re testing the system, and whatever feedback, whatever experiences they can

167
00:09:33,430 --> 00:09:37,070
give you will be valuable for your goals, which is trying to make the system better.

168
00:09:38,440 --> 00:09:41,200
And again you need to let your participants know this,

169
00:09:41,200 --> 00:09:44,960
that their participation is voluntary, they can stop at any time, and

170
00:09:44,960 --> 00:09:46,740
that your testing the system and not them.

171
00:09:48,520 --> 00:09:53,270
Okay, so the assignment that we&#39;re gonna do this week and next,

172
00:09:53,270 --> 00:09:58,890
we&#39;re gonna start this week by planning what we call a micro usability test and

173
00:09:58,890 --> 00:10:02,440
the next week we&#39;re gonna have you accomplish a micro usability test.

174
00:10:02,440 --> 00:10:08,070
We&#39;ve been talking about the general basic ideas behind user testing so what do

175
00:10:08,070 --> 00:10:12,650
we mean when we talk about a micro test, the test that you guys are gonna be doing.

176
00:10:12,650 --> 00:10:15,440
Well we&#39;re sort of scaling things down so

177
00:10:15,440 --> 00:10:19,830
that they can be quicker and easier, and have a faster turning around.

178
00:10:19,830 --> 00:10:24,050
And this kind of testing is done very frequently in the industry, especially

179
00:10:24,050 --> 00:10:28,240
when you&#39;re working on a product that&#39;s under development and you need to get

180
00:10:28,240 --> 00:10:32,220
rapid feedback about are we on the right track or are we not on the right track.

181
00:10:32,220 --> 00:10:34,900
So one of the things that we relax when

182
00:10:35,930 --> 00:10:40,430
doing a micro version of a user task is we relax the recruiting.

183
00:10:40,430 --> 00:10:44,120
So we&#39;re as our goal is to

184
00:10:44,120 --> 00:10:48,830
have people that are clearly members of the target audience and potential users.

185
00:10:48,830 --> 00:10:51,450
For micro usability test, we might get people that are,

186
00:10:51,450 --> 00:10:55,940
we don&#39;t know necessarily think they would be and users of the product, but

187
00:10:55,940 --> 00:10:59,750
they&#39;re close enough that they could imagine what that would be like.

188
00:10:59,750 --> 00:11:03,660
One variant of the micro-usability test is something that&#39;s called the hallway

189
00:11:03,660 --> 00:11:04,470
usability test.

190
00:11:04,470 --> 00:11:07,590
And the idea there, especially in a workplace environment,

191
00:11:07,590 --> 00:11:10,890
is you just pop out into the hall, you grab whoever&#39;s out there,

192
00:11:10,890 --> 00:11:13,890
have them come in and try your thing out and give you quick and

193
00:11:13,890 --> 00:11:17,380
dirty feedback on what it is that is working and what isn&#39;t working.

194
00:11:18,390 --> 00:11:22,000
Usually, with a micro usability test, we&#39;re gonna do fewer tasks.

195
00:11:22,000 --> 00:11:25,680
So, maybe just two or three tasks, as opposed to Maybe

196
00:11:25,680 --> 00:11:29,990
five to ten tasks that we might typically do in a standard usability test.

197
00:11:29,990 --> 00:11:33,630
And we&#39;re gonna keep the time short, it&#39;s usually less than 30 minutes,

198
00:11:33,630 --> 00:11:36,540
maybe even more like 15 or 20 minutes, as opposed

199
00:11:36,540 --> 00:11:40,810
to the standard 60 to 90 minutes that we would use for a full blown usability test.

200
00:11:42,200 --> 00:11:46,720
We&#39;re also not gonna invest very much in formal data collection, so

201
00:11:46,720 --> 00:11:51,460
we&#39;re not going to for example, do screen recording or video recording.

202
00:11:51,460 --> 00:11:55,630
We&#39;re not gonna administer questionnaires that collect data

203
00:11:55,630 --> 00:11:58,990
from users in a systematic way, let&#39;s say about their demographics or

204
00:11:58,990 --> 00:12:02,230
about their prior behaviors or about their response to the system.

205
00:12:02,230 --> 00:12:05,490
And we&#39;re not even gonna usually log or

206
00:12:05,490 --> 00:12:10,820
take notes during the test because we are focused on just observing what&#39;s going on.

207
00:12:12,190 --> 00:12:15,650
So in a standard usability test we will do all of these things.

208
00:12:15,650 --> 00:12:19,520
We&#39;ll have screen recording, we&#39;ll often use video recording, we&#39;ll administer

209
00:12:19,520 --> 00:12:23,670
questionnaires and we&#39;ll actually have additional people in the room who&#39;s job it

210
00:12:23,670 --> 00:12:27,630
is to log the critical incidents so that we can review them later.

211
00:12:27,630 --> 00:12:29,320
And also, in a micro usability test,

212
00:12:29,320 --> 00:12:32,510
we&#39;re not gonna go quite as deeply into the analysis as we might do.

213
00:12:32,510 --> 00:12:36,200
So in a standard usability test, we&#39;ll actually review the recordings and

214
00:12:36,200 --> 00:12:37,670
review the notes.

215
00:12:37,670 --> 00:12:40,650
We&#39;ll collate the data from the questionnaires and

216
00:12:40,650 --> 00:12:45,300
maybe correlate it with the results from the tests and things like that.

217
00:12:45,300 --> 00:12:47,240
For the micro-usability tests,

218
00:12:47,240 --> 00:12:49,990
we&#39;re gonna really do a much more off-the-cuff analysis.

219
00:12:49,990 --> 00:12:53,620
Where we sit down right afterwards, we think about what would have three or

220
00:12:53,620 --> 00:12:56,200
four most important things that we observed and

221
00:12:56,200 --> 00:13:00,600
what can we do with that to improve the product in the next cycle.

222
00:13:00,600 --> 00:13:02,620
Okay, so that&#39;s the basics right there.

223
00:13:02,620 --> 00:13:07,398
So next up we&#39;re gonna provide you an example of a micro-usability test that we

224
00:13:07,398 --> 00:13:11,107
conducted here in the studios at the University of Michigan so

225
00:13:11,107 --> 00:13:13,984
that you can get an idea of what this looks like.

226
00:13:13,984 --> 00:13:18,682
And then over the next couple of weeks you will go through the process of preparing

227
00:13:18,682 --> 00:13:21,600
and conducting your own micro-usability test.

228
00:13:21,600 --> 00:13:23,720
Good luck.

