0
00:00:00,000 --> 00:00:04,960
[MUSIC PLAYING]

1
00:00:05,860 --> 00:00:08,559
BLAKE MCKIMMIE: Well, Bill, thanks for joining us today. BILL VON HIPPEL: My pleasure.

2
00:00:08,559 --> 00:00:11,929
BLAKE MCKIMMIE: So, Bill, we&#39;ve been talking a bit about deception and people&#39;s ability

3
00:00:11,929 --> 00:00:13,610
to detect deception.

4
00:00:13,610 --> 00:00:18,300
And one of the challenges that people face is they often think that they&#39;re very good

5
00:00:18,300 --> 00:00:19,370
at detecting deception.

6
00:00:19,370 --> 00:00:21,260
But the research suggests that they&#39;re not.

7
00:00:21,260 --> 00:00:25,890
And one of the reasons is because people have a stereotype that&#39;s a bit inaccurate about

8
00:00:25,890 --> 00:00:28,810
what nonverbal behavior should look like.

9
00:00:28,810 --> 00:00:31,460
When somebody is being deceptive, they focus on all of these things.

10
00:00:31,460 --> 00:00:33,980
But they&#39;re just indicators of nervousness.

11
00:00:33,980 --> 00:00:39,670
And so this has kind of led people to conclude that people just generally are not very accurate

12
00:00:39,670 --> 00:00:40,809
at deception detection.

13
00:00:40,809 --> 00:00:43,289
Is that really the conclusion we should draw from their research?

14
00:00:43,289 --> 00:00:46,980
BILL VON HIPPEL: Well, first of all I definitely agree with you that people make the mistake

15
00:00:46,980 --> 00:00:49,319
of equating nervousness with deceiving.

16
00:00:49,319 --> 00:00:52,739
And, of course, if you&#39;re interrogating me and I&#39;m worried what happens if you don&#39;t

17
00:00:52,739 --> 00:00:54,320
believe me, I&#39;ll be nervous.

18
00:00:54,320 --> 00:00:56,270
Even if I know I&#39;m completely innocent.

19
00:00:56,270 --> 00:00:59,179
So I think those data are all very reliable.

20
00:00:59,179 --> 00:01:03,510
But I think it&#39;s too big of an inference to then go on and say people can&#39;t detect deception.

21
00:01:03,510 --> 00:01:07,799
Now, I&#39;m making this argument in the face of a huge database that shows that people

22
00:01:07,799 --> 00:01:08,799
can&#39;t do it.

23
00:01:08,799 --> 00:01:10,970
So, of course, that raises the question, why would you make such an argument?

24
00:01:10,970 --> 00:01:15,350
And I think the answer to that question is that the research has been done in a way that

25
00:01:15,350 --> 00:01:20,250
facilitated ease of research, but didn&#39;t facilitate matching real world deception.

26
00:01:20,250 --> 00:01:23,130
So real world deceptions are typically important.

27
00:01:23,130 --> 00:01:26,070
I&#39;m not just lying to you about your haircut I&#39;m lying to you about something that, if

28
00:01:26,070 --> 00:01:28,530
I&#39;m discovered, I&#39;ll suffer for it.

29
00:01:28,530 --> 00:01:30,430
And they&#39;re often quite complicated.

30
00:01:30,430 --> 00:01:35,009
We eliminate all that in our typical research paradigm, where we just videotape somebody

31
00:01:35,009 --> 00:01:38,840
who&#39;s telling a simple lie, and then I watch a videotape and I try to say if they&#39;re telling

32
00:01:38,840 --> 00:01:39,840
the truth or not.

33
00:01:39,840 --> 00:01:41,640
It&#39;s great for experimental control.

34
00:01:41,640 --> 00:01:45,780
It&#39;s lousy for getting at the underlying dimensions of what really is involved when people deceive.

35
00:01:45,780 --> 00:01:49,760
BLAKE MCKIMMIE: So there&#39;s are no real consequences in the lab for getting it wrong, like when

36
00:01:49,760 --> 00:01:51,479
you&#39;re trying to figure out if someone&#39;s lying.

37
00:01:51,479 --> 00:01:56,580
And for the lair themselves on the video, what have they got vested in trying to dupe

38
00:01:56,580 --> 00:01:57,580
someone?

39
00:01:57,580 --> 00:01:58,580
BILL VON HIPPEL: That&#39;s right.

40
00:01:58,580 --> 00:01:59,580
They don&#39;t care if they&#39;re caught.

41
00:01:59,580 --> 00:02:01,609
And the lie the telling is typically very simple.

42
00:02:01,609 --> 00:02:05,170
That they&#39;re asked to go in the professor&#39;s office, steal the wallet off the table, or

43
00:02:05,170 --> 00:02:06,170
don&#39;t.

44
00:02:06,170 --> 00:02:07,549
And then they have to claim they didn&#39;t.

45
00:02:07,549 --> 00:02:09,660
And we don&#39;t know which it is that they really did.

46
00:02:09,660 --> 00:02:11,530
So that&#39;s a super-easy lie.

47
00:02:11,530 --> 00:02:12,830
I didn&#39;t take the wallet, right?

48
00:02:12,830 --> 00:02:14,950
You just keep saying that over and over again.

49
00:02:14,950 --> 00:02:18,980
And you&#39;re on videotape, and you&#39;re not going to suffer if people believe you did.

50
00:02:18,980 --> 00:02:21,660
But the real world, we often tell very complicated lies.

51
00:02:21,660 --> 00:02:24,840
They involve reshaping all sorts of world events.

52
00:02:24,840 --> 00:02:28,150
So that I really wasn&#39;t at the bowling alley with your wife at that time, or whatever the

53
00:02:28,150 --> 00:02:29,430
case might be.

54
00:02:29,430 --> 00:02:31,110
And it&#39;s very easy to get caught out in those.

55
00:02:31,110 --> 00:02:34,590
And so, in our lab, we&#39;ve done a little bit of work on this, where we try to get people

56
00:02:34,590 --> 00:02:37,310
to engage in some very complicated lies.

57
00:02:37,310 --> 00:02:39,430
And then see if people can detect them.

58
00:02:39,430 --> 00:02:44,000
And what we found today is that, in fact, when people tell these complicated lies, there&#39;s

59
00:02:44,000 --> 00:02:45,190
a bit of a truth bias.

60
00:02:45,190 --> 00:02:46,480
And people believe that they&#39;re true.

61
00:02:46,480 --> 00:02:47,810
They just automatically accept them.

62
00:02:47,810 --> 00:02:51,260
But as soon as we alert them to the fact that there was a lie that was told, people are

63
00:02:51,260 --> 00:02:55,040
very accurate in saying, well, in that case, I think you&#39;re the one who actually told this

64
00:02:55,040 --> 00:02:56,040
lie.

65
00:02:56,040 --> 00:02:59,010
Now interestingly, in our initial study, interrogation didn&#39;t help.

66
00:02:59,010 --> 00:03:02,920
It was just their thinking back on the whole sequence of events and where the lie likely

67
00:03:02,920 --> 00:03:06,080
was that is what enabled them to discover it.

68
00:03:06,080 --> 00:03:10,150
But nonetheless, it shows that, even when people initially accept something is true,

69
00:03:10,150 --> 00:03:13,569
they&#39;re actually quite capable, when the lie is meaningful, the lie is complicated, and

70
00:03:13,569 --> 00:03:16,220
the lie&#39;s told to their face, they&#39;re capable of going back and finding it.

71
00:03:16,220 --> 00:03:19,250
BLAKE MCKIMMIE: So what did you do in your studies, then, that was different from the

72
00:03:19,250 --> 00:03:24,830
prototypical deception study, that improves deception detection accuracy?

73
00:03:24,830 --> 00:03:27,360
BILL VON HIPPEL: So in this particular study, we did a few things.

74
00:03:27,360 --> 00:03:29,319
First of all, they were always friends with each other.

75
00:03:29,319 --> 00:03:33,000
Because if you&#39;re not somebody&#39;s friend, you might not know when they&#39;re showing cues of

76
00:03:33,000 --> 00:03:37,170
cognitive load or raised pitch of their voice, the things that really are indicative of lying.

77
00:03:37,170 --> 00:03:39,260
Because you don&#39;t know what their voice usually sounds like.

78
00:03:39,260 --> 00:03:40,870
And you don&#39;t know how quickly they usually speak.

79
00:03:40,870 --> 00:03:42,940
So they are always groups of friends.

80
00:03:42,940 --> 00:03:46,970
And then we had them tell this complicated lie where they&#39;re involved with each other,

81
00:03:46,970 --> 00:03:49,800
and they&#39;re trying to get their partners to make a bad choice.

82
00:03:49,800 --> 00:03:51,780
It&#39;s an ambiguous situation, nobody knows the answer.

83
00:03:51,780 --> 00:03:54,269
But they&#39;re pushing an answer that they know is wrong.

84
00:03:54,269 --> 00:03:55,909
But they&#39;re told you have to push it subtly.

85
00:03:55,909 --> 00:03:59,770
You&#39;ll get paid if your group buys your answer, but only if they don&#39;t detect you as a liar.

86
00:03:59,770 --> 00:04:04,020
So doing this as gently as they can, but nonetheless, people know them well, and they get a chance

87
00:04:04,020 --> 00:04:06,830
to think, well, who was speaking more than they ought to if they can go back and look

88
00:04:06,830 --> 00:04:12,780
for unusual events in the episode that took place and try to find the liar or that way.

89
00:04:12,780 --> 00:04:14,260
Real life is often that way.

90
00:04:14,260 --> 00:04:15,420
Of course it&#39;s often not.

91
00:04:15,420 --> 00:04:18,489
Maybe the lie took place in hidden circumstances.

92
00:04:18,488 --> 00:04:21,680
But then we can say, well, how well do the other circumstances fit with what the liar&#39;s

93
00:04:21,680 --> 00:04:22,680
trying to tell us?

94
00:04:22,680 --> 00:04:27,000
And I think that what these data show us is that interrogation, which we believe is really

95
00:04:27,000 --> 00:04:29,090
effective, may not be terribly effective.

96
00:04:29,090 --> 00:04:32,930
But our good knowledge about people and about the ways they usually behave actually can

97
00:04:32,930 --> 00:04:36,490
be very useful for us detecting, well, when are they trying to do something that&#39;s a bit

98
00:04:36,490 --> 00:04:37,900
different from what they would usually do?

99
00:04:37,900 --> 00:04:41,900
BLAKE MCKIMMIE: And so they&#39;re able to reasonably, accurately detect deception, even when they&#39;re

100
00:04:41,900 --> 00:04:44,259
not actively looking for it just in retrospect, thinking back.

101
00:04:44,259 --> 00:04:45,259
BILL VON HIPPEL: Yeah.

102
00:04:45,259 --> 00:04:46,259
That&#39;s exactly right.

103
00:04:46,259 --> 00:04:50,169
So in our case, we had 250 people in this experiment.

104
00:04:50,169 --> 00:04:53,870
And we asked them at the end of this study, once they done their group decision making

105
00:04:53,870 --> 00:04:58,460
task, not knowing that one of the group members was a saboteur, we say to them, OK, what&#39;s

106
00:04:58,460 --> 00:04:59,490
this study really about?

107
00:04:59,490 --> 00:05:01,430
It&#39;s not about group decision making.

108
00:05:01,430 --> 00:05:03,220
So we were deceiving you.

109
00:05:03,220 --> 00:05:04,310
There&#39;s something else going on.

110
00:05:04,310 --> 00:05:08,461
Not a single person out of 250 said it was about deception, and that one of the people

111
00:05:08,461 --> 00:05:09,720
here is a liar.

112
00:05:09,720 --> 00:05:11,620
Then we say, well, it&#39;s actually about deception.

113
00:05:11,620 --> 00:05:13,150
One of the people here is a liar.

114
00:05:13,150 --> 00:05:18,259
And when chance would be 50%, if you set it up that way, they were way up, like 75 or

115
00:05:18,259 --> 00:05:19,259
80.

116
00:05:19,259 --> 00:05:21,720
And so the typical the chance is you&#39;re a 53.

117
00:05:21,720 --> 00:05:23,310
You&#39;re not a 75.

118
00:05:23,310 --> 00:05:26,639
So it&#39;s clearly a case where now, even though they believed it the first time, they think

119
00:05:26,639 --> 00:05:29,960
back on all the complicated things that took place during that group discussion.

120
00:05:29,960 --> 00:05:31,110
There&#39;s something fishy here.

121
00:05:31,110 --> 00:05:32,390
And Blake, you&#39;re the one.

122
00:05:32,390 --> 00:05:37,509
BLAKE MCKIMMIE: Do you think that knowing the person is potentially deceptive is one

123
00:05:37,509 --> 00:05:38,740
of the key factors?

124
00:05:38,740 --> 00:05:41,979
Because you&#39;ve had feedback from previous interactions with them about when they&#39;re

125
00:05:41,979 --> 00:05:43,160
being truthful and not.

126
00:05:43,160 --> 00:05:48,090
Do you think feedback plays a role in increasing their ability to detect deception?

127
00:05:48,090 --> 00:05:49,250
BILL VON HIPPEL: I think that.

128
00:05:49,250 --> 00:05:50,820
But I don&#39;t have any evidence for it.

129
00:05:50,820 --> 00:05:55,210
So it&#39;s our belief that, in the small groups that we evolved in, we always knew all the

130
00:05:55,210 --> 00:05:56,230
people we interacted with.

131
00:05:56,230 --> 00:06:00,341
So if we were trying to develop abilities, evolve abilities, to detect deception, they&#39;re

132
00:06:00,341 --> 00:06:04,330
likely comparing the Blake that I&#39;m watching now with the Blake I&#39;ve known for a long time.

133
00:06:04,330 --> 00:06:06,180
And making judgments about differences.

134
00:06:06,180 --> 00:06:08,840
And so when somebody is a stranger, you can&#39;t do that.

135
00:06:08,840 --> 00:06:13,020
We believe that plays a critical role, but we haven&#39;t run the study that involves strangers.

136
00:06:13,020 --> 00:06:14,289
So we don&#39;t know.

137
00:06:14,289 --> 00:06:17,190
Even our paradigm wouldn&#39;t work with strangers, anyway.

138
00:06:17,190 --> 00:06:20,599
People are awfully polite to strangers, and so they might not be willing to do the things

139
00:06:20,599 --> 00:06:22,850
that they&#39;re happy to mess around with their friends.

140
00:06:22,850 --> 00:06:27,520
But it&#39;s my suspicion that it matters a lot that you know the person, that we&#39;re good

141
00:06:27,520 --> 00:06:29,720
at comparing current to prior behaviors.

142
00:06:29,720 --> 00:06:33,599
That it matters a lot that the lie&#39;s important, so there&#39;s something really on the line.

143
00:06:33,599 --> 00:06:35,930
That it matters a lot that the lie is complicated.

144
00:06:35,930 --> 00:06:38,849
So there&#39;s not just an issue of repeating over and over, &quot;I didn&#39;t do it.&quot;

145
00:06:38,849 --> 00:06:43,210
BLAKE MCKIMMIE: So to increase the consequences, or to increase the stakes, of getting away

146
00:06:43,210 --> 00:06:44,630
with that deception.

147
00:06:44,630 --> 00:06:48,669
But also in detecting the deception, you paid your participants money.

148
00:06:48,669 --> 00:06:52,050
So can you just tell us a little bit about how that worked exactly

149
00:06:52,050 --> 00:06:53,050
BILL VON HIPPEL: Sure.

150
00:06:53,050 --> 00:06:55,090
So one of the people&#39;s the saboteur.

151
00:06:55,090 --> 00:06:58,599
And they&#39;re told, we&#39;ll pay you for every wrong answer you can convince your group to

152
00:06:58,599 --> 00:06:59,599
use.

153
00:06:59,599 --> 00:07:01,919
The group is paid for every right answer that they choose.

154
00:07:01,919 --> 00:07:03,710
So they&#39;re clearly at cross-purposes for each other.

155
00:07:03,710 --> 00:07:04,810
Now, they&#39;re not paid much.

156
00:07:04,810 --> 00:07:06,360
A dollar per answer.

157
00:07:06,360 --> 00:07:11,110
The key with the saboteur, though, is that, to really tell a lie, I have to not only convince

158
00:07:11,110 --> 00:07:12,110
you in the moment.

159
00:07:12,110 --> 00:07:14,949
But I have to convince you later on when somebody-- when it discovers that somebody did have an

160
00:07:14,949 --> 00:07:15,949
affair with your wife.

161
00:07:15,949 --> 00:07:17,560
I don&#39;t want you to think it&#39;s me.

162
00:07:17,560 --> 00:07:21,919
And so they were told, you&#39;ll be paid a dollar for every wrong answer you convince your group,

163
00:07:21,919 --> 00:07:26,100
if / when they then find out there&#39;s a saboteur, and they don&#39;t use you.

164
00:07:26,100 --> 00:07:31,060
And so they could make an extra $10 or $15 if they could successfully lie to their group

165
00:07:31,060 --> 00:07:34,900
and convince the group, even later on when interrogation took place, they&#39;re the only

166
00:07:34,900 --> 00:07:38,660
ones who knew, eventually it will be revealed, that there was a liar in here.

167
00:07:38,660 --> 00:07:41,199
And they have to convince the group later on that that liar was not them.

168
00:07:41,199 --> 00:07:44,520
BLAKE MCKIMMIE: Don&#39;t you think the money was the only thing that they were really striving

169
00:07:44,520 --> 00:07:46,270
for and trying to get away with the lie?

170
00:07:46,270 --> 00:07:48,129
BILL VON HIPPEL: Look, the money was nice, of course.

171
00:07:48,129 --> 00:07:51,400
But I actually think that what it really came down to was the social fun.

172
00:07:51,400 --> 00:07:54,850
They want to pull one over on their friends and prove that they could lie to them.

173
00:07:54,850 --> 00:07:58,169
And the friends don&#39;t want to have somebody pulling the wool over their eyes.

174
00:07:58,169 --> 00:08:02,800
And so the lab is right next to my office, and when it was revealed that there was a

175
00:08:02,800 --> 00:08:05,680
saboteur, there was laughter and accusations and yelling and back and forth.

176
00:08:05,680 --> 00:08:07,280
And it was a lot of fun for them.

177
00:08:07,280 --> 00:08:10,669
And you could see they were bound and determined not to be found out.

178
00:08:10,669 --> 00:08:13,540
And they were also bound and determined to find out who it really was.

179
00:08:13,540 --> 00:08:15,409
And the few dollars probably made little difference.

180
00:08:15,409 --> 00:08:21,949
BLAKE MCKIMMIE: So maybe the conclusion, one thing you might take from your study, then,

181
00:08:21,949 --> 00:08:25,020
detecting deception is really a social thing.

182
00:08:25,020 --> 00:08:28,190
It&#39;s not an individual&#39;s ability per se.

183
00:08:28,190 --> 00:08:32,440
But it&#39;s something that comes out of being in a social group and living in a social context.

184
00:08:32,440 --> 00:08:34,320
BILL VON HIPPEL: That&#39;s exactly right.

185
00:08:34,320 --> 00:08:38,130
The deception is a social process, just like truth-telling is.

186
00:08:38,130 --> 00:08:41,640
And so truth-telling is about making sure that you and I both understand the world as

187
00:08:41,640 --> 00:08:42,800
it really is.

188
00:08:42,799 --> 00:08:46,410
And deception is making sure that you and I understand a world that&#39;s favorable to me,

189
00:08:46,410 --> 00:08:48,290
but is not how the world really is.

190
00:08:48,290 --> 00:08:50,210
Both of those are social processes.

191
00:08:50,210 --> 00:08:54,790
Sometimes I can get you on board, and you would rather just go with me than really know

192
00:08:54,790 --> 00:08:55,790
the truth.

193
00:08:55,790 --> 00:08:57,430
Because your relationship is more important than the facts.

194
00:08:57,430 --> 00:08:59,980
Other times, the facts are more important than the relationship.

195
00:08:59,980 --> 00:09:04,250
But in all cases, what we&#39;re trying to do is create these competing social realities

196
00:09:04,250 --> 00:09:07,770
that allow us to, in the end, understand what&#39;s really going on.

197
00:09:07,770 --> 00:09:10,290
But also, in the end, be on the same page as each other.

198
00:09:10,290 --> 00:09:11,400
That&#39;s a fundamental human motive

199
00:09:11,400 --> 00:09:12,400
BLAKE MCKIMMIE: Excellent.

200
00:09:12,400 --> 00:09:12,900
Thanks, Bill.

