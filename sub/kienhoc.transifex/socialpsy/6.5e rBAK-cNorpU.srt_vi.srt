0
00:00:06,620 --> 00:00:08,400
Cảm ơn Alex đã tham gia cùng chúng tôi ngày hôm nay

1
00:00:08,420 --> 00:00:09,420
Xin cảm ơn

2
00:00:09,420 --> 00:00:13,960
Bây giờ chúng ta sẽ bàn đôi chút về 
nghiên cứu của Milgram

3
00:00:13,960 --> 00:00:20,320
và ý nghĩ rằng cuối Thế chiến thứ hai
khi mọi người nhận thức hơn 

4
00:00:20,320 --> 00:00:24,980
về sự ghê rợn, tàn ác trong cuộc chiến
một trong những cách giải thích 

5
00:00:24,980 --> 00:00:29,380
thường được đưa ra cho sự việc đó
là chắc phải có gì đó không ổn

6
00:00:29,380 --> 00:00:32,930
với người Đức, và vì thế
họ mới đồng lõa với hành động đó

7
00:00:32,930 --> 00:00:38,610
Milgram tiến hành một nghiên cứu
yêu cầu người tham gia sốc điện các học sinh

8
00:00:38,610 --> 00:00:40,560
chúng ta đã nghe qua thí nghiệm này
trong khóa học

9
00:00:40,560 --> 00:00:45,370
Giờ đây ông lại đưa ra một cách giải thích
hơi khác hay thậm chí là rất khác

10
00:00:45,370 --> 00:00:46,960
cho các sự việc khủng khiếp đã xảy ra

11
00:00:46,960 --> 00:00:48,320
Anh có thể nói thêm về việc này không ạ?

12
00:00:48,320 --> 00:00:53,020
Milgram tiến hành thí nghiệm 15 năm

13
00:00:53,020 --> 00:00:55,950
sau chiến tranh, vào đầu những năm 60

14
00:00:55,950 --> 00:01:02,980
Và như bạn nói, tôi nghĩ ông ấy
không bị thuyết phục bởi khác biệt cá nhân


15
00:01:02,980 --> 00:01:04,820
những phán đoán về hành động bạo ngược dựa trên tính cách

16
00:01:04,819 --> 00:01:08,870
Một điều hiển nhiên là rất khó có khả năng
tất cả mọi người Đức

17
00:01:08,870 --> 00:01:15,850
đều có chung tính cách, hay có chung
sự thiếu hụt tính cách hay bệnh lý nào đó

18
00:01:15,850 --> 00:01:20,460
dẫn đến sự việc bạn thấy được ở vụ thảm sát Đức Quốc xã

19
00:01:20,460 --> 00:01:23,160
Như vậy, bạn cần một cách giải thích khác

20
00:01:23,160 --> 00:01:28,000
Theo tôi, Milgram đang tìm kiếm
nguyên nhân

21
00:01:28,000 --> 00:01:33,680
Ông chịu ảnh hưởng từ công trình
nghiên cứu của Solômn Asch về ảnh hưởng xã hội

22
00:01:33,680 --> 00:01:40,150
Quan niệm cho rằng chúng ra bị ảnh hưởng
bởi người khác và sẽ có thể làm theo

23
00:01:40,150 --> 00:01:46,300
quan điểm, ý muốn của người khác
được Milgram thấy có vẻ hợp lý

24
00:01:46,300 --> 00:01:53,870
Nên ông đã tạo một hình mẫu để người tham gia
vào trong, và người xem

25
00:01:53,870 --> 00:01:58,720
có khả năng nhận thức sẽ được yêu cầu
đóng vai giáo viên trong một thí nghiệm học tập

26
00:01:58,720 --> 00:02:03,080
Người làm thí nghiệm hưỡng dẫn họ mỗi lần học sinh
phạm lỗi khi làm bài tập

27
00:02:03,080 --> 00:02:09,470
họ phải tăng mức sốc điện lên 15 vôn

28
00:02:09,470 --> 00:02:15,600
từ 0 vôn đến 450 vôn, mức điện gọi là XXX

29
00:02:15,600 --> 00:02:18,210
sốc điện cực kỳ nguy hiểm, vượt xa mức nguy hiểm 

30
00:02:18,210 --> 00:02:23,120
Thật ra tất cả đã được dàn xếp
không có sốc điện nào là thật cả

31
00:02:23,120 --> 00:02:24,810
nhưng người tham gia không hề biết

32
00:02:24,810 --> 00:02:30,990
mặc dù có vẻ như câu hỏi đặt ra là
một người bình thường như người dân ở New Haven

33
00:02:30,990 --> 00:02:38,890
ở lân cận hay xung quanh Yale ở Connecticut,
liệu họ có sẵn sàng giết chết ai đó

34
00:02:38,890 --> 00:02:43,110
vì được người làm thí nghiệm yêu cầu 
trong một thí nghiệm tâm lý?

35
00:02:43,110 --> 00:02:47,709
Khi Milgram hỏi các bác sĩ tâm thần và một số người
liệu họ có làm thế không

36
00:02:47,709 --> 00:02:49,180
họ đều trả lời, tất nhiên là không

37
00:02:49,180 --> 00:02:54,260
Họ nói, có thể chỉ khoảng 2% người sẽ đi đến mức
450 vôn 

38
00:02:54,260 --> 00:02:57,410
vì đó là tỉ lệ người mắc bệnh tâm thần trong cộng đồng

39
00:02:57,410 --> 00:03:02,820
Như những người học tâm lý đều biết,
kết quả thí nghiệm Milgram thu được,

40
00:03:02,820 --> 00:03:08,550
trong điều kiện chuẩn, là có 65% người

41
00:03:08,550 --> 00:03:09,550
đi đến mức điện cao nhất

42
00:03:09,550 --> 00:03:13,069
Điều này cho thấy hành vi này không chỉ kì lạ
trong một nhóm người nào đó

43
00:03:13,069 --> 00:03:16,910
nhưng nó là một thứ gì đó
khá cơ bản và thường thấy

44
00:03:16,910 --> 00:03:17,910
trong tâm lý mọi người

45
00:03:17,910 --> 00:03:26,020
quan niệm của ông là, theo một góc độ nào đó
con người được lập trình để tuân theo những người có quyền

46
00:03:26,020 --> 00:03:31,080
đó là cách xã hội cấu thành, đó là điều ta được học,
và chúng ta thường ở trong những tình huống

47
00:03:31,080 --> 00:03:36,770
có những quyền lực rõ ràng, và chúng ta
nhường lại trách nhiệm cho họ

48
00:03:36,770 --> 00:03:41,980
Chúng ta nhường lại trách nhiệm cho họ bằng nhiều cách,
và thực sự câu hỏi chúng ta đưa ra là bạn muốn tôi làm gì

49
00:03:41,980 --> 00:03:46,290
tôi sẽ làm, chứ không phải câu hỏi, bạn đang
yêu cầu tôi làm gì

50
00:03:46,290 --> 00:03:47,520
và liệu tôi có nên làm không

51
00:03:47,520 --> 00:03:51,300
Như vậy nó không phải là về tính cách

52
00:03:51,300 --> 00:03:53,080
nhưng là về hoàn cảnh xã hội

53
00:03:53,080 --> 00:03:57,550
Đó là luận điểm của Milgram.
Nguyên do là tình huống

54
00:03:57,550 --> 00:04:02,739
chứ không phải tại con người
và trong những tình huống bức bách

55
00:04:02,739 --> 00:04:06,629
hầu hết mọi người sẽ theo
những áp lực trong hoàn cảnh đó

56
00:04:06,629 --> 00:04:11,910
Tức là nó không phải do cá nhân,

57
00:04:11,910 --> 00:04:13,120
nhưng do tình huống

58
00:04:13,120 --> 00:04:19,329
Vấn đề là ban đầu khi bạn nhìn vào dữ liệu của Milgram
bạn sẽ thấy

59
00:04:19,329 --> 00:04:21,359
không phải tất cả người tham gia 
đều đi đến mức điện cao nhất

60
00:04:21,358 --> 00:04:26,589
Thật ra trong suốt nghiên cứu,
ông có 30 phiên bản tiến hành khác nhau

61
00:04:26,589 --> 00:04:30,849
trung bình thì hầu hết người tham gia không
đi đến mức cao nhất, và trong các nghiên cứu này
mức độ sẵn sàng

62
00:04:30,849 --> 00:04:36,819
đi đến cuối cùng đi từ 100% trong một số trường hợp
xuống 0% trong trường hợp khác

63
00:04:36,819 --> 00:04:42,199
Nên thực sự quan niệm cho rằng chúng ta
chỉ biết tuân theo uy quyền là không hợp lý

64
00:04:42,199 --> 00:04:45,860
vì rõ ràng chúng ta thấy có khá nhiều khả năng xảy ra

65
00:04:45,860 --> 00:04:51,120
và vấn đề của phân tích của Milgram khi
chúng ta rơi vào trạng thái mà ông gọi là
trạng thái vâng phục

66
00:04:51,120 --> 00:04:55,900
khi mà ta chỉ tuân theo người có quyền
đó là trạng thái này cũng không giải thích được
dữ liệu nghiên cứu của ông

67
00:04:55,900 --> 00:04:58,370
Tôi nghĩ đóng gớp của ông khá quan trọng

68
00:04:58,370 --> 00:04:59,580
Nhưng rõ ràng còn hạn chế

69
00:04:59,580 --> 00:05:05,150
Vậy anh đã làm một số nghiên cứu
dựa trên ý tưởng này và khám phá

70
00:05:05,150 --> 00:05:10,330
nếu lý do trên không giải thích được
thì đâu là nguyên nhân của hành vi này?

71
00:05:10,330 --> 00:05:15,069
Theo tôi, bạn có thể tham khảo ở nhiều nguồn

72
00:05:15,069 --> 00:05:21,270
Nhưng bạn có thể bắt đầu xem qua
một trong những nghiên cứu thành công nhất

73
00:05:21,270 --> 00:05:22,270
trong các phiên bản của nghiên cứu Milgram

74
00:05:22,270 --> 00:05:23,410
Có khoảng 30 phiên bản 

75
00:05:23,410 --> 00:05:25,940
Và xem xét xem đâu là thí nghiệm
mà mọi người đi đến cuối cùng?

76
00:05:25,940 --> 00:05:27,779
và thí nghiệm nào mọi người không làm đến cùng?

77
00:05:27,779 --> 00:05:33,869
Và điều bạn thấy rõ là mọi người
đi đến cuối thí nghiệm


78
00:05:33,869 --> 00:05:40,270
bị mắc kẹt trong sự liên hệ mật thiết
ới người làm thí nghiệm và khoa học

79
00:05:40,270 --> 00:05:41,719
của thí nghiệm

80
00:05:41,719 --> 00:05:46,689
Họ không tiếp xúc được với
ảnh hưởng ngược lại trên học sinh

81
00:05:46,689 --> 00:05:50,809
Các bạn thấy được trong đièu kiện chuẩn
khi mức độ tuân thủ mệnh lệnh là 65%

82
00:05:50,809 --> 00:05:57,020
Họ bị giằng co giữa việc 
nên nghe theo người làm thí nghiệm
hay các học sinh

83
00:05:57,020 --> 00:06:00,619
Theo tôi, thật ra cái bạn thấy phụ thuộc
vào cách họ liên hệ cảm xúc của họ,

84
00:06:00,619 --> 00:06:07,349
mức độ thông cảm với
việc làm của người làm thí nghiệm


85
00:06:07,349 --> 00:06:13,939
so với những gì người tham gia thí nghiệm phát biểu
như một người bình thường, tử tế trong xã hội

86
00:06:13,939 --> 00:06:16,999
way they go, that&#39;s how they make-- that&#39;s the critical variable.

87
00:06:16,999 --> 00:06:21,430
Bạn có thể thấy trong các 
phiên bản khác của nghiên cứu,
Milgram đã thay đổi

88
00:06:21,430 --> 00:06:27,149
extent to which the participants are oriented towards the experimenter or oriented towards

89
00:06:27,149 --> 00:06:28,149
the learner.

90
00:06:28,149 --> 00:06:32,409
If the learner is in the room next to them, then they identify much more with him-- it&#39;s

91
00:06:32,409 --> 00:06:36,139
always a male-- and so they are much less likely to administer the shocks.

92
00:06:36,139 --> 00:06:40,430
If the learner is not in the room, and, indeed, you don&#39;t hear from him, all you hear from

93
00:06:40,430 --> 00:06:45,010
is the experimenter, then actually-- and that was in the very first study that Milgram did--

94
00:06:45,010 --> 00:06:46,659
they go all the way to the end.

95
00:06:46,659 --> 00:06:52,789
So again, it&#39;s really about identification and buying into the task that you&#39;re being

96
00:06:52,789 --> 00:06:54,789
asked to contribute to.

97
00:06:54,789 --> 00:06:59,029
And if you undermine the identification in some way or other by-- and there&#39;s lots of

98
00:06:59,029 --> 00:07:04,309
ways in which Milgram does that-- what you see is that you don&#39;t get the effects that

99
00:07:04,309 --> 00:07:06,289
everybody associates with that study.

100
00:07:06,289 --> 00:07:11,029
So they&#39;re very much contingent upon participants thinking that what they&#39;re doing is worthwhile

101
00:07:11,029 --> 00:07:15,240
and useful and helpful and valuable.

102
00:07:15,240 --> 00:07:19,009
And to the extent that they believe, then, that that is the case, they do it.

103
00:07:19,009 --> 00:07:23,409
It&#39;s not that they&#39;re blind, or they&#39;re ignorant, or they&#39;re stupid, or they&#39;re not paying attention.

104
00:07:23,409 --> 00:07:24,800
They are paying attention.

105
00:07:24,800 --> 00:07:28,020
They just think that this is a very important scientific project and that they&#39;re doing

106
00:07:28,020 --> 00:07:29,509
something helpful.

107
00:07:29,509 --> 00:07:33,319
And that&#39;s really a very-- and so they&#39;re cooperating with the experimenter and not

108
00:07:33,319 --> 00:07:35,349
just obeying blindly.

109
00:07:35,349 --> 00:07:42,219
And I think that lends itself to a very different understanding of why people commit-- perpetrate

110
00:07:42,219 --> 00:07:43,800
obscene atrocities.

111
00:07:43,800 --> 00:07:47,499
Again, typically what you find is not that they&#39;re just-- not they don&#39;t know what they&#39;re

112
00:07:47,499 --> 00:07:48,499
doing.

113
00:07:48,499 --> 00:07:52,139
They do it because they actually really believe in the cause that they&#39;re following and the

114
00:07:52,139 --> 00:07:54,330
leadership of that cause.

115
00:07:54,330 --> 00:07:58,539
And they also believe that it&#39;s actually a good and worthy cause.

116
00:07:58,539 --> 00:07:59,979
That&#39;s actually very critical.

117
00:07:59,979 --> 00:08:04,699
It&#39;s not that they think, oh, this is a bad thing, but I&#39;m just being asked to do it.

118
00:08:04,699 --> 00:08:07,139
No, they&#39;ll actually convinced themself it&#39;s a good thing.

119
00:08:07,139 --> 00:08:10,840
BLAKE MCKIMMIE: And I think you&#39;ve also looked at what some of the participants in that study

120
00:08:10,840 --> 00:08:14,219
actually said when they&#39;re interviewed after participating.

121
00:08:14,219 --> 00:08:18,389
And if you look at the words they&#39;re using, it&#39;s clear they&#39;re not just blindly following.

122
00:08:18,389 --> 00:08:20,460
They&#39;re often quite torn about what they&#39;re done, and--

123
00:08:20,460 --> 00:08:23,591
ALEX HASLAM: Yeah, so I think the thing is, clearly, at that time, the participants are

124
00:08:23,591 --> 00:08:25,849
very stressed by what they have to do.

125
00:08:25,849 --> 00:08:29,610
But they steel themselves to that task, and they follow it through because they believe

126
00:08:29,610 --> 00:08:32,390
that they&#39;re making a contribution to the science.

127
00:08:32,390 --> 00:08:37,930
So yeah, this is-- they believe that this enterprise is valuable, so they struggle on.

128
00:08:37,929 --> 00:08:41,780
And then at the end, of course, Milgram says, well, actually, thanks very much for participating

129
00:08:41,780 --> 00:08:42,780
in the study.

130
00:08:42,780 --> 00:08:46,060
You&#39;ve made a fantastic contribution to science because now we understand why people behave

131
00:08:46,060 --> 00:08:49,721
in the way that you did and we see in other kinds of situations.

132
00:08:49,721 --> 00:08:52,320
And the participants feel good about what they&#39;ve done because they&#39;ve made a contribution

133
00:08:52,320 --> 00:08:53,320
to that.

134
00:08:53,320 --> 00:08:58,860
So they actually-- Milgram does a really good job of explaining to them that they have,

135
00:08:58,860 --> 00:09:03,050
indeed, been good subjects and that what they have done is good.

136
00:09:03,050 --> 00:09:09,820
And one of the really interesting consequences of that is that while we have a sense as outsiders

137
00:09:09,820 --> 00:09:13,321
that the participants must have felt pretty crappy because of what they&#39;d done, actually

138
00:09:13,321 --> 00:09:17,960
they felt very good because they didn&#39;t really undersee it from other people&#39;s perspective--

139
00:09:17,960 --> 00:09:19,110
look you&#39;ve done a terrible thing.

140
00:09:19,110 --> 00:09:20,880
No, they didn&#39;t think they&#39;d done a terrible thing.

141
00:09:20,880 --> 00:09:22,690
They thought they&#39;d done a good thing.

142
00:09:22,690 --> 00:09:25,210
And actually, that really, really comes through in their responses.

143
00:09:25,210 --> 00:09:30,720
They&#39;re happy is-- the signature hallmark emotion is one of happiness, not really of

144
00:09:30,720 --> 00:09:33,670
stress or disaffection or regret even.

145
00:09:33,670 --> 00:09:34,740
No, they think this is great.

146
00:09:34,740 --> 00:09:36,150
I did a wonderful thing.

147
00:09:36,150 --> 00:09:38,190
And Milgram helped them to see it that way.

148
00:09:38,190 --> 00:09:41,820
BLAKE MCKIMMIE: So even after shocking somebody all the way to the end, they feel like they&#39;ve

149
00:09:41,820 --> 00:09:42,820
actually achieved something.

150
00:09:42,820 --> 00:09:43,820
ALEX HASLAM: They&#39;ve achieved something.

151
00:09:43,820 --> 00:09:44,820
They&#39;ve been good participants.

152
00:09:44,820 --> 00:09:45,900
They made a contribution to science.

153
00:09:45,900 --> 00:09:46,900
They&#39;ve pushed science forward.

154
00:09:46,900 --> 00:09:49,580
And of course, from Milgram&#39;s perspective, that was indeed what they had done.

155
00:09:49,580 --> 00:09:52,150
They had made that contribution to this cause.

156
00:09:52,150 --> 00:09:55,392
It&#39;s only as outsiders we say, well, but look, hang on a minute here.

157
00:09:55,392 --> 00:09:57,540
You were pre-- you just killed this person for no good reason.

158
00:09:57,540 --> 00:09:58,740
Well, there was a good reason.

159
00:09:58,740 --> 00:10:00,740
And the reason was science.

160
00:10:00,740 --> 00:10:04,140
And again, when you see people do bad things to other people, that&#39;s typically because

161
00:10:04,140 --> 00:10:09,430
they believe in what they&#39;re doing and the value of it, the utility of it, and its contribution

162
00:10:09,430 --> 00:10:12,120
to making the world a better place, not a worse place.

163
00:10:12,120 --> 00:10:17,760
BLAKE MCKIMMIE: So knowing what we know now then, looking at it through those eyes, what

164
00:10:17,760 --> 00:10:24,180
are the sorts of things you can do to maybe undermine some of the negative consequences

165
00:10:24,180 --> 00:10:28,620
of following-- identifying with and following those sorts of goals?

166
00:10:28,620 --> 00:10:31,420
ALEX HASLAM: Yeah, I mean, I think that&#39;s a very important question.

167
00:10:31,420 --> 00:10:36,720
I mean what you see is that Milgram was able to induce obedience because he had created

168
00:10:36,720 --> 00:10:40,220
a kind of total-- where he did, because he didn&#39;t always, bear in mind, when and where

169
00:10:40,220 --> 00:10:46,140
he did-- it was because he created a totalizing environment where you didn&#39;t hear from the

170
00:10:46,140 --> 00:10:47,160
other.

171
00:10:47,160 --> 00:10:51,310
You weren&#39;t aware of the other potential perspectives or identities that were in play.

172
00:10:51,310 --> 00:10:52,580
It was just about the science.

173
00:10:52,580 --> 00:10:54,080
And you&#39;re caught up in the science.

174
00:10:54,080 --> 00:11:04,000
And if you look at most organizations or enterprises which cultivate what we understand as evil,

175
00:11:04,000 --> 00:11:05,960
what you see is they have that totalizing character.

176
00:11:05,960 --> 00:11:11,590
So whether you&#39;re talking about extremist political groups or terrorist groups or cults,

177
00:11:11,590 --> 00:11:16,830
again, it&#39;s very much about one version of reality, one leadership.

178
00:11:16,830 --> 00:11:25,220
And those organizations go to a lot of difficulty to silence and to peripheralize other interests.

179
00:11:25,220 --> 00:11:28,250
So again, you see that in totalitarian regimes.

180
00:11:28,250 --> 00:11:32,870
You don&#39;t allow other perspectives to enter into people&#39;s consciousness.

181
00:11:32,870 --> 00:11:37,510
So I think one issue there is that that&#39;s the importance of pluralistic democracies

182
00:11:37,510 --> 00:11:45,270
in a sense is that they provide a perspective from which to critique your own stance.

183
00:11:45,270 --> 00:11:50,620
And they allow you to sometimes step outside one identity and look at it from the perspective

184
00:11:50,620 --> 00:11:51,690
of another identity.

185
00:11:51,690 --> 00:11:52,810
And that&#39;s really very critical.

186
00:11:52,810 --> 00:11:58,460
And I think with that, comes a particular form of insight and, indeed, a sort of recognition

187
00:11:58,460 --> 00:12:02,320
that maybe what you&#39;re doing isn&#39;t quite as wonderful as it is presented as being.

