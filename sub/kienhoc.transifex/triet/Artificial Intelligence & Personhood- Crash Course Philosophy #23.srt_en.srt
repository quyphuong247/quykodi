1
00:00:03,080 --> 00:00:06,260
https://www.youtube.com/watch?v=39EdqUbj92U
Crash Course Philosophy is brought to you
by Squarespace.

2
00:00:06,261 --> 00:00:08,861
Squarespace: share your passion with the world

3
00:00:08,861 --> 00:00:11,541
Ok, guys, real talk.
Uhh, I’m kinda worried.

4
00:00:11,549 --> 00:00:14,140
I think my brother John might be a robot.

5
00:00:14,140 --> 00:00:17,560
I know, it sounds ridiculous.
He looks like a human. Pretty much.

6
00:00:17,560 --> 00:00:19,800
And he acts like a human.
Most of the time.

7
00:00:19,800 --> 00:00:24,680
But how could I really-100-percent-for-sure
know that he is what he looks like?

8
00:00:24,680 --> 00:00:30,460
At least, without getting a close look at what’s inside him – in his head, his body, his inner workings?

9
00:00:30,460 --> 00:00:32,440
And keep in mind, I’m the younger brother.

10
00:00:32,440 --> 00:00:36,200
For all I know, Mom and Dad brought him home
from Radio Shack, not the hospital.

11
00:00:36,200 --> 00:00:41,700
So. How can I tell whether my brother John Green
is a human, or just a really intelligent machine?

12
00:00:41,700 --> 00:00:51,880
[Theme Music]

13
00:00:51,880 --> 00:00:54,739
A couple of weeks ago, we talked about what
it means to be a person.

14
00:00:54,740 --> 00:01:00,400
But a subject that we need to explore a little better is whether a non-living being, like a robot, could be a person, too.

15
00:01:00,400 --> 00:01:03,500
This isn’t just a concern for science fiction
writers.

16
00:01:03,500 --> 00:01:06,670
This issue matters, because technology is
getting better all the time,

17
00:01:06,670 --> 00:01:11,210
and we need to figure out how we're going
to treat potential new persons,

18
00:01:11,210 --> 00:01:14,820
if we end up creating beings that we decide
meet the threshold of personhood.

19
00:01:14,820 --> 00:01:18,810
I'm talking about – robots, androids, replicants,
cylons whatever you call ‘em.

20
00:01:18,810 --> 00:01:21,030
If you read and watch the right stuff, you
know who I’m talking about.

21
00:01:21,030 --> 00:01:24,790
Now, you might be thinking: Don't we have artificial intelligence already? Like, on my phone?

22
00:01:24,790 --> 00:01:29,560
Well, yeah. But the kind of AI that we use to send our texts, proof-read our emails,

23
00:01:29,560 --> 00:01:32,420
and plot our commutes to work is pretty weak
in the technical sense.

24
00:01:32,420 --> 00:01:37,189
A machine or system that mimics some aspect
of human intelligence is known as Weak AI.

25
00:01:37,189 --> 00:01:41,149
Siri is a good example, but similar technology
has been around a lot longer than that.

26
00:01:41,149 --> 00:01:46,579
Auto-correct, spell-check, even old school calculators are capable of mimicking portions of human intelligence.

27
00:01:46,579 --> 00:01:51,439
Weak AI is characterized by its relatively
narrow range of thought-like abilities.

28
00:01:51,440 --> 00:01:56,160
Strong AI, on the other hand, is a machine
or system that actually thinks like us.

29
00:01:56,160 --> 00:02:01,060
Whatever it is that our brains do, strong AI is an inorganic system that does the same thing.

30
00:02:01,060 --> 00:02:04,540
While weak AI has been around for a long time,
and keeps getting stronger,

31
00:02:04,549 --> 00:02:06,860
we have yet to design a system with strong
AI.

32
00:02:06,860 --> 00:02:10,079
But what would it mean for something to have
strong AI

33
00:02:10,079 --> 00:02:12,200
Would we even know when it happened?

34
00:02:12,200 --> 00:02:16,249
Way back in 1950, British mathematician Alan
Turing was thinking about this very question.

35
00:02:16,249 --> 00:02:23,389
And he devised a test – called the Turing Test – that he thought would be able to demonstrate when a machine had developed the ability to think like us.

36
00:02:23,389 --> 00:02:28,520
Turing’s description of the test was a product of its time – a time in which there were really no computers, to speak of.

37
00:02:28,520 --> 00:02:31,980
But if Turing were describing it today, it
would probably go something like this:

38
00:02:31,980 --> 00:02:34,920
You’re having a conversation, via text,
with two individuals.

39
00:02:34,920 --> 00:02:38,740
One is a human, and the other is a computer
or AI of some kind.

40
00:02:38,749 --> 00:02:40,749
And you aren’t told which is which.

41
00:02:40,749 --> 00:02:43,469
You may ask both of your interlocutors anything
you would like,

42
00:02:43,469 --> 00:02:46,580
and they are free to answer however they like
– they can even lie.

43
00:02:46,580 --> 00:02:49,019
Do you think you’d be able to tell which
one was the human?

44
00:02:49,020 --> 00:02:51,600
How would you tell?
What sort of questions would you ask?

45
00:02:51,600 --> 00:02:53,640
And what kind of answers would you expect
back?

46
00:02:53,640 --> 00:02:58,820
A machine with complex enough programming ought to be able to fool you into believing you’re conversing with another human.

47
00:02:58,820 --> 00:03:04,260
And Turing said, if a machine can fool a human into thinking it's a human, then it has strong AI.

48
00:03:04,260 --> 00:03:09,760
So in his view, all it means for something to think like us is for it to be able to convince us that it’s thinking like us.

49
00:03:09,760 --> 00:03:12,519
If we can’t tell the difference, there really
is no difference.

50
00:03:12,519 --> 00:03:14,510
It's a strictly behavior-based test.

51
00:03:14,510 --> 00:03:18,339
And if you think about it, isn’t behavior
really the standard we use to judge each other?

52
00:03:18,340 --> 00:03:20,060
I mean, really, I could be a robot!

53
00:03:20,069 --> 00:03:22,730
So could these guys who are helping me shoot
this episode.

54
00:03:22,730 --> 00:03:28,750
The reason I don’t think I’m working with a bunch of androids is that they act the way that I’ve come to expect people to act.

55
00:03:28,750 --> 00:03:29,999
At least, most of the time.

56
00:03:29,999 --> 00:03:32,929
And when we see someone displaying behaviors
that seem a lot like ours

57
00:03:32,929 --> 00:03:35,769
– displaying things like intentionality
and understanding –

58
00:03:35,769 --> 00:03:38,589
we assume that they have intentionality and
understanding.

59
00:03:38,589 --> 00:03:43,280
Now, fast-forward a few decades, and meet contemporary American philosopher William Lycan.

60
00:03:43,280 --> 00:03:49,100
He agrees with Turing on many points, and has the benefit of living in a time when artificial intelligence has advanced like crazy.

61
00:03:49,100 --> 00:03:53,840
But Lycan recognizes that a lot of people still think that you can make a person-like robot,

62
00:03:53,840 --> 00:03:57,139
but you could never actually make a robot
that’s a person.

63
00:03:57,139 --> 00:04:00,790
And for those people, Lycan would offer up
this guy for consideration: Harry.

64
00:04:00,790 --> 00:04:04,760
Harry is a humanoid robot with lifelike skin.
He can play golf and the viola.

65
00:04:04,760 --> 00:04:08,520
He gets nervous. He makes love.
He has a weakness for expensive gin.

66
00:04:08,520 --> 00:04:12,519
Harry, like John Green, gives every impression
of being a person.

67
00:04:12,520 --> 00:04:16,020
He has intentions and emotions.
You consider him to be your friend.

68
00:04:16,020 --> 00:04:21,680
So if Harry gets a cut, and then motor oil, rather than blood, spills out, you would certainly be surprised.

69
00:04:21,680 --> 00:04:28,080
But, Lycan says, this revelation shouldn’t cause you to downgrade Harry’s cognitive state from “person” to “person-like.”

70
00:04:28,080 --> 00:04:31,040
If you would argue that Harry’s not a person,
then what’s he missing?

71
00:04:31,040 --> 00:04:34,100
One possible answer is that he’s not a person
because he was programmed.

72
00:04:34,100 --> 00:04:37,680
Lycan’s response to that is, well, weren’t
we all?

73
00:04:37,680 --> 00:04:42,360
Each of us came loaded with a genetic code that predisposed us to all sorts of different things –

74
00:04:42,360 --> 00:04:46,400
you might have a short fuse like your mom,
or a dry sense of humor like your grandfather.

75
00:04:46,400 --> 00:04:51,800
And in addition to the coding you had at birth, you were programmed in all sorts of other ways by your parents and teachers.

76
00:04:51,800 --> 00:04:56,080
You were programmed to use a toilet, silverware,
to speak English, rather than Portuguese.

77
00:04:56,080 --> 00:04:59,800
Unless, of course, you speak Portuguese.
But if you do, you were still programmed.

78
00:04:59,800 --> 00:05:03,560
And what do you think I’m doing right now?
I’m programming you!

79
00:05:03,560 --> 00:05:08,740
Sure, you have the ability to go beyond your programming, but so does Harry. That’s Lycan’s point.

80
00:05:08,740 --> 00:05:14,660
Now another distinction that you might make between persons like us and Harry is that we have souls and Harry doesn’t.

81
00:05:14,660 --> 00:05:18,980
Now, you’ve probably seen enough Crash Course Philosophy by now to know how problematic this argument is.

82
00:05:18,980 --> 00:05:23,160
But let’s suppose there is a God, and let’s
suppose that he gave each of us a soul.

83
00:05:23,169 --> 00:05:26,930
We of course have no idea what the process
of “ensoulment” might look like.

84
00:05:26,930 --> 00:05:31,800
But suffice it to say, if God can zap a soul
into a fertilized egg or a newborn baby,

85
00:05:31,800 --> 00:05:35,580
there’s no real reason to suppose he couldn’t
zap one into Harry as well.

86
00:05:35,580 --> 00:05:39,960
Harry can’t reproduce, but neither can plenty
of humans, and we don’t call them non-persons.

87
00:05:39,960 --> 00:05:43,700
He doesn’t have blood but, really, do you think that that’s the thing that makes you you?

88
00:05:43,700 --> 00:05:45,560
Lycan says Harry’s a person.

89
00:05:45,560 --> 00:05:50,270
His origin and his material constitution are
different than yours and mine, but who cares?

90
00:05:50,270 --> 00:05:55,289
After all, there have been times and places in which having a different color of skin, or different sex organs,

91
00:05:55,289 --> 00:06:01,260
has caused someone to be labeled a “non-person,” but we know that kind of thinking doesn't hold up to scrutiny.

92
00:06:01,260 --> 00:06:04,760
Back in 1950, Turing knew no machine could
pass his test.

93
00:06:04,760 --> 00:06:06,960
But he thought it would happen by the year
2000.

94
00:06:06,960 --> 00:06:12,000
It turns out, though, that because we can think outside of our programming in ways that computer programs can't,

95
00:06:12,000 --> 00:06:15,400
it's been really hard to design a program
that can pass the Turing Test.

96
00:06:15,400 --> 00:06:17,400
But what will happen when an something can?

97
00:06:17,400 --> 00:06:22,580
Many argue that, even if a machine does pass the Turing test, that doesn't tell us that it actually has strong AI.

98
00:06:22,580 --> 00:06:27,000
These objectors argue that there's more to
“thinking like us” than simply being able to fool us.

99
00:06:27,000 --> 00:06:29,480
Let’s head over to the Thought Bubble for
some Flash Philosophy.

100
00:06:29,480 --> 00:06:34,980
Contemporary American philosopher John Searle constructed a famous thought experiment called the “Chinese Room,”

101
00:06:34,980 --> 00:06:39,880
designed to show that passing for human isn’t
sufficient to qualify for strong AI.

102
00:06:39,880 --> 00:06:42,340
Imagine you're a person who speaks no Chinese.

103
00:06:42,349 --> 00:06:45,280
You’re locked in a room with boxes filled
with Chinese characters,

104
00:06:45,280 --> 00:06:50,180
and a code book in English with instructions about what characters to use in response to what input.

105
00:06:50,180 --> 00:06:53,900
Native Chinese speakers pass written messages,
in Chinese, into the room.

106
00:06:53,900 --> 00:06:57,840
Using the code book, you figure out how to
respond to the characters you receive,

107
00:06:57,840 --> 00:07:00,180
and you pass out the appropriate characters
in return.

108
00:07:00,180 --> 00:07:03,980
You have no idea what any of it means, but
you successfully follow the code.

109
00:07:03,980 --> 00:07:08,420
You do this so well, in fact, that the native
Chinese speakers believe you know Chinese.

110
00:07:08,430 --> 00:07:11,030
You’ve passed the Chinese-speaking Turing
Test.

111
00:07:11,030 --> 00:07:13,640
But do you know Chinese?
Of course not.

112
00:07:13,640 --> 00:07:17,060
You just know how to manipulate symbols – with
no understanding of what they mean –

113
00:07:17,069 --> 00:07:20,249
in a way that fools people into thinking you
know something you don't.

114
00:07:20,249 --> 00:07:26,500
Likewise, according to Searle, the fact that a machine can fool someone into thinking it’s a person doesn't mean it has strong AI.

115
00:07:26,500 --> 00:07:31,000
Searle argues that strong AI would require
that the machine have actual understanding,

116
00:07:31,009 --> 00:07:34,439
which he thinks is impossible for a computer
to ever achieve.

117
00:07:34,440 --> 00:07:36,580
Thanks, Thought Bubble!
One more point before we get out of here.

118
00:07:36,580 --> 00:07:41,400
Some people have responded to the Chinese Room thought experiment by saying, sure, you don’t know Chinese.

119
00:07:41,400 --> 00:07:44,880
But, no particular region of your brain knows
English, either.

120
00:07:44,880 --> 00:07:47,539
The whole system that is your brain knows
English.

121
00:07:47,539 --> 00:07:51,939
Likewise, the whole system that is the Chinese
Room – you, the code book, the symbols –

122
00:07:51,940 --> 00:07:57,040
together know Chinese, even though the particular
piece of the system that is you, does not.

123
00:07:57,040 --> 00:08:01,080
So…I’ve been thinking about it.
I’m still not convinced John isn’t a robot.

124
00:08:01,080 --> 00:08:06,199
In fact, Harry really drove home the point for me that we don’t actually know what’s going on inside any of us.

125
00:08:06,199 --> 00:08:09,319
But if it would turn out that John
– the John I’ve known my entire life –

126
00:08:09,319 --> 00:08:13,620
has motor oil instead of blood inside, well,
he’d still be my brother.

127
00:08:13,620 --> 00:08:17,650
Today we learned about artificial intelligence,
including weak AI and strong AI,

128
00:08:17,650 --> 00:08:20,650
and the various ways that thinkers have tried
to define strong AI.

129
00:08:20,650 --> 00:08:25,070
We considered the Turing Test, and John Searle’s
response to the Turing Test, the Chinese Room.

130
00:08:25,070 --> 00:08:30,780
We also talked about William Lycan, Harry, and my brother, the still-possibly-but-probably-not android.

131
00:08:30,780 --> 00:08:35,700
Next time, we’ll look into an issue that has been lurking around this discussion of artificial intelligence:

132
00:08:35,700 --> 00:08:37,760
do any of us have free will?

133
00:08:37,760 --> 00:08:40,240
This episode is brought to you by Squarespace.

134
00:08:40,240 --> 00:08:44,900
Squarespace helps to create websites, blogs
or online stores for you and your ideas.

135
00:08:44,900 --> 00:08:49,110
Websites look professionally designed regardless
of skill level, no coding required.

136
00:08:49,110 --> 00:08:53,010
Try Squarespace at squarespace.com/crashcourse
for a special offer.

137
00:08:53,010 --> 00:08:55,200
Squarespace: share your passion with the world.

138
00:08:55,200 --> 00:08:58,680
Crash Course Philosophy is produced in association
with PBS Digital Studios.

139
00:08:58,680 --> 00:09:02,780
You can head over to their channel and check out a playlist of the latest episodes from shows like

140
00:09:02,780 --> 00:09:06,180
PBS OffBook, The Art Assignment, and Blank
on Blank.

141
00:09:06,180 --> 00:09:10,140
This episode of Crash Course was filmed in
the Doctor Cheryl C. Kinney Crash Course Studio

142
00:09:10,140 --> 00:09:15,180
with the help of all of these awesome people and our equally fantastic graphics team is Thought Cafe.

